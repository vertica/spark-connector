<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/vertica/spark/util/table/TableUtils.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>// (c) Copyright [2020-2021] Micro Focus or one of its affiliates.
</span>2 <span style=''>// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
</span>3 <span style=''>// You may not use this file except in compliance with the License.
</span>4 <span style=''>// You may obtain a copy of the License at
</span>5 <span style=''>//
</span>6 <span style=''>// http://www.apache.org/licenses/LICENSE-2.0
</span>7 <span style=''>//
</span>8 <span style=''>// Unless required by applicable law or agreed to in writing, software
</span>9 <span style=''>// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
</span>10 <span style=''>// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span>11 <span style=''>// See the License for the specific language governing permissions and
</span>12 <span style=''>// limitations under the License.
</span>13 <span style=''>
</span>14 <span style=''>package com.vertica.spark.util.table
</span>15 <span style=''>
</span>16 <span style=''>import com.vertica.spark.config.{EscapeUtils, LogProvider, TableName}
</span>17 <span style=''>import com.vertica.spark.datasource.jdbc.{JdbcLayerInterface, JdbcLayerStringParam, JdbcUtils}
</span>18 <span style=''>import com.vertica.spark.util.error.ErrorHandling.ConnectorResult
</span>19 <span style=''>import com.vertica.spark.util.error.{ConnectorError, CreateTableError, DropTableError, JdbcError, JobStatusCreateError, JobStatusUpdateError, SchemaConversionError, TableCheckError}
</span>20 <span style=''>import com.vertica.spark.util.schema.SchemaToolsInterface
</span>21 <span style=''>import org.apache.spark.sql.types.StructType
</span>22 <span style=''>
</span>23 <span style=''>import scala.util.{Failure, Success, Try}
</span>24 <span style=''>
</span>25 <span style=''>/**
</span>26 <span style=''> * Interface for common functionality dealing with Vertica tables.
</span>27 <span style=''> */
</span>28 <span style=''>trait TableUtilsInterface {
</span>29 <span style=''>  /**
</span>30 <span style=''>   * Checks if a view exists by a given name.
</span>31 <span style=''>   */
</span>32 <span style=''>  def viewExists(view: TableName): ConnectorResult[Boolean]
</span>33 <span style=''>
</span>34 <span style=''>  /**
</span>35 <span style=''>   * Checks if a view exists by a given name.
</span>36 <span style=''>   */
</span>37 <span style=''>  def tableExists(table: TableName): ConnectorResult[Boolean]
</span>38 <span style=''>
</span>39 <span style=''>  /**
</span>40 <span style=''>   * Checks specifically if a table exists by the given name AND that table is temporary.
</span>41 <span style=''>   */
</span>42 <span style=''>  def tempTableExists(table: TableName): ConnectorResult[Boolean]
</span>43 <span style=''>
</span>44 <span style=''>  /**
</span>45 <span style=''>   * Creates a table. Will either used passed in statement to create it, or generate it's own create statement here.
</span>46 <span style=''>   *
</span>47 <span style=''>   * @param tablename Name of table
</span>48 <span style=''>   * @param targetTableSql Optional value, if specified this entire string will be used to create the table and other params will be ignored.
</span>49 <span style=''>   * @param schema Spark schema of data we want to write to the table
</span>50 <span style=''>   * @param strlen Length to use for strings in Vertica string types
</span>51 <span style=''>   */
</span>52 <span style=''>  def createTable(tablename: TableName, targetTableSql: Option[String], schema: StructType, strlen: Long): ConnectorResult[Unit]
</span>53 <span style=''>
</span>54 <span style=''>
</span>55 <span style=''>  /**
</span>56 <span style=''>   * Creates an external table based on parquet data on disk.
</span>57 <span style=''>   *
</span>58 <span style=''>   * @param tablename Name of table
</span>59 <span style=''>   * @param targetTableSql Optional value, if specified this entire string will be used to create the table and other params will be ignored.
</span>60 <span style=''>   * @param schema Spark schema of data we want to write to the table
</span>61 <span style=''>   * @param strlen Length to use for strings in Vertica string types
</span>62 <span style=''>   */
</span>63 <span style=''>  def createExternalTable(tablename: TableName, targetTableSql: Option[String], schema: StructType, strlen: Long, urlToCopyFrom: String): ConnectorResult[Unit]
</span>64 <span style=''>
</span>65 <span style=''>  /**
</span>66 <span style=''>   * Validates that an external table was created properly and can be loaded from without error
</span>67 <span style=''>   *
</span>68 <span style=''>   * @param tablename
</span>69 <span style=''>   * @return Empty result if valid, error otherwise
</span>70 <span style=''>   */
</span>71 <span style=''>  def validateExternalTable(tablename: TableName): ConnectorResult[Unit]
</span>72 <span style=''>
</span>73 <span style=''>  /**
</span>74 <span style=''>   * Drops/Deletes a given table if it exists.
</span>75 <span style=''>   */
</span>76 <span style=''>  def dropTable(tablename: TableName): ConnectorResult[Unit]
</span>77 <span style=''>
</span>78 <span style=''>  /**
</span>79 <span style=''>   * Creates a temporary table.
</span>80 <span style=''>   *
</span>81 <span style=''>   * @param tablename Name of table
</span>82 <span style=''>   * @param schema Spark schema of data we want to write to the table
</span>83 <span style=''>   * @param strlen Length to use for strings in Vertica string types
</span>84 <span style=''>   */
</span>85 <span style=''>  def createTempTable(tablename: TableName, schema: StructType, strlen: Long): ConnectorResult[Unit]
</span>86 <span style=''>
</span>87 <span style=''>  /**
</span>88 <span style=''>   * Creates the job status table if it doesn't exist and adds the entry for this job.
</span>89 <span style=''>   *
</span>90 <span style=''>   * The job status table records write jobs in Vertica and their status, so we can have an auditable record of writes from Spark to Vertica.
</span>91 <span style=''>   *
</span>92 <span style=''>   * @param tablename Table being used in this job.
</span>93 <span style=''>   * @param user Vertica user executing this job.
</span>94 <span style=''>   * @param sessionId Unique identifier for this job.
</span>95 <span style=''>   */
</span>96 <span style=''>  def createAndInitJobStatusTable(tablename: TableName, user: String, sessionId: String, saveMode: String): ConnectorResult[Unit]
</span>97 <span style=''>
</span>98 <span style=''>  /**
</span>99 <span style=''>   * Updates the job status table entry for the given job.
</span>100 <span style=''>   *
</span>101 <span style=''>   * @param tableName Table being used in this job.
</span>102 <span style=''>   * @param user Vertica user executing this job.
</span>103 <span style=''>   * @param failedRowsPercent Percent of rows that failed to write in this job.
</span>104 <span style=''>   * @param sessionId Unique identifier for this job.
</span>105 <span style=''>   * @param success Whether the job succeeded.
</span>106 <span style=''>   */
</span>107 <span style=''>  def updateJobStatusTable(tableName: TableName, user: String, failedRowsPercent: Double, sessionId: String, success: Boolean): ConnectorResult[Unit]
</span>108 <span style=''>}
</span>109 <span style=''>
</span>110 <span style=''>/**
</span>111 <span style=''> * Implementation of TableUtils wrapping JDBC layer.
</span>112 <span style=''> */
</span>113 <span style=''>class TableUtils(schemaTools: SchemaToolsInterface, jdbcLayer: JdbcLayerInterface) extends TableUtilsInterface {
</span>114 <span style=''>  private val logger = </span><span style='background: #AEF1AE'>LogProvider.getLogger(classOf[TableUtils])</span><span style=''>
</span>115 <span style=''>
</span>116 <span style=''>  private def buildCreateTableStmt(tablename: TableName, schema: StructType, strlen: Long, temp: Boolean = false): ConnectorResult[String] = {
</span>117 <span style=''>    val sb = </span><span style='background: #AEF1AE'>new StringBuilder()</span><span style=''>
</span>118 <span style=''>    </span><span style='background: #AEF1AE'>sb.append(tablename.getFullTableName)</span><span style=''>
</span>119 <span style=''>
</span>120 <span style=''>    </span><span style='background: #AEF1AE'>schemaTools.makeTableColumnDefs(schema, strlen)</span><span style=''> match {
</span>121 <span style=''>      case Right(columnDefs) =&gt;
</span>122 <span style=''>        val sb = </span><span style='background: #AEF1AE'>new StringBuilder()</span><span style=''>
</span>123 <span style=''>        if(temp) </span><span style='background: #F0ADAD'>sb.append(&quot;CREATE TEMPORARY TABLE &quot;)</span><span style=''> else </span><span style='background: #AEF1AE'>sb.append(&quot;CREATE table &quot;)</span><span style=''>
</span>124 <span style=''>        </span><span style='background: #AEF1AE'>sb.append(tablename.getFullTableName)</span><span style=''>
</span>125 <span style=''>
</span>126 <span style=''>        </span><span style='background: #AEF1AE'>sb.append(columnDefs)</span><span style=''>
</span>127 <span style=''>
</span>128 <span style=''>        if(temp) </span><span style='background: #F0ADAD'>sb.append(&quot; ON COMMIT PRESERVE ROWS INCLUDE SCHEMA PRIVILEGES &quot;)</span><span style=''> else </span><span style='background: #AEF1AE'>sb.append(&quot; INCLUDE SCHEMA PRIVILEGES &quot;)</span><span style=''>
</span>129 <span style=''>        </span><span style='background: #AEF1AE'>Right(sb.toString)</span><span style=''>
</span>130 <span style=''>      case Left(err) =&gt; </span><span style='background: #F0ADAD'>Left(err)</span><span style=''>
</span>131 <span style=''>    }
</span>132 <span style=''>  }
</span>133 <span style=''>
</span>134 <span style=''>  override def tempTableExists(table: TableName): ConnectorResult[Boolean] = {
</span>135 <span style=''>    val dbschema = </span><span style='background: #AEF1AE'>table.dbschema.getOrElse(&quot;public&quot;)</span><span style=''>
</span>136 <span style=''>    val query = </span><span style='background: #AEF1AE'>&quot;select is_temp_table as t from v_catalog.tables where table_name=? and table_schema=?&quot;</span><span style=''>
</span>137 <span style=''>    val params = </span><span style='background: #AEF1AE'>Seq(JdbcLayerStringParam(table.name), JdbcLayerStringParam(dbschema))</span><span style=''>
</span>138 <span style=''>    val ret = </span><span style='background: #AEF1AE'>for {
</span>139 <span style=''></span><span style='background: #AEF1AE'>      rs &lt;- jdbcLayer.query(query, params)
</span>140 <span style=''></span><span style='background: #AEF1AE'>      res = Try{ if (rs.next) {rs.getBoolean(&quot;t&quot;) } else </span><span style='background: #F0ADAD'>false</span><span style='background: #AEF1AE'> }
</span>141 <span style=''></span><span style='background: #AEF1AE'>      _ = rs.close()
</span>142 <span style=''></span><span style='background: #AEF1AE'>      isTemp &lt;- JdbcUtils.tryJdbcToResult(jdbcLayer, res)
</span>143 <span style=''></span><span style='background: #AEF1AE'>    } yield isTemp</span><span style=''>
</span>144 <span style=''>
</span>145 <span style=''>    </span><span style='background: #AEF1AE'>ret.left.map(err =&gt; TableCheckError(Some(err)).context(&quot;Cannot append to a temporary table&quot;))</span><span style=''>
</span>146 <span style=''>  }
</span>147 <span style=''>
</span>148 <span style=''>  override def viewExists(view: TableName): ConnectorResult[Boolean] = {
</span>149 <span style=''>    val dbschema = </span><span style='background: #AEF1AE'>view.dbschema.getOrElse(&quot;public&quot;)</span><span style=''>
</span>150 <span style=''>    val query = </span><span style='background: #AEF1AE'>&quot;select count(*) from views where table_schema ILIKE ? and table_name ILIKE ?&quot;</span><span style=''>
</span>151 <span style=''>    val params = </span><span style='background: #AEF1AE'>Seq(JdbcLayerStringParam(dbschema), JdbcLayerStringParam(view.name))</span><span style=''>
</span>152 <span style=''>
</span>153 <span style=''>    </span><span style='background: #AEF1AE'>jdbcLayer.query(query, params)</span><span style=''> match {
</span>154 <span style=''>      case Left(err) =&gt; </span><span style='background: #F0ADAD'>Left(TableCheckError(Some(err)).context(&quot;JDBC Error when checking if view exists&quot;))</span><span style=''>
</span>155 <span style=''>      case Right(rs) =&gt;
</span>156 <span style=''>        try {
</span>157 <span style=''>          </span><span style='background: #AEF1AE'>if (!rs.next()) {
</span>158 <span style=''></span><span style='background: #AEF1AE'>            </span><span style='background: #F0ADAD'>Left(TableCheckError(None).context(&quot;View check: empty result&quot;))</span><span style='background: #AEF1AE'>
</span>159 <span style=''></span><span style='background: #AEF1AE'>          } else {
</span>160 <span style=''></span><span style='background: #AEF1AE'>            Right(rs.getInt(1) &gt;= 1)
</span>161 <span style=''></span><span style='background: #AEF1AE'>          }</span><span style=''>
</span>162 <span style=''>        } catch {
</span>163 <span style=''>          case e: Throwable =&gt;
</span>164 <span style=''>            </span><span style='background: #F0ADAD'>jdbcLayer.handleJDBCException(e)</span><span style=''>
</span>165 <span style=''>            </span><span style='background: #F0ADAD'>Left(TableCheckError(None))</span><span style=''>
</span>166 <span style=''>        } finally {
</span>167 <span style=''>          </span><span style='background: #AEF1AE'>rs.close()</span><span style=''>
</span>168 <span style=''>        }
</span>169 <span style=''>    }
</span>170 <span style=''>  }
</span>171 <span style=''>
</span>172 <span style=''>  override def tableExists(table: TableName): ConnectorResult[Boolean] = {
</span>173 <span style=''>    val dbschema = </span><span style='background: #AEF1AE'>table.dbschema.getOrElse(&quot;public&quot;)</span><span style=''>
</span>174 <span style=''>    val query = </span><span style='background: #AEF1AE'>&quot;select count(*) from v_catalog.tables where table_schema ILIKE ? and table_name ILIKE ?&quot;</span><span style=''>
</span>175 <span style=''>    val params = </span><span style='background: #AEF1AE'>Seq(JdbcLayerStringParam(dbschema), JdbcLayerStringParam(table.name))</span><span style=''>
</span>176 <span style=''>
</span>177 <span style=''>    </span><span style='background: #AEF1AE'>jdbcLayer.query(query, params)</span><span style=''> match {
</span>178 <span style=''>      case Left(err) =&gt;
</span>179 <span style=''>        </span><span style='background: #AEF1AE'>Left(TableCheckError(Some(err)).context(&quot;JDBC Error when checking if table exists&quot;))</span><span style=''>
</span>180 <span style=''>      case Right(rs) =&gt;
</span>181 <span style=''>        try {
</span>182 <span style=''>          </span><span style='background: #AEF1AE'>if (!rs.next()) {
</span>183 <span style=''></span><span style='background: #AEF1AE'>            </span><span style='background: #F0ADAD'>Left(TableCheckError(None).context(&quot;Table check: empty result&quot;))</span><span style='background: #AEF1AE'>
</span>184 <span style=''></span><span style='background: #AEF1AE'>          } else {
</span>185 <span style=''></span><span style='background: #AEF1AE'>            Right(rs.getInt(1) &gt;= 1)
</span>186 <span style=''></span><span style='background: #AEF1AE'>          }</span><span style=''>
</span>187 <span style=''>        }
</span>188 <span style=''>        catch {
</span>189 <span style=''>          case e: Throwable =&gt;
</span>190 <span style=''>            </span><span style='background: #F0ADAD'>jdbcLayer.handleJDBCException(e)</span><span style=''>
</span>191 <span style=''>            </span><span style='background: #F0ADAD'>Left(TableCheckError(None))</span><span style=''>
</span>192 <span style=''>        }
</span>193 <span style=''>        finally {
</span>194 <span style=''>          </span><span style='background: #AEF1AE'>rs.close()</span><span style=''>
</span>195 <span style=''>        }
</span>196 <span style=''>    }
</span>197 <span style=''>  }
</span>198 <span style=''>
</span>199 <span style=''>  override def createExternalTable(tablename: TableName, targetTableSql: Option[String], schema: StructType, strlen: Long, urlToCopyFrom: String): ConnectorResult[Unit] = {
</span>200 <span style=''>    val statement: ConnectorResult[String] = targetTableSql match {
</span>201 <span style=''>      case Some(sql) =&gt; </span><span style='background: #F0ADAD'>Right(sql)</span><span style=''>
</span>202 <span style=''>      case None =&gt;
</span>203 <span style=''>        </span><span style='background: #AEF1AE'>schemaTools.makeTableColumnDefs(schema, strlen)</span><span style=''> match {
</span>204 <span style=''>          case Right(columnDefs) =&gt;
</span>205 <span style=''>            val sb = </span><span style='background: #AEF1AE'>new StringBuilder()</span><span style=''>
</span>206 <span style=''>            </span><span style='background: #AEF1AE'>sb.append(&quot;CREATE EXTERNAL table &quot;)</span><span style=''>
</span>207 <span style=''>            </span><span style='background: #AEF1AE'>sb.append(tablename.getFullTableName)</span><span style=''>
</span>208 <span style=''>
</span>209 <span style=''>            </span><span style='background: #AEF1AE'>sb.append(columnDefs)</span><span style=''>
</span>210 <span style=''>
</span>211 <span style=''>            </span><span style='background: #AEF1AE'>sb.append(&quot; AS COPY FROM '&quot;)</span><span style=''>
</span>212 <span style=''>            </span><span style='background: #AEF1AE'>sb.append(urlToCopyFrom)</span><span style=''>
</span>213 <span style=''>            </span><span style='background: #AEF1AE'>sb.append(&quot;' PARQUET&quot;)</span><span style=''>
</span>214 <span style=''>            </span><span style='background: #AEF1AE'>Right(sb.toString)</span><span style=''>
</span>215 <span style=''>          case Left(err) =&gt; </span><span style='background: #F0ADAD'>Left(err)</span><span style=''>
</span>216 <span style=''>        }
</span>217 <span style=''>    }
</span>218 <span style=''>
</span>219 <span style=''>    statement match {
</span>220 <span style=''>      case Left(err) =&gt; </span><span style='background: #F0ADAD'>Left(err)</span><span style=''>
</span>221 <span style=''>      case Right(st) =&gt;
</span>222 <span style=''>        logger.info(s&quot;BUILDING EXTERNAL TABLE WITH COMMAND: &quot; + statement)
</span>223 <span style=''>        </span><span style='background: #AEF1AE'>jdbcLayer.execute(st).left.map(err =&gt; </span><span style='background: #F0ADAD'>CreateTableError(Some(err)).context(&quot;JDBC Error creating external table&quot;)</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>224 <span style=''>    }
</span>225 <span style=''>  }
</span>226 <span style=''>
</span>227 <span style=''>  override def validateExternalTable(tablename: TableName): ConnectorResult[Unit] = {
</span>228 <span style=''>    // Load a single row from the table to verify that it can be loaded from properly.
</span>229 <span style=''>    // Necessary since basic errors will not be detected upon creation of the external table
</span>230 <span style=''>    </span><span style='background: #F0ADAD'>jdbcLayer.query(&quot;SELECT * FROM &quot; + tablename.getFullTableName + &quot; LIMIT 1;&quot;)</span><span style=''> match {
</span>231 <span style=''>      case Right(_) =&gt; </span><span style='background: #F0ADAD'>Right(())</span><span style=''>
</span>232 <span style=''>      case Left(err) =&gt; </span><span style='background: #F0ADAD'>Left(err)</span><span style=''>
</span>233 <span style=''>    }
</span>234 <span style=''>  }
</span>235 <span style=''>
</span>236 <span style=''>  override def createTable(tablename: TableName, targetTableSql: Option[String], schema: StructType, strlen: Long): ConnectorResult[Unit] = {
</span>237 <span style=''>    // Either get the user-supplied statement to create the table, or build our own
</span>238 <span style=''>    val statement: ConnectorResult[String] = targetTableSql match {
</span>239 <span style=''>      case Some(sql) =&gt; </span><span style='background: #AEF1AE'>Right(sql)</span><span style=''>
</span>240 <span style=''>      case None =&gt;
</span>241 <span style=''>        </span><span style='background: #AEF1AE'>buildCreateTableStmt(tablename, schema, strlen)</span><span style=''>
</span>242 <span style=''>    }
</span>243 <span style=''>
</span>244 <span style=''>    statement match {
</span>245 <span style=''>      case Left(err) =&gt; </span><span style='background: #F0ADAD'>Left(err)</span><span style=''>
</span>246 <span style=''>      case Right(st) =&gt;
</span>247 <span style=''>        logger.info(s&quot;BUILDING TABLE WITH COMMAND: &quot; + statement)
</span>248 <span style=''>        </span><span style='background: #AEF1AE'>jdbcLayer.execute(st).left.map(err =&gt; </span><span style='background: #F0ADAD'>CreateTableError(Some(err)).context(&quot;JDBC Error creating table&quot;)</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>249 <span style=''>    }
</span>250 <span style=''>  }
</span>251 <span style=''>
</span>252 <span style=''>  def dropTable(tablename: TableName): ConnectorResult[Unit] = {
</span>253 <span style=''>    </span><span style='background: #AEF1AE'>jdbcLayer.execute(&quot;DROP TABLE IF EXISTS &quot; + tablename.getFullTableName)
</span>254 <span style=''></span><span style='background: #AEF1AE'>      .left.map(err =&gt; </span><span style='background: #F0ADAD'>err.context(&quot;JDBC Error dropping table&quot;)</span><span style='background: #AEF1AE'>)</span><span style=''>
</span>255 <span style=''>  }
</span>256 <span style=''>
</span>257 <span style=''>  override def createTempTable(tablename: TableName, schema: StructType, strlen: Long): ConnectorResult[Unit] = {
</span>258 <span style=''>    val statement = </span><span style='background: #F0ADAD'>buildCreateTableStmt(tablename, schema, strlen, true)</span><span style=''>
</span>259 <span style=''>    logger.info(s&quot;BUILDING TEMP TABLE WITH COMMAND: &quot; + statement)
</span>260 <span style=''>    statement match {
</span>261 <span style=''>      case Left(err) =&gt; </span><span style='background: #F0ADAD'>Left(err)</span><span style=''>
</span>262 <span style=''>      case Right(st) =&gt;
</span>263 <span style=''>        </span><span style='background: #F0ADAD'>jdbcLayer.execute(st).left.map(err =&gt; CreateTableError(Some(err)).context(&quot;JDBC Error creating table&quot;))</span><span style=''>
</span>264 <span style=''>    }
</span>265 <span style=''>  }
</span>266 <span style=''>
</span>267 <span style=''>  override def createAndInitJobStatusTable(tablename: TableName, user: String, sessionId: String, saveMode: String): ConnectorResult[Unit] = {
</span>268 <span style=''>    val dbschema = </span><span style='background: #AEF1AE'>tablename.dbschema</span><span style=''> match {
</span>269 <span style=''>      case Some(schema) =&gt; schema
</span>270 <span style=''>      case None =&gt; </span><span style='background: #AEF1AE'>&quot;public&quot;</span><span style=''>
</span>271 <span style=''>    }
</span>272 <span style=''>
</span>273 <span style=''>    val table = </span><span style='background: #AEF1AE'>&quot;S2V_JOB_STATUS&quot; + &quot;_USER_&quot; + user.toUpperCase</span><span style=''>
</span>274 <span style=''>
</span>275 <span style=''>    val jobStatusTableName = </span><span style='background: #AEF1AE'>TableName(table, Some(dbschema))</span><span style=''>
</span>276 <span style=''>
</span>277 <span style=''>    // Create job status table for the user if it doesn't exist
</span>278 <span style=''>    val createStatement = </span><span style='background: #AEF1AE'>&quot;CREATE TABLE IF NOT EXISTS &quot; + jobStatusTableName.getFullTableName +
</span>279 <span style=''></span><span style='background: #AEF1AE'>      &quot;(target_table_schema VARCHAR(128), &quot; +
</span>280 <span style=''></span><span style='background: #AEF1AE'>      &quot;target_table_name VARCHAR(128), &quot; +
</span>281 <span style=''></span><span style='background: #AEF1AE'>      &quot;save_mode VARCHAR(128), &quot; +
</span>282 <span style=''></span><span style='background: #AEF1AE'>      &quot;job_name VARCHAR(256), &quot; +
</span>283 <span style=''></span><span style='background: #AEF1AE'>      &quot;start_time TIMESTAMPTZ, &quot; +
</span>284 <span style=''></span><span style='background: #AEF1AE'>      &quot;all_done BOOLEAN NOT NULL, &quot; +
</span>285 <span style=''></span><span style='background: #AEF1AE'>      &quot;success BOOLEAN NOT NULL, &quot; +
</span>286 <span style=''></span><span style='background: #AEF1AE'>      &quot;percent_failed_rows DOUBLE PRECISION)&quot;</span><span style=''>
</span>287 <span style=''>
</span>288 <span style=''>    val jobStartTime = </span><span style='background: #AEF1AE'>java.util.Calendar.getInstance().getTime.toString</span><span style=''>
</span>289 <span style=''>    val date = </span><span style='background: #AEF1AE'>new java.util.Date()</span><span style=''>
</span>290 <span style=''>    val timestamp = </span><span style='background: #AEF1AE'>new java.sql.Timestamp(date.getTime)</span><span style=''>
</span>291 <span style=''>    val randJobName = sessionId
</span>292 <span style=''>
</span>293 <span style=''>    val comment = </span><span style='background: #AEF1AE'>&quot;COMMENT ON TABLE &quot;  + jobStatusTableName.getFullTableName + &quot; IS 'Persistent job status table showing all jobs, serving as permanent record of data loaded from Spark to Vertica. Creation time:&quot; + jobStartTime + &quot;'&quot;</span><span style=''>
</span>294 <span style=''>
</span>295 <span style=''>    val insertStatement = </span><span style='background: #AEF1AE'>&quot;INSERT into &quot; + jobStatusTableName.getFullTableName + &quot; VALUES ('&quot; + EscapeUtils.sqlEscape(dbschema,'\'') + &quot;','&quot; + EscapeUtils.sqlEscape(tablename.name, '\'') + &quot;','&quot; + saveMode + &quot;','&quot; + randJobName +  &quot;','&quot; + timestamp + &quot;',&quot; + &quot;false,false,&quot; + (-1.0).toString + &quot;)&quot;</span><span style=''>
</span>296 <span style=''>
</span>297 <span style=''>    val ret = </span><span style='background: #AEF1AE'>for {
</span>298 <span style=''></span><span style='background: #AEF1AE'>      tableExists &lt;- tableExists(jobStatusTableName)
</span>299 <span style=''></span><span style='background: #AEF1AE'>      _ &lt;- if(!tableExists) jdbcLayer.execute(createStatement) else </span><span style='background: #F0ADAD'>Right(())</span><span style='background: #AEF1AE'>
</span>300 <span style=''></span><span style='background: #AEF1AE'>      _ &lt;- if(!tableExists) jdbcLayer.execute(comment) else </span><span style='background: #F0ADAD'>Right(())</span><span style='background: #AEF1AE'>
</span>301 <span style=''></span><span style='background: #AEF1AE'>      _ &lt;- jdbcLayer.execute(insertStatement)
</span>302 <span style=''></span><span style='background: #AEF1AE'>      _ &lt;- jdbcLayer.commit()
</span>303 <span style=''></span><span style='background: #AEF1AE'>    } yield ()</span><span style=''>
</span>304 <span style=''>
</span>305 <span style=''>    ret match {
</span>306 <span style=''>      case Left(err) =&gt; </span><span style='background: #AEF1AE'>err.getUnderlyingError</span><span style=''> match {
</span>307 <span style=''>        case er: JdbcError =&gt; </span><span style='background: #AEF1AE'>Left(JobStatusCreateError(er)
</span>308 <span style=''></span><span style='background: #AEF1AE'>          .context(&quot;JDBC error when trying to initialize job status table&quot;))</span><span style=''>
</span>309 <span style=''>        case _: ConnectorError =&gt; </span><span style='background: #F0ADAD'>Left(err)</span><span style=''>
</span>310 <span style=''>      }
</span>311 <span style=''>      case Right(_) =&gt; </span><span style='background: #AEF1AE'>Right(())</span><span style=''>
</span>312 <span style=''>    }
</span>313 <span style=''>  }
</span>314 <span style=''>
</span>315 <span style=''>  override def updateJobStatusTable(mainTableName: TableName, user: String, failedRowsPercent: Double, sessionId: String, success: Boolean): ConnectorResult[Unit] = {
</span>316 <span style=''>    val dbschema = </span><span style='background: #AEF1AE'>mainTableName.dbschema.getOrElse(&quot;public&quot;)</span><span style=''>
</span>317 <span style=''>    val tablename = </span><span style='background: #AEF1AE'>&quot;S2V_JOB_STATUS&quot; + &quot;_USER_&quot; + user.toUpperCase</span><span style=''>
</span>318 <span style=''>
</span>319 <span style=''>    val jobStatusTableName = </span><span style='background: #AEF1AE'>TableName(tablename, Some(dbschema))</span><span style=''>
</span>320 <span style=''>
</span>321 <span style=''>    val updateStatusTable = (</span><span style='background: #AEF1AE'>&quot;UPDATE &quot;
</span>322 <span style=''></span><span style='background: #AEF1AE'>      + jobStatusTableName.getFullTableName
</span>323 <span style=''></span><span style='background: #AEF1AE'>      + &quot; SET all_done=&quot; + true + &quot;,&quot;
</span>324 <span style=''></span><span style='background: #AEF1AE'>      + &quot;success=&quot; + success + &quot;,&quot;
</span>325 <span style=''></span><span style='background: #AEF1AE'>      + &quot;percent_failed_rows=&quot; + failedRowsPercent.toString + &quot; &quot;
</span>326 <span style=''></span><span style='background: #AEF1AE'>      + &quot;WHERE job_name='&quot; + sessionId + &quot;' &quot;
</span>327 <span style=''></span><span style='background: #AEF1AE'>      + &quot;AND all_done=&quot; + false</span><span style=''>)
</span>328 <span style=''>
</span>329 <span style=''>    // update the S2V_JOB_STATUS table, and commit the final operation.
</span>330 <span style=''>    logger.info(s&quot;Updating &quot; + jobStatusTableName.getFullTableName + &quot; next...&quot;)
</span>331 <span style=''>    </span><span style='background: #AEF1AE'>jdbcLayer.executeUpdate(updateStatusTable)</span><span style=''> match {
</span>332 <span style=''>      case Left(err) =&gt; </span><span style='background: #F0ADAD'>Left(JobStatusUpdateError(Some(err)).context(&quot;JDBC Error when updating status table&quot;))</span><span style=''>
</span>333 <span style=''>      case Right(c) =&gt;
</span>334 <span style=''>        if(</span><span style='background: #AEF1AE'>c == 1</span><span style=''>) </span><span style='background: #AEF1AE'>{
</span>335 <span style=''></span><span style='background: #AEF1AE'>          logger.info(s&quot;Update of &quot; + jobStatusTableName.getFullTableName + &quot; succeeded.&quot;)
</span>336 <span style=''></span><span style='background: #AEF1AE'>          Right(())
</span>337 <span style=''></span><span style='background: #AEF1AE'>        }</span><span style=''> else {
</span>338 <span style=''>          </span><span style='background: #F0ADAD'>Left(JobStatusUpdateError(None).context(&quot;Status_table update failed.&quot;))</span><span style=''>
</span>339 <span style=''>        }
</span>340 <span style=''>    }
</span>341 <span style=''>  }
</span>342 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Code</th>
      </tr><tr>
        <td>
          114
        </td>
        <td>
          2668
        </td>
        <td>
          4823
          -
          4865
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.config.LogProvider.getLogger
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.config.LogProvider.getLogger(classOf[com.vertica.spark.util.table.TableUtils])
        </td>
      </tr><tr>
        <td>
          117
        </td>
        <td>
          2669
        </td>
        <td>
          5023
          -
          5042
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new scala.`package`.StringBuilder()
        </td>
      </tr><tr>
        <td>
          118
        </td>
        <td>
          2670
        </td>
        <td>
          5057
          -
          5083
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.config.TableName.getFullTableName
        </td>
        <td style="background: #AEF1AE">
          tablename.getFullTableName
        </td>
      </tr><tr>
        <td>
          118
        </td>
        <td>
          2671
        </td>
        <td>
          5047
          -
          5084
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(tablename.getFullTableName)
        </td>
      </tr><tr>
        <td>
          120
        </td>
        <td>
          2672
        </td>
        <td>
          5090
          -
          5137
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.schema.SchemaToolsInterface.makeTableColumnDefs
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.schemaTools.makeTableColumnDefs(schema, strlen)
        </td>
      </tr><tr>
        <td>
          122
        </td>
        <td>
          2673
        </td>
        <td>
          5195
          -
          5214
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new scala.`package`.StringBuilder()
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          2676
        </td>
        <td>
          5274
          -
          5300
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(&quot;CREATE table &quot;)
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          2675
        </td>
        <td>
          5232
          -
          5268
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #F0ADAD">
          sb.append(&quot;CREATE TEMPORARY TABLE &quot;)
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          2677
        </td>
        <td>
          5274
          -
          5300
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(&quot;CREATE table &quot;)
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          2674
        </td>
        <td>
          5232
          -
          5268
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #F0ADAD">
          sb.append(&quot;CREATE TEMPORARY TABLE &quot;)
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          2679
        </td>
        <td>
          5309
          -
          5346
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(tablename.getFullTableName)
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          2678
        </td>
        <td>
          5319
          -
          5345
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.config.TableName.getFullTableName
        </td>
        <td style="background: #AEF1AE">
          tablename.getFullTableName
        </td>
      </tr><tr>
        <td>
          126
        </td>
        <td>
          2680
        </td>
        <td>
          5356
          -
          5377
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(columnDefs)
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          2682
        </td>
        <td>
          5396
          -
          5460
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #F0ADAD">
          sb.append(&quot; ON COMMIT PRESERVE ROWS INCLUDE SCHEMA PRIVILEGES &quot;)
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          2681
        </td>
        <td>
          5396
          -
          5460
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #F0ADAD">
          sb.append(&quot; ON COMMIT PRESERVE ROWS INCLUDE SCHEMA PRIVILEGES &quot;)
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          2684
        </td>
        <td>
          5466
          -
          5506
        </td>
        <td>
          Block
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(&quot; INCLUDE SCHEMA PRIVILEGES &quot;)
        </td>
      </tr><tr>
        <td>
          128
        </td>
        <td>
          2683
        </td>
        <td>
          5466
          -
          5506
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(&quot; INCLUDE SCHEMA PRIVILEGES &quot;)
        </td>
      </tr><tr>
        <td>
          129
        </td>
        <td>
          2685
        </td>
        <td>
          5521
          -
          5532
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.toString
        </td>
        <td style="background: #AEF1AE">
          sb.toString()
        </td>
      </tr><tr>
        <td>
          129
        </td>
        <td>
          2686
        </td>
        <td>
          5515
          -
          5533
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, String](sb.toString())
        </td>
      </tr><tr>
        <td>
          130
        </td>
        <td>
          2687
        </td>
        <td>
          5558
          -
          5567
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](err)
        </td>
      </tr><tr>
        <td>
          135
        </td>
        <td>
          2688
        </td>
        <td>
          5677
          -
          5711
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td style="background: #AEF1AE">
          table.dbschema.getOrElse[String](&quot;public&quot;)
        </td>
      </tr><tr>
        <td>
          136
        </td>
        <td>
          2689
        </td>
        <td>
          5728
          -
          5815
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;select is_temp_table as t from v_catalog.tables where table_name=? and table_schema=?&quot;
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          2690
        </td>
        <td>
          5858
          -
          5868
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.config.TableName.name
        </td>
        <td style="background: #AEF1AE">
          table.name
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          2693
        </td>
        <td>
          5833
          -
          5902
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.apply[com.vertica.spark.datasource.jdbc.JdbcLayerStringParam](com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(table.name), com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(dbschema))
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          2692
        </td>
        <td>
          5871
          -
          5901
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(dbschema)
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          2691
        </td>
        <td>
          5837
          -
          5869
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(table.name)
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          2704
        </td>
        <td>
          5917
          -
          6128
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.flatMap
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.query(query, params).map[(java.sql.ResultSet, scala.util.Try[Boolean], Unit)](((rs: java.sql.ResultSet) =&gt; {
  val res: scala.util.Try[Boolean] = scala.util.Try.apply[Boolean](if (rs.next())
    rs.getBoolean(&quot;t&quot;)
  else
    false);
  val x$1: Unit = rs.close();
  scala.Tuple3.apply[java.sql.ResultSet, scala.util.Try[Boolean], Unit](rs, res, x$1)
})).flatMap[com.vertica.spark.util.error.ConnectorError, Boolean](((x$2: (java.sql.ResultSet, scala.util.Try[Boolean], Unit)) =&gt; (x$2: (java.sql.ResultSet, scala.util.Try[Boolean], Unit) @unchecked) match {
  case (_1: java.sql.ResultSet, _2: scala.util.Try[Boolean], _3: Unit)(java.sql.ResultSet, scala.util.Try[Boolean], Unit)((rs @ _), (res @ _), _) =&gt; com.vertica.spark.datasource.jdbc.JdbcUtils.tryJdbcToResult[Boolean](TableUtils.this.jdbcLayer, res).map[Boolean](((isTemp: Boolean) =&gt; isTemp))
}))
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          2701
        </td>
        <td>
          5929
          -
          5929
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Tuple3.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Tuple3.apply[java.sql.ResultSet, scala.util.Try[Boolean], Unit](rs, res, x$1)
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          2694
        </td>
        <td>
          5987
          -
          5994
        </td>
        <td>
          Apply
        </td>
        <td>
          java.sql.ResultSet.next
        </td>
        <td style="background: #AEF1AE">
          rs.next()
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          2697
        </td>
        <td>
          6023
          -
          6028
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #F0ADAD">
          false
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          2699
        </td>
        <td>
          5978
          -
          6030
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Try.apply
        </td>
        <td style="background: #AEF1AE">
          scala.util.Try.apply[Boolean](if (rs.next())
  rs.getBoolean(&quot;t&quot;)
else
  false)
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          2696
        </td>
        <td>
          5997
          -
          6015
        </td>
        <td>
          Block
        </td>
        <td>
          java.sql.ResultSet.getBoolean
        </td>
        <td style="background: #AEF1AE">
          rs.getBoolean(&quot;t&quot;)
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          2695
        </td>
        <td>
          5997
          -
          6015
        </td>
        <td>
          Apply
        </td>
        <td>
          java.sql.ResultSet.getBoolean
        </td>
        <td style="background: #AEF1AE">
          rs.getBoolean(&quot;t&quot;)
        </td>
      </tr><tr>
        <td>
          140
        </td>
        <td>
          2698
        </td>
        <td>
          6023
          -
          6028
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #F0ADAD">
          false
        </td>
      </tr><tr>
        <td>
          141
        </td>
        <td>
          2700
        </td>
        <td>
          6041
          -
          6051
        </td>
        <td>
          Apply
        </td>
        <td>
          java.sql.ResultSet.close
        </td>
        <td style="background: #AEF1AE">
          rs.close()
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          2703
        </td>
        <td>
          6058
          -
          6128
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.map
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.datasource.jdbc.JdbcUtils.tryJdbcToResult[Boolean](TableUtils.this.jdbcLayer, res).map[Boolean](((isTemp: Boolean) =&gt; isTemp))
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          2702
        </td>
        <td>
          6094
          -
          6103
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.util.table.TableUtils.jdbcLayer
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          2706
        </td>
        <td>
          6134
          -
          6227
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.LeftProjection.map
        </td>
        <td style="background: #AEF1AE">
          ret.left.map[com.vertica.spark.util.error.ConnectorError](((err: com.vertica.spark.util.error.ConnectorError) =&gt; com.vertica.spark.util.error.TableCheckError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;Cannot append to a temporary table&quot;)))
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          2705
        </td>
        <td>
          6154
          -
          6226
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.TableCheckError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;Cannot append to a temporary table&quot;)
        </td>
      </tr><tr>
        <td>
          149
        </td>
        <td>
          2707
        </td>
        <td>
          6325
          -
          6358
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td style="background: #AEF1AE">
          view.dbschema.getOrElse[String](&quot;public&quot;)
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          2708
        </td>
        <td>
          6375
          -
          6453
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;select count(*) from views where table_schema ILIKE ? and table_name ILIKE ?&quot;
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          2712
        </td>
        <td>
          6471
          -
          6539
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.apply[com.vertica.spark.datasource.jdbc.JdbcLayerStringParam](com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(dbschema), com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(view.name))
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          2711
        </td>
        <td>
          6507
          -
          6538
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(view.name)
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          2710
        </td>
        <td>
          6528
          -
          6537
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.config.TableName.name
        </td>
        <td style="background: #AEF1AE">
          view.name
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          2709
        </td>
        <td>
          6475
          -
          6505
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(dbschema)
        </td>
      </tr><tr>
        <td>
          153
        </td>
        <td>
          2713
        </td>
        <td>
          6545
          -
          6575
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.query
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.query(query, params)
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          2715
        </td>
        <td>
          6608
          -
          6691
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error when checking if view exists&quot;))
        </td>
      </tr><tr>
        <td>
          154
        </td>
        <td>
          2714
        </td>
        <td>
          6613
          -
          6690
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.TableCheckError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error when checking if view exists&quot;)
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          2723
        </td>
        <td>
          6740
          -
          6901
        </td>
        <td>
          If
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          if (rs.next().unary_!)
  scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.None).context(&quot;View check: empty result&quot;))
else
  scala.`package`.Right.apply[Nothing, Boolean](rs.getInt(1).&gt;=(1))
        </td>
      </tr><tr>
        <td>
          157
        </td>
        <td>
          2716
        </td>
        <td>
          6744
          -
          6754
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td style="background: #AEF1AE">
          rs.next().unary_!
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          2717
        </td>
        <td>
          6775
          -
          6832
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.TableCheckError.apply(scala.None).context(&quot;View check: empty result&quot;)
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          2719
        </td>
        <td>
          6770
          -
          6833
        </td>
        <td>
          Block
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.None).context(&quot;View check: empty result&quot;))
        </td>
      </tr><tr>
        <td>
          158
        </td>
        <td>
          2718
        </td>
        <td>
          6770
          -
          6833
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.None).context(&quot;View check: empty result&quot;))
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          2721
        </td>
        <td>
          6865
          -
          6889
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, Boolean](rs.getInt(1).&gt;=(1))
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          2720
        </td>
        <td>
          6871
          -
          6888
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;=
        </td>
        <td style="background: #AEF1AE">
          rs.getInt(1).&gt;=(1)
        </td>
      </tr><tr>
        <td>
          160
        </td>
        <td>
          2722
        </td>
        <td>
          6865
          -
          6889
        </td>
        <td>
          Block
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, Boolean](rs.getInt(1).&gt;=(1))
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          2724
        </td>
        <td>
          6963
          -
          6995
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.handleJDBCException
        </td>
        <td style="background: #F0ADAD">
          TableUtils.this.jdbcLayer.handleJDBCException(e)
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          2726
        </td>
        <td>
          7013
          -
          7034
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.TableCheckError.apply
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.TableCheckError.apply(scala.None)
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          2725
        </td>
        <td>
          7029
          -
          7033
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td style="background: #F0ADAD">
          scala.None
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          2727
        </td>
        <td>
          7008
          -
          7035
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.TableCheckError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.None))
        </td>
      </tr><tr>
        <td>
          167
        </td>
        <td>
          2729
        </td>
        <td>
          7066
          -
          7076
        </td>
        <td>
          Block
        </td>
        <td>
          java.sql.ResultSet.close
        </td>
        <td style="background: #AEF1AE">
          rs.close()
        </td>
      </tr><tr>
        <td>
          167
        </td>
        <td>
          2728
        </td>
        <td>
          7066
          -
          7076
        </td>
        <td>
          Apply
        </td>
        <td>
          java.sql.ResultSet.close
        </td>
        <td style="background: #AEF1AE">
          rs.close()
        </td>
      </tr><tr>
        <td>
          173
        </td>
        <td>
          2730
        </td>
        <td>
          7192
          -
          7226
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td style="background: #AEF1AE">
          table.dbschema.getOrElse[String](&quot;public&quot;)
        </td>
      </tr><tr>
        <td>
          174
        </td>
        <td>
          2731
        </td>
        <td>
          7243
          -
          7332
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;select count(*) from v_catalog.tables where table_schema ILIKE ? and table_name ILIKE ?&quot;
        </td>
      </tr><tr>
        <td>
          175
        </td>
        <td>
          2733
        </td>
        <td>
          7407
          -
          7417
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.config.TableName.name
        </td>
        <td style="background: #AEF1AE">
          table.name
        </td>
      </tr><tr>
        <td>
          175
        </td>
        <td>
          2732
        </td>
        <td>
          7354
          -
          7384
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(dbschema)
        </td>
      </tr><tr>
        <td>
          175
        </td>
        <td>
          2735
        </td>
        <td>
          7350
          -
          7419
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.generic.GenericCompanion.apply
        </td>
        <td style="background: #AEF1AE">
          scala.collection.Seq.apply[com.vertica.spark.datasource.jdbc.JdbcLayerStringParam](com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(dbschema), com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(table.name))
        </td>
      </tr><tr>
        <td>
          175
        </td>
        <td>
          2734
        </td>
        <td>
          7386
          -
          7418
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.datasource.jdbc.JdbcLayerStringParam.apply(table.name)
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          2736
        </td>
        <td>
          7425
          -
          7455
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.query
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.query(query, params)
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          2738
        </td>
        <td>
          7496
          -
          7580
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error when checking if table exists&quot;))
        </td>
      </tr><tr>
        <td>
          179
        </td>
        <td>
          2737
        </td>
        <td>
          7501
          -
          7579
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.TableCheckError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error when checking if table exists&quot;)
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          2739
        </td>
        <td>
          7633
          -
          7643
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td style="background: #AEF1AE">
          rs.next().unary_!
        </td>
      </tr><tr>
        <td>
          182
        </td>
        <td>
          2746
        </td>
        <td>
          7629
          -
          7791
        </td>
        <td>
          If
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          if (rs.next().unary_!)
  scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.None).context(&quot;Table check: empty result&quot;))
else
  scala.`package`.Right.apply[Nothing, Boolean](rs.getInt(1).&gt;=(1))
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          2742
        </td>
        <td>
          7659
          -
          7723
        </td>
        <td>
          Block
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.None).context(&quot;Table check: empty result&quot;))
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          2741
        </td>
        <td>
          7659
          -
          7723
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.None).context(&quot;Table check: empty result&quot;))
        </td>
      </tr><tr>
        <td>
          183
        </td>
        <td>
          2740
        </td>
        <td>
          7664
          -
          7722
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.TableCheckError.apply(scala.None).context(&quot;Table check: empty result&quot;)
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          2744
        </td>
        <td>
          7755
          -
          7779
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, Boolean](rs.getInt(1).&gt;=(1))
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          2743
        </td>
        <td>
          7761
          -
          7778
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.&gt;=
        </td>
        <td style="background: #AEF1AE">
          rs.getInt(1).&gt;=(1)
        </td>
      </tr><tr>
        <td>
          185
        </td>
        <td>
          2745
        </td>
        <td>
          7755
          -
          7779
        </td>
        <td>
          Block
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, Boolean](rs.getInt(1).&gt;=(1))
        </td>
      </tr><tr>
        <td>
          190
        </td>
        <td>
          2747
        </td>
        <td>
          7861
          -
          7893
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.handleJDBCException
        </td>
        <td style="background: #F0ADAD">
          TableUtils.this.jdbcLayer.handleJDBCException(e)
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          2748
        </td>
        <td>
          7927
          -
          7931
        </td>
        <td>
          Select
        </td>
        <td>
          scala.None
        </td>
        <td style="background: #F0ADAD">
          scala.None
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          2750
        </td>
        <td>
          7906
          -
          7933
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.TableCheckError, Nothing](com.vertica.spark.util.error.TableCheckError.apply(scala.None))
        </td>
      </tr><tr>
        <td>
          191
        </td>
        <td>
          2749
        </td>
        <td>
          7911
          -
          7932
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.TableCheckError.apply
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.TableCheckError.apply(scala.None)
        </td>
      </tr><tr>
        <td>
          194
        </td>
        <td>
          2752
        </td>
        <td>
          7972
          -
          7982
        </td>
        <td>
          Block
        </td>
        <td>
          java.sql.ResultSet.close
        </td>
        <td style="background: #AEF1AE">
          rs.close()
        </td>
      </tr><tr>
        <td>
          194
        </td>
        <td>
          2751
        </td>
        <td>
          7972
          -
          7982
        </td>
        <td>
          Apply
        </td>
        <td>
          java.sql.ResultSet.close
        </td>
        <td style="background: #AEF1AE">
          rs.close()
        </td>
      </tr><tr>
        <td>
          201
        </td>
        <td>
          2753
        </td>
        <td>
          8269
          -
          8279
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, String](sql)
        </td>
      </tr><tr>
        <td>
          203
        </td>
        <td>
          2754
        </td>
        <td>
          8307
          -
          8354
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.schema.SchemaToolsInterface.makeTableColumnDefs
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.schemaTools.makeTableColumnDefs(schema, strlen)
        </td>
      </tr><tr>
        <td>
          205
        </td>
        <td>
          2755
        </td>
        <td>
          8420
          -
          8439
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new scala.`package`.StringBuilder()
        </td>
      </tr><tr>
        <td>
          206
        </td>
        <td>
          2756
        </td>
        <td>
          8452
          -
          8487
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(&quot;CREATE EXTERNAL table &quot;)
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          2757
        </td>
        <td>
          8510
          -
          8536
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.config.TableName.getFullTableName
        </td>
        <td style="background: #AEF1AE">
          tablename.getFullTableName
        </td>
      </tr><tr>
        <td>
          207
        </td>
        <td>
          2758
        </td>
        <td>
          8500
          -
          8537
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(tablename.getFullTableName)
        </td>
      </tr><tr>
        <td>
          209
        </td>
        <td>
          2759
        </td>
        <td>
          8551
          -
          8572
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(columnDefs)
        </td>
      </tr><tr>
        <td>
          211
        </td>
        <td>
          2760
        </td>
        <td>
          8586
          -
          8614
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(&quot; AS COPY FROM \'&quot;)
        </td>
      </tr><tr>
        <td>
          212
        </td>
        <td>
          2761
        </td>
        <td>
          8627
          -
          8651
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(urlToCopyFrom)
        </td>
      </tr><tr>
        <td>
          213
        </td>
        <td>
          2762
        </td>
        <td>
          8664
          -
          8686
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.append
        </td>
        <td style="background: #AEF1AE">
          sb.append(&quot;\' PARQUET&quot;)
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          2764
        </td>
        <td>
          8699
          -
          8717
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, String](sb.toString())
        </td>
      </tr><tr>
        <td>
          214
        </td>
        <td>
          2763
        </td>
        <td>
          8705
          -
          8716
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.collection.mutable.StringBuilder.toString
        </td>
        <td style="background: #AEF1AE">
          sb.toString()
        </td>
      </tr><tr>
        <td>
          215
        </td>
        <td>
          2765
        </td>
        <td>
          8746
          -
          8755
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](err)
        </td>
      </tr><tr>
        <td>
          220
        </td>
        <td>
          2766
        </td>
        <td>
          8819
          -
          8828
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](err)
        </td>
      </tr><tr>
        <td>
          223
        </td>
        <td>
          2768
        </td>
        <td>
          8974
          -
          9047
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.CreateTableError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error creating external table&quot;)
        </td>
      </tr><tr>
        <td>
          223
        </td>
        <td>
          2767
        </td>
        <td>
          8946
          -
          8946
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute$default$2
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute$default$2
        </td>
      </tr><tr>
        <td>
          223
        </td>
        <td>
          2769
        </td>
        <td>
          8936
          -
          9048
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.LeftProjection.map
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute(st, TableUtils.this.jdbcLayer.execute$default$2).left.map[com.vertica.spark.util.error.ConnectorError](((err: com.vertica.spark.util.error.ConnectorError) =&gt; com.vertica.spark.util.error.CreateTableError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error creating external table&quot;)))
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          2771
        </td>
        <td>
          9340
          -
          9340
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.query$default$2
        </td>
        <td style="background: #F0ADAD">
          TableUtils.this.jdbcLayer.query$default$2
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          2770
        </td>
        <td>
          9346
          -
          9405
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.+
        </td>
        <td style="background: #F0ADAD">
          &quot;SELECT * FROM &quot;.+(tablename.getFullTableName).+(&quot; LIMIT 1;&quot;)
        </td>
      </tr><tr>
        <td>
          230
        </td>
        <td>
          2772
        </td>
        <td>
          9330
          -
          9406
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.query
        </td>
        <td style="background: #F0ADAD">
          TableUtils.this.jdbcLayer.query(&quot;SELECT * FROM &quot;.+(tablename.getFullTableName).+(&quot; LIMIT 1;&quot;), TableUtils.this.jdbcLayer.query$default$2)
        </td>
      </tr><tr>
        <td>
          231
        </td>
        <td>
          2773
        </td>
        <td>
          9438
          -
          9447
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, Unit](())
        </td>
      </tr><tr>
        <td>
          232
        </td>
        <td>
          2774
        </td>
        <td>
          9472
          -
          9481
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](err)
        </td>
      </tr><tr>
        <td>
          239
        </td>
        <td>
          2775
        </td>
        <td>
          9811
          -
          9821
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, String](sql)
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          2777
        </td>
        <td>
          9849
          -
          9896
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.table.TableUtils.buildCreateTableStmt
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.buildCreateTableStmt(tablename, schema, strlen, TableUtils.this.buildCreateTableStmt$default$4)
        </td>
      </tr><tr>
        <td>
          241
        </td>
        <td>
          2776
        </td>
        <td>
          9849
          -
          9849
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.util.table.TableUtils.buildCreateTableStmt$default$4
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.buildCreateTableStmt$default$4
        </td>
      </tr><tr>
        <td>
          245
        </td>
        <td>
          2778
        </td>
        <td>
          9950
          -
          9959
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](err)
        </td>
      </tr><tr>
        <td>
          248
        </td>
        <td>
          2780
        </td>
        <td>
          10096
          -
          10160
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.CreateTableError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error creating table&quot;)
        </td>
      </tr><tr>
        <td>
          248
        </td>
        <td>
          2779
        </td>
        <td>
          10068
          -
          10068
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute$default$2
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute$default$2
        </td>
      </tr><tr>
        <td>
          248
        </td>
        <td>
          2781
        </td>
        <td>
          10058
          -
          10161
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.LeftProjection.map
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute(st, TableUtils.this.jdbcLayer.execute$default$2).left.map[com.vertica.spark.util.error.ConnectorError](((err: com.vertica.spark.util.error.ConnectorError) =&gt; com.vertica.spark.util.error.CreateTableError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error creating table&quot;)))
        </td>
      </tr><tr>
        <td>
          253
        </td>
        <td>
          2784
        </td>
        <td>
          10260
          -
          10312
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.+
        </td>
        <td style="background: #AEF1AE">
          &quot;DROP TABLE IF EXISTS &quot;.+(tablename.getFullTableName)
        </td>
      </tr><tr>
        <td>
          253
        </td>
        <td>
          2783
        </td>
        <td>
          10286
          -
          10312
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.config.TableName.getFullTableName
        </td>
        <td style="background: #AEF1AE">
          tablename.getFullTableName
        </td>
      </tr><tr>
        <td>
          253
        </td>
        <td>
          2782
        </td>
        <td>
          10260
          -
          10283
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;DROP TABLE IF EXISTS &quot;
        </td>
      </tr><tr>
        <td>
          253
        </td>
        <td>
          2785
        </td>
        <td>
          10252
          -
          10252
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute$default$2
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute$default$2
        </td>
      </tr><tr>
        <td>
          254
        </td>
        <td>
          2786
        </td>
        <td>
          10337
          -
          10377
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #F0ADAD">
          err.context(&quot;JDBC Error dropping table&quot;)
        </td>
      </tr><tr>
        <td>
          254
        </td>
        <td>
          2787
        </td>
        <td>
          10242
          -
          10378
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.LeftProjection.map
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute(&quot;DROP TABLE IF EXISTS &quot;.+(tablename.getFullTableName), TableUtils.this.jdbcLayer.execute$default$2).left.map[com.vertica.spark.util.error.ConnectorError](((err: com.vertica.spark.util.error.ConnectorError) =&gt; err.context(&quot;JDBC Error dropping table&quot;)))
        </td>
      </tr><tr>
        <td>
          258
        </td>
        <td>
          2788
        </td>
        <td>
          10518
          -
          10571
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.table.TableUtils.buildCreateTableStmt
        </td>
        <td style="background: #F0ADAD">
          TableUtils.this.buildCreateTableStmt(tablename, schema, strlen, true)
        </td>
      </tr><tr>
        <td>
          261
        </td>
        <td>
          2789
        </td>
        <td>
          10685
          -
          10694
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](err)
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          2792
        </td>
        <td>
          10727
          -
          10830
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.LeftProjection.map
        </td>
        <td style="background: #F0ADAD">
          TableUtils.this.jdbcLayer.execute(st, TableUtils.this.jdbcLayer.execute$default$2).left.map[com.vertica.spark.util.error.ConnectorError](((err: com.vertica.spark.util.error.ConnectorError) =&gt; com.vertica.spark.util.error.CreateTableError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error creating table&quot;)))
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          2791
        </td>
        <td>
          10765
          -
          10829
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.CreateTableError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error creating table&quot;)
        </td>
      </tr><tr>
        <td>
          263
        </td>
        <td>
          2790
        </td>
        <td>
          10737
          -
          10737
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute$default$2
        </td>
        <td style="background: #F0ADAD">
          TableUtils.this.jdbcLayer.execute$default$2
        </td>
      </tr><tr>
        <td>
          268
        </td>
        <td>
          2793
        </td>
        <td>
          11004
          -
          11022
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.config.TableName.dbschema
        </td>
        <td style="background: #AEF1AE">
          tablename.dbschema
        </td>
      </tr><tr>
        <td>
          270
        </td>
        <td>
          2794
        </td>
        <td>
          11084
          -
          11092
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;public&quot;
        </td>
      </tr><tr>
        <td>
          273
        </td>
        <td>
          2795
        </td>
        <td>
          11116
          -
          11143
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;S2V_JOB_STATUS_USER_&quot;
        </td>
      </tr><tr>
        <td>
          273
        </td>
        <td>
          2797
        </td>
        <td>
          11116
          -
          11162
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.+
        </td>
        <td style="background: #AEF1AE">
          &quot;S2V_JOB_STATUS_USER_&quot;.+(user.toUpperCase())
        </td>
      </tr><tr>
        <td>
          273
        </td>
        <td>
          2796
        </td>
        <td>
          11146
          -
          11162
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.toUpperCase
        </td>
        <td style="background: #AEF1AE">
          user.toUpperCase()
        </td>
      </tr><tr>
        <td>
          275
        </td>
        <td>
          2798
        </td>
        <td>
          11210
          -
          11224
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[String](dbschema)
        </td>
      </tr><tr>
        <td>
          275
        </td>
        <td>
          2799
        </td>
        <td>
          11193
          -
          11225
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.config.TableName.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.config.TableName.apply(table, scala.Some.apply[String](dbschema))
        </td>
      </tr><tr>
        <td>
          285
        </td>
        <td>
          2800
        </td>
        <td>
          11317
          -
          11700
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.+
        </td>
        <td style="background: #AEF1AE">
          &quot;CREATE TABLE IF NOT EXISTS &quot;.+(jobStatusTableName.getFullTableName).+(&quot;(target_table_schema VARCHAR(128), &quot;).+(&quot;target_table_name VARCHAR(128), &quot;).+(&quot;save_mode VARCHAR(128), &quot;).+(&quot;job_name VARCHAR(256), &quot;).+(&quot;start_time TIMESTAMPTZ, &quot;).+(&quot;all_done BOOLEAN NOT NULL, &quot;).+(&quot;success BOOLEAN NOT NULL, &quot;).+(&quot;percent_failed_rows DOUBLE PRECISION)&quot;)
        </td>
      </tr><tr>
        <td>
          288
        </td>
        <td>
          2801
        </td>
        <td>
          11725
          -
          11774
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Date.toString
        </td>
        <td style="background: #AEF1AE">
          java.util.Calendar.getInstance().getTime().toString()
        </td>
      </tr><tr>
        <td>
          289
        </td>
        <td>
          2802
        </td>
        <td>
          11790
          -
          11810
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Date.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new java.util.Date()
        </td>
      </tr><tr>
        <td>
          290
        </td>
        <td>
          2804
        </td>
        <td>
          11831
          -
          11867
        </td>
        <td>
          Apply
        </td>
        <td>
          java.sql.Timestamp.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new java.sql.Timestamp(date.getTime())
        </td>
      </tr><tr>
        <td>
          290
        </td>
        <td>
          2803
        </td>
        <td>
          11854
          -
          11866
        </td>
        <td>
          Apply
        </td>
        <td>
          java.util.Date.getTime
        </td>
        <td style="background: #AEF1AE">
          date.getTime()
        </td>
      </tr><tr>
        <td>
          293
        </td>
        <td>
          2805
        </td>
        <td>
          11919
          -
          12134
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.+
        </td>
        <td style="background: #AEF1AE">
          &quot;COMMENT ON TABLE &quot;.+(jobStatusTableName.getFullTableName).+(&quot; IS \'Persistent job status table showing all jobs, serving as permanent record of data loaded from Spark to Vertica. Creation time:&quot;).+(jobStartTime).+(&quot;\'&quot;)
        </td>
      </tr><tr>
        <td>
          295
        </td>
        <td>
          2806
        </td>
        <td>
          12162
          -
          12432
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.+
        </td>
        <td style="background: #AEF1AE">
          &quot;INSERT into &quot;.+(jobStatusTableName.getFullTableName).+(&quot; VALUES (\'&quot;).+(com.vertica.spark.config.EscapeUtils.sqlEscape(dbschema, '\'')).+(&quot;\',\'&quot;).+(com.vertica.spark.config.EscapeUtils.sqlEscape(tablename.name, '\'')).+(&quot;\',\'&quot;).+(saveMode).+(&quot;\',\'&quot;).+(randJobName).+(&quot;\',\'&quot;).+(timestamp).+(&quot;\',&quot;).+(&quot;false,false,&quot;).+(-1.0.toString()).+(&quot;)&quot;)
        </td>
      </tr><tr>
        <td>
          298
        </td>
        <td>
          2825
        </td>
        <td>
          12448
          -
          12745
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.flatMap
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.tableExists(jobStatusTableName).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((tableExists: Boolean) =&gt; if (tableExists.unary_!)
  TableUtils.this.jdbcLayer.execute(createStatement, TableUtils.this.jdbcLayer.execute$default$2)
else
  scala.`package`.Right.apply[Nothing, Unit](()).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((_: Unit) =&gt; if (tableExists.unary_!)
  TableUtils.this.jdbcLayer.execute(comment, TableUtils.this.jdbcLayer.execute$default$2)
else
  scala.`package`.Right.apply[Nothing, Unit](()).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((_: Unit) =&gt; TableUtils.this.jdbcLayer.execute(insertStatement, TableUtils.this.jdbcLayer.execute$default$2).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((_: Unit) =&gt; TableUtils.this.jdbcLayer.commit().map[Unit](((_: Unit) =&gt; ()))))))))))
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          2810
        </td>
        <td>
          12535
          -
          12569
        </td>
        <td>
          Block
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute(createStatement, TableUtils.this.jdbcLayer.execute$default$2)
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          2807
        </td>
        <td>
          12521
          -
          12533
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td style="background: #AEF1AE">
          tableExists.unary_!
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          2824
        </td>
        <td>
          12513
          -
          12745
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.flatMap
        </td>
        <td style="background: #AEF1AE">
          if (tableExists.unary_!)
  TableUtils.this.jdbcLayer.execute(createStatement, TableUtils.this.jdbcLayer.execute$default$2)
else
  scala.`package`.Right.apply[Nothing, Unit](()).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((_: Unit) =&gt; if (tableExists.unary_!)
  TableUtils.this.jdbcLayer.execute(comment, TableUtils.this.jdbcLayer.execute$default$2)
else
  scala.`package`.Right.apply[Nothing, Unit](()).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((_: Unit) =&gt; TableUtils.this.jdbcLayer.execute(insertStatement, TableUtils.this.jdbcLayer.execute$default$2).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((_: Unit) =&gt; TableUtils.this.jdbcLayer.commit().map[Unit](((_: Unit) =&gt; ()))))))))
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          2809
        </td>
        <td>
          12535
          -
          12569
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute(createStatement, TableUtils.this.jdbcLayer.execute$default$2)
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          2812
        </td>
        <td>
          12575
          -
          12584
        </td>
        <td>
          Block
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, Unit](())
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          2811
        </td>
        <td>
          12575
          -
          12584
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, Unit](())
        </td>
      </tr><tr>
        <td>
          299
        </td>
        <td>
          2808
        </td>
        <td>
          12545
          -
          12545
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute$default$2
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute$default$2
        </td>
      </tr><tr>
        <td>
          300
        </td>
        <td>
          2813
        </td>
        <td>
          12599
          -
          12611
        </td>
        <td>
          Select
        </td>
        <td>
          scala.Boolean.unary_!
        </td>
        <td style="background: #AEF1AE">
          tableExists.unary_!
        </td>
      </tr><tr>
        <td>
          300
        </td>
        <td>
          2816
        </td>
        <td>
          12613
          -
          12639
        </td>
        <td>
          Block
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute(comment, TableUtils.this.jdbcLayer.execute$default$2)
        </td>
      </tr><tr>
        <td>
          300
        </td>
        <td>
          2815
        </td>
        <td>
          12613
          -
          12639
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute(comment, TableUtils.this.jdbcLayer.execute$default$2)
        </td>
      </tr><tr>
        <td>
          300
        </td>
        <td>
          2818
        </td>
        <td>
          12645
          -
          12654
        </td>
        <td>
          Block
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, Unit](())
        </td>
      </tr><tr>
        <td>
          300
        </td>
        <td>
          2814
        </td>
        <td>
          12623
          -
          12623
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute$default$2
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute$default$2
        </td>
      </tr><tr>
        <td>
          300
        </td>
        <td>
          2823
        </td>
        <td>
          12591
          -
          12745
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.flatMap
        </td>
        <td style="background: #AEF1AE">
          if (tableExists.unary_!)
  TableUtils.this.jdbcLayer.execute(comment, TableUtils.this.jdbcLayer.execute$default$2)
else
  scala.`package`.Right.apply[Nothing, Unit](()).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((_: Unit) =&gt; TableUtils.this.jdbcLayer.execute(insertStatement, TableUtils.this.jdbcLayer.execute$default$2).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((_: Unit) =&gt; TableUtils.this.jdbcLayer.commit().map[Unit](((_: Unit) =&gt; ()))))))
        </td>
      </tr><tr>
        <td>
          300
        </td>
        <td>
          2817
        </td>
        <td>
          12645
          -
          12654
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Right.apply[Nothing, Unit](())
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          2819
        </td>
        <td>
          12676
          -
          12676
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.execute$default$2
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute$default$2
        </td>
      </tr><tr>
        <td>
          301
        </td>
        <td>
          2822
        </td>
        <td>
          12661
          -
          12745
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.flatMap
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.execute(insertStatement, TableUtils.this.jdbcLayer.execute$default$2).flatMap[com.vertica.spark.util.error.ConnectorError, Unit](((_: Unit) =&gt; TableUtils.this.jdbcLayer.commit().map[Unit](((_: Unit) =&gt; ()))))
        </td>
      </tr><tr>
        <td>
          302
        </td>
        <td>
          2821
        </td>
        <td>
          12707
          -
          12745
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Either.map
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.commit().map[Unit](((_: Unit) =&gt; ()))
        </td>
      </tr><tr>
        <td>
          303
        </td>
        <td>
          2820
        </td>
        <td>
          12743
          -
          12745
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          306
        </td>
        <td>
          2826
        </td>
        <td>
          12787
          -
          12809
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.getUnderlyingError
        </td>
        <td style="background: #AEF1AE">
          err.getUnderlyingError
        </td>
      </tr><tr>
        <td>
          307
        </td>
        <td>
          2828
        </td>
        <td>
          12848
          -
          12954
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.JobStatusCreateError.apply(er).context(&quot;JDBC error when trying to initialize job status table&quot;))
        </td>
      </tr><tr>
        <td>
          308
        </td>
        <td>
          2827
        </td>
        <td>
          12853
          -
          12953
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.JobStatusCreateError.apply(er).context(&quot;JDBC error when trying to initialize job status table&quot;)
        </td>
      </tr><tr>
        <td>
          309
        </td>
        <td>
          2829
        </td>
        <td>
          12989
          -
          12998
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](err)
        </td>
      </tr><tr>
        <td>
          311
        </td>
        <td>
          2830
        </td>
        <td>
          13030
          -
          13039
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, Unit](())
        </td>
      </tr><tr>
        <td>
          316
        </td>
        <td>
          2831
        </td>
        <td>
          13237
          -
          13279
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Option.getOrElse
        </td>
        <td style="background: #AEF1AE">
          mainTableName.dbschema.getOrElse[String](&quot;public&quot;)
        </td>
      </tr><tr>
        <td>
          317
        </td>
        <td>
          2834
        </td>
        <td>
          13300
          -
          13346
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.+
        </td>
        <td style="background: #AEF1AE">
          &quot;S2V_JOB_STATUS_USER_&quot;.+(user.toUpperCase())
        </td>
      </tr><tr>
        <td>
          317
        </td>
        <td>
          2833
        </td>
        <td>
          13330
          -
          13346
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.toUpperCase
        </td>
        <td style="background: #AEF1AE">
          user.toUpperCase()
        </td>
      </tr><tr>
        <td>
          317
        </td>
        <td>
          2832
        </td>
        <td>
          13300
          -
          13327
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          &quot;S2V_JOB_STATUS_USER_&quot;
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          2836
        </td>
        <td>
          13377
          -
          13413
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.config.TableName.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.config.TableName.apply(tablename, scala.Some.apply[String](dbschema))
        </td>
      </tr><tr>
        <td>
          319
        </td>
        <td>
          2835
        </td>
        <td>
          13398
          -
          13412
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Some.apply
        </td>
        <td style="background: #AEF1AE">
          scala.Some.apply[String](dbschema)
        </td>
      </tr><tr>
        <td>
          327
        </td>
        <td>
          2837
        </td>
        <td>
          13444
          -
          13714
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.+
        </td>
        <td style="background: #AEF1AE">
          &quot;UPDATE &quot;.+(jobStatusTableName.getFullTableName).+(&quot; SET all_done=&quot;).+(true).+(&quot;,&quot;).+(&quot;success=&quot;).+(success).+(&quot;,&quot;).+(&quot;percent_failed_rows=&quot;).+(failedRowsPercent.toString()).+(&quot; &quot;).+(&quot;WHERE job_name=\'&quot;).+(sessionId).+(&quot;\' &quot;).+(&quot;AND all_done=&quot;).+(false)
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          2839
        </td>
        <td>
          13874
          -
          13916
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.executeUpdate
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.executeUpdate(updateStatusTable, TableUtils.this.jdbcLayer.executeUpdate$default$2)
        </td>
      </tr><tr>
        <td>
          331
        </td>
        <td>
          2838
        </td>
        <td>
          13884
          -
          13884
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.jdbc.JdbcLayerInterface.executeUpdate$default$2
        </td>
        <td style="background: #AEF1AE">
          TableUtils.this.jdbcLayer.executeUpdate$default$2
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          2840
        </td>
        <td>
          13954
          -
          14034
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.JobStatusUpdateError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error when updating status table&quot;)
        </td>
      </tr><tr>
        <td>
          332
        </td>
        <td>
          2841
        </td>
        <td>
          13949
          -
          14035
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.JobStatusUpdateError.apply(scala.Some.apply[com.vertica.spark.util.error.ConnectorError](err)).context(&quot;JDBC Error when updating status table&quot;))
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          2842
        </td>
        <td>
          14070
          -
          14076
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.Int.==
        </td>
        <td style="background: #AEF1AE">
          c.==(1)
        </td>
      </tr><tr>
        <td>
          334
        </td>
        <td>
          2844
        </td>
        <td>
          14078
          -
          14200
        </td>
        <td>
          Block
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          {
  (if (TableUtils.this.logger.underlying.isInfoEnabled())
    TableUtils.this.logger.underlying.info(scala.StringContext.apply(&quot;Update of &quot;).s().+(jobStatusTableName.getFullTableName).+(&quot; succeeded.&quot;))
  else
    (): Unit);
  scala.`package`.Right.apply[Nothing, Unit](())
}
        </td>
      </tr><tr>
        <td>
          336
        </td>
        <td>
          2843
        </td>
        <td>
          14181
          -
          14190
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Right.apply
        </td>
        <td style="background: #AEF1AE">
          scala.`package`.Right.apply[Nothing, Unit](())
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          2846
        </td>
        <td>
          14218
          -
          14289
        </td>
        <td>
          Apply
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.JobStatusUpdateError.apply(scala.None).context(&quot;Status_table update failed.&quot;))
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          2845
        </td>
        <td>
          14223
          -
          14288
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ConnectorError.context
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.JobStatusUpdateError.apply(scala.None).context(&quot;Status_table update failed.&quot;)
        </td>
      </tr><tr>
        <td>
          338
        </td>
        <td>
          2847
        </td>
        <td>
          14218
          -
          14289
        </td>
        <td>
          Block
        </td>
        <td>
          scala.util.Left.apply
        </td>
        <td style="background: #F0ADAD">
          scala.`package`.Left.apply[com.vertica.spark.util.error.ConnectorError, Nothing](com.vertica.spark.util.error.JobStatusUpdateError.apply(scala.None).context(&quot;Status_table update failed.&quot;))
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>