<html>
      <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
        <title id="title">
          com/vertica/spark/datasource/v2/VerticaDatasourceV2Write.scala.html
        </title>
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/css/theme.default.min.css" type="text/css"/><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.tablesorter/2.20.1/js/jquery.tablesorter.min.js"></script><link rel="stylesheet" href="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/css/bootstrap.min.css" type="text/css"/><script src="https://netdna.bootstrapcdn.com/bootstrap/3.0.3/js/bootstrap.min.js"></script><script type="text/javascript">
        $(document).ready(function() {$(".tablesorter").tablesorter();});
      </script>
        <style>
          table.codegrid { font-family: monospace; font-size: 12px; width: auto!important; }table.statementlist { width: auto!important; font-size: 13px; } table.codegrid td { padding: 0!important; border: 0!important } table td.linenumber { width: 40px!important; } 
        </style>
      </head>
      <body style="font-family: monospace;">
        <ul class="nav nav-tabs">
          <li>
            <a href="#codegrid" data-toggle="tab">Codegrid</a>
          </li>
          <li>
            <a href="#statementlist" data-toggle="tab">Statement List</a>
          </li>
        </ul>
        <div class="tab-content">
          <div class="tab-pane active" id="codegrid">
            <pre style='font-size: 12pt; font-family: courier, monospace;'>1 <span style=''>// (c) Copyright [2020-2021] Micro Focus or one of its affiliates.
</span>2 <span style=''>// Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
</span>3 <span style=''>// You may not use this file except in compliance with the License.
</span>4 <span style=''>// You may obtain a copy of the License at
</span>5 <span style=''>//
</span>6 <span style=''>// http://www.apache.org/licenses/LICENSE-2.0
</span>7 <span style=''>//
</span>8 <span style=''>// Unless required by applicable law or agreed to in writing, software
</span>9 <span style=''>// distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
</span>10 <span style=''>// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
</span>11 <span style=''>// See the License for the specific language governing permissions and
</span>12 <span style=''>// limitations under the License.
</span>13 <span style=''>
</span>14 <span style=''>package com.vertica.spark.datasource.v2
</span>15 <span style=''>
</span>16 <span style=''>import cats.data.Validated.{Invalid, Valid}
</span>17 <span style=''>import com.typesafe.scalalogging.Logger
</span>18 <span style=''>import com.vertica.spark.config.{LogProvider, WriteConfig, DistributedFilesystemWriteConfig}
</span>19 <span style=''>import com.vertica.spark.datasource.core.{DSConfigSetupInterface, DSWriter, DSWriterInterface, ExistingData, NewData}
</span>20 <span style=''>import com.vertica.spark.util.error.{ConnectorError, ErrorHandling, ErrorList}
</span>21 <span style=''>import com.vertica.spark.util.error.{NonEmptyDataFrameError, JobAbortedError}
</span>22 <span style=''>import com.vertica.spark.util.general.Utils
</span>23 <span style=''>import org.apache.spark.sql.connector.write._
</span>24 <span style=''>import org.apache.spark.sql.catalyst.InternalRow
</span>25 <span style=''>
</span>26 <span style=''>import collection.JavaConverters._
</span>27 <span style=''>
</span>28 <span style=''>object WriteSucceeded extends WriterCommitMessage
</span>29 <span style=''>object WriteFailed extends WriterCommitMessage
</span>30 <span style=''>
</span>31 <span style=''>/**
</span>32 <span style=''>  * Builds the class for use in writing to Vertica
</span>33 <span style=''>  */
</span>34 <span style=''>class VerticaWriteBuilder(info: LogicalWriteInfo, writeSetupInterface: DSConfigSetupInterface[WriteConfig]) extends WriteBuilder with SupportsTruncate {
</span>35 <span style=''>
</span>36 <span style=''>  private val logger = </span><span style='background: #AEF1AE'>LogProvider.getLogger(classOf[VerticaTable])</span><span style=''>
</span>37 <span style=''>  private val config = </span><span style='background: #AEF1AE'>writeSetupInterface.validateAndGetConfig(info.options.asScala.toMap)</span><span style=''> match {
</span>38 <span style=''>    case Invalid(errList) =&gt;
</span>39 <span style=''>      </span><span style='background: #AEF1AE'>ErrorHandling.logAndThrowError(logger, ErrorList(errList.toNonEmptyList))</span><span style=''>
</span>40 <span style=''>    case Valid(cfg) =&gt; cfg
</span>41 <span style=''>  }
</span>42 <span style=''>  logger.debug(&quot;Config loaded&quot;)
</span>43 <span style=''>
</span>44 <span style=''>/**
</span>45 <span style=''>  * Builds the class representing a write operation to a Vertica table
</span>46 <span style=''>  *
</span>47 <span style=''>  * @return [[VerticaBatchWrite]]
</span>48 <span style=''>  */
</span>49 <span style=''>  override def buildForBatch(): BatchWrite = {
</span>50 <span style=''>    </span><span style='background: #AEF1AE'>new VerticaBatchWrite(config, writeSetupInterface)</span><span style=''>
</span>51 <span style=''>  }
</span>52 <span style=''>
</span>53 <span style=''>  def truncate: WriteBuilder = {
</span>54 <span style=''>    </span><span style='background: #F0ADAD'>config.setOverwrite(true)</span><span style=''>
</span>55 <span style=''>    this
</span>56 <span style=''>  }
</span>57 <span style=''>
</span>58 <span style=''>}
</span>59 <span style=''>
</span>60 <span style=''>/**
</span>61 <span style=''>  * Represents a write operation to Vertica
</span>62 <span style=''>  *
</span>63 <span style=''>  * Extends mixin class to represent type of write. Options are Batch or Stream, we are doing a batch write.
</span>64 <span style=''>  */
</span>65 <span style=''>class VerticaBatchWrite(config: WriteConfig, writeSetupInterface: DSConfigSetupInterface[WriteConfig]) extends BatchWrite {
</span>66 <span style=''>  private val logger: Logger = </span><span style='background: #AEF1AE'>LogProvider.getLogger(classOf[VerticaBatchReader])</span><span style=''>
</span>67 <span style=''>
</span>68 <span style=''>  // Perform initial setup for the write operation
</span>69 <span style=''>  </span><span style='background: #AEF1AE'>writeSetupInterface.performInitialSetup(config)</span><span style=''> match {
</span>70 <span style=''>    case Left(err) =&gt; </span><span style='background: #AEF1AE'>ErrorHandling.logAndThrowError(logger, err)</span><span style=''>
</span>71 <span style=''>    case Right(_) =&gt; </span><span style='background: #AEF1AE'>()</span><span style=''>
</span>72 <span style=''>  }
</span>73 <span style=''>
</span>74 <span style=''>
</span>75 <span style=''>/**
</span>76 <span style=''>  * Creates the writer factory which will be serialized and sent to workers
</span>77 <span style=''>  *
</span>78 <span style=''>  * @param physicalWriteInfo Structure containing partition information.
</span>79 <span style=''>  * @return [[VerticaWriterFactory]]
</span>80 <span style=''>  */
</span>81 <span style=''>  override def createBatchWriterFactory(physicalWriteInfo: PhysicalWriteInfo): DataWriterFactory = </span><span style='background: #AEF1AE'>new VerticaWriterFactory(config)</span><span style=''>
</span>82 <span style=''>
</span>83 <span style=''>/**
</span>84 <span style=''>  * Responsible for commiting the write operation.
</span>85 <span style=''>  *
</span>86 <span style=''>  * @param writerCommitMessages list of commit messages returned from each worker node
</span>87 <span style=''>  * Called after all worker nodes report that they have succesfully completed their operations.
</span>88 <span style=''>  */
</span>89 <span style=''>  override def commit(writerCommitMessages: Array[WriterCommitMessage]): Unit = {
</span>90 <span style=''>    val writer = </span><span style='background: #F0ADAD'>new DSWriter(config, &quot;&quot;)</span><span style=''>
</span>91 <span style=''>    </span><span style='background: #F0ADAD'>writer.commitRows()</span><span style=''> match {
</span>92 <span style=''>      case Left(err) =&gt; </span><span style='background: #F0ADAD'>ErrorHandling.logAndThrowError(logger, err)</span><span style=''>
</span>93 <span style=''>      case Right(_) =&gt; </span><span style='background: #F0ADAD'>()</span><span style=''>
</span>94 <span style=''>    }
</span>95 <span style=''>  }
</span>96 <span style=''>
</span>97 <span style=''>/**
</span>98 <span style=''>  * Responsible for cleaning up a failed write operation.
</span>99 <span style=''>  *
</span>100 <span style=''>  * @param writerCommitMessages list of commit messages returned from each worker node
</span>101 <span style=''>  * Called after one or more worker nodes report that they have failed.
</span>102 <span style=''>  */
</span>103 <span style=''>  override def abort(writerCommitMessages: Array[WriterCommitMessage]): Unit = {
</span>104 <span style=''>    </span><span style='background: #AEF1AE'>ErrorHandling.logAndThrowError(logger, JobAbortedError())</span><span style=''>
</span>105 <span style=''>  }
</span>106 <span style=''>}
</span>107 <span style=''>
</span>108 <span style=''>/**
</span>109 <span style=''>  * Factory class for creating the Vertica writer
</span>110 <span style=''>  *
</span>111 <span style=''>  * This class is seriazlized and sent to each worker node. On the worker, createWriter will be called with a given unique id for the partition being written.
</span>112 <span style=''>  */
</span>113 <span style=''>class VerticaWriterFactory(config: WriteConfig) extends DataWriterFactory {
</span>114 <span style=''>
</span>115 <span style=''>/**
</span>116 <span style=''>  * Called from the worker node to get the writer for that node
</span>117 <span style=''>  *
</span>118 <span style=''>  * @param partitionId A unique identifier for the partition being written
</span>119 <span style=''>  * @param taskId A unique identifier for the specific task, which there may be multiple of for a partition due to retries or speculative execution
</span>120 <span style=''>  * @return [[VerticaBatchWriter]]
</span>121 <span style=''>  */
</span>122 <span style=''>  override def createWriter(partitionId: Int, taskId: Long): DataWriter[InternalRow] = {
</span>123 <span style=''>    val uniqueId : String = </span><span style='background: #F0ADAD'>partitionId + &quot;-&quot; + taskId</span><span style=''>
</span>124 <span style=''>    val writer = </span><span style='background: #F0ADAD'>new DSWriter(config, uniqueId)</span><span style=''>
</span>125 <span style=''>    </span><span style='background: #F0ADAD'>new VerticaBatchWriter(config, writer)</span><span style=''>
</span>126 <span style=''>  }
</span>127 <span style=''>}
</span>128 <span style=''>
</span>129 <span style=''>/**
</span>130 <span style=''>  * Writer class that passes rows to be written to the underlying datasource
</span>131 <span style=''>  */
</span>132 <span style=''>class VerticaBatchWriter(config: WriteConfig, writer: DSWriterInterface) extends DataWriter[InternalRow] {
</span>133 <span style=''>  private val logger: Logger = </span><span style='background: #AEF1AE'>LogProvider.getLogger(classOf[VerticaBatchReader])</span><span style=''>
</span>134 <span style=''>
</span>135 <span style=''>  // Construct a unique identifier string based on the partition and task IDs we've been passed for this operation
</span>136 <span style=''>
</span>137 <span style=''>  </span><span style='background: #AEF1AE'>config</span><span style=''> match {
</span>138 <span style=''>    case cfg: DistributedFilesystemWriteConfig =&gt;
</span>139 <span style=''>      </span><span style='background: #AEF1AE'>cfg.createExternalTable</span><span style=''> match {
</span>140 <span style=''>        case Some(value) =&gt;
</span>141 <span style=''>          value match {
</span>142 <span style=''>            case ExistingData =&gt; </span><span style='background: #AEF1AE'>()</span><span style=''>
</span>143 <span style=''>            case NewData =&gt;
</span>144 <span style=''>              </span><span style='background: #F0ADAD'>writer.openWrite()</span><span style=''> match {
</span>145 <span style=''>                case Right(_) =&gt; </span><span style='background: #F0ADAD'>()</span><span style=''>
</span>146 <span style=''>                case Left(err) =&gt; </span><span style='background: #F0ADAD'>ErrorHandling.logAndThrowError(logger, err)</span><span style=''>
</span>147 <span style=''>              }
</span>148 <span style=''>          }
</span>149 <span style=''>        case None =&gt;
</span>150 <span style=''>          </span><span style='background: #AEF1AE'>writer.openWrite()</span><span style=''> match {
</span>151 <span style=''>            case Right(_) =&gt; </span><span style='background: #AEF1AE'>()</span><span style=''>
</span>152 <span style=''>            case Left(err) =&gt; </span><span style='background: #AEF1AE'>ErrorHandling.logAndThrowError(logger, err)</span><span style=''>
</span>153 <span style=''>          }
</span>154 <span style=''>    }
</span>155 <span style=''>  }
</span>156 <span style=''>
</span>157 <span style=''>
</span>158 <span style=''>  /**
</span>159 <span style=''>  * Writes the row to datasource. Not permanent until a commit from the driver happens
</span>160 <span style=''>  *
</span>161 <span style=''>  * @param record The row to be written to the source.
</span>162 <span style=''>  */
</span>163 <span style=''>  override def write(record: InternalRow): Unit = {
</span>164 <span style=''>    </span><span style='background: #AEF1AE'>writer.writeRow(record)</span><span style=''> match {
</span>165 <span style=''>      case Right(_) =&gt; </span><span style='background: #AEF1AE'>()</span><span style=''>
</span>166 <span style=''>      case Left(err) =&gt; </span><span style='background: #AEF1AE'>ErrorHandling.logAndThrowError(logger, err)</span><span style=''>
</span>167 <span style=''>    }
</span>168 <span style=''>  }
</span>169 <span style=''>
</span>170 <span style=''>/**
</span>171 <span style=''>  * Initiates final stages of writing for a sucessful write of this partition. This does not act as a final commit as that will be done by [[VerticaBatchWrite.commit]] from the driver.
</span>172 <span style=''>  *
</span>173 <span style=''>  * @return org.apache.spark.sql.connector.write.WriterCommitMessage
</span>174 <span style=''>  */
</span>175 <span style=''>  override def commit(): WriterCommitMessage = {
</span>176 <span style=''>    </span><span style='background: #AEF1AE'>writer.closeWrite()</span><span style=''> match {
</span>177 <span style=''>      case Left(err) =&gt; </span><span style='background: #AEF1AE'>ErrorHandling.logAndThrowError(logger, err)</span><span style=''>
</span>178 <span style=''>      case Right(_) =&gt; WriteSucceeded
</span>179 <span style=''>    }
</span>180 <span style=''>  }
</span>181 <span style=''>
</span>182 <span style=''>/**
</span>183 <span style=''>  * Initiates final stages of writing for a failed write of this partition.
</span>184 <span style=''>  */
</span>185 <span style=''>  override def abort(): Unit = {
</span>186 <span style=''>    // Ignore the error here because the error that caused the abort is more relevant
</span>187 <span style=''>    </span><span style='background: #AEF1AE'>Utils.ignore(writer.closeWrite())</span><span style=''>
</span>188 <span style=''>  }
</span>189 <span style=''>
</span>190 <span style=''>/**
</span>191 <span style=''>  * Called when all rows have been written.
</span>192 <span style=''>  *
</span>193 <span style=''>  * Calls any necessary cleanup. Called after commit or abort.
</span>194 <span style=''>  */
</span>195 <span style=''>  override def close(): Unit = </span><span style='background: #AEF1AE'>{}</span><span style=''>
</span>196 <span style=''>}
</span></pre>
          </div>
          <div class="tab-pane" id="statementlist">
            <table cellspacing="0" cellpadding="0" class="table statementlist">
      <tr>
        <th>Line</th>
        <th>Stmt Id</th>
        <th>Pos</th>
        <th>Tree</th>
        <th>Symbol</th>
        <th>Code</th>
      </tr><tr>
        <td>
          36
        </td>
        <td>
          1776
        </td>
        <td>
          1623
          -
          1667
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.config.LogProvider.getLogger
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.config.LogProvider.getLogger(classOf[com.vertica.spark.datasource.v2.VerticaTable])
        </td>
      </tr><tr>
        <td>
          37
        </td>
        <td>
          1779
        </td>
        <td>
          1732
          -
          1758
        </td>
        <td>
          ApplyToImplicitArgs
        </td>
        <td>
          scala.collection.TraversableOnce.toMap
        </td>
        <td style="background: #AEF1AE">
          scala.collection.JavaConverters.mapAsScalaMapConverter[String, String](VerticaWriteBuilder.this.info.options()).asScala.toMap[String, String](scala.Predef.$conforms[(String, String)])
        </td>
      </tr><tr>
        <td>
          37
        </td>
        <td>
          1778
        </td>
        <td>
          1753
          -
          1753
        </td>
        <td>
          TypeApply
        </td>
        <td>
          scala.Predef.$conforms
        </td>
        <td style="background: #AEF1AE">
          scala.Predef.$conforms[(String, String)]
        </td>
      </tr><tr>
        <td>
          37
        </td>
        <td>
          1777
        </td>
        <td>
          1732
          -
          1744
        </td>
        <td>
          Apply
        </td>
        <td>
          org.apache.spark.sql.connector.write.LogicalWriteInfo.options
        </td>
        <td style="background: #AEF1AE">
          VerticaWriteBuilder.this.info.options()
        </td>
      </tr><tr>
        <td>
          37
        </td>
        <td>
          1780
        </td>
        <td>
          1691
          -
          1759
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSConfigSetupInterface.validateAndGetConfig
        </td>
        <td style="background: #AEF1AE">
          VerticaWriteBuilder.this.writeSetupInterface.validateAndGetConfig(scala.collection.JavaConverters.mapAsScalaMapConverter[String, String](VerticaWriteBuilder.this.info.options()).asScala.toMap[String, String](scala.Predef.$conforms[(String, String)]))
        </td>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          1782
        </td>
        <td>
          1852
          -
          1874
        </td>
        <td>
          Select
        </td>
        <td>
          cats.data.NonEmptyChainOps.toNonEmptyList
        </td>
        <td style="background: #AEF1AE">
          data.this.NonEmptyChainImpl.catsNonEmptyChainOps[com.vertica.spark.util.error.ConnectorError](errList).toNonEmptyList
        </td>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          1781
        </td>
        <td>
          1834
          -
          1840
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaWriteBuilder.logger
        </td>
        <td style="background: #AEF1AE">
          VerticaWriteBuilder.this.logger
        </td>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          1784
        </td>
        <td>
          1803
          -
          1876
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError(VerticaWriteBuilder.this.logger, com.vertica.spark.util.error.ErrorList.apply(data.this.NonEmptyChainImpl.catsNonEmptyChainOps[com.vertica.spark.util.error.ConnectorError](errList).toNonEmptyList))
        </td>
      </tr><tr>
        <td>
          39
        </td>
        <td>
          1783
        </td>
        <td>
          1842
          -
          1875
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ErrorList.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.ErrorList.apply(data.this.NonEmptyChainImpl.catsNonEmptyChainOps[com.vertica.spark.util.error.ConnectorError](errList).toNonEmptyList)
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          1787
        </td>
        <td>
          2110
          -
          2160
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWrite.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new VerticaBatchWrite(VerticaWriteBuilder.this.config, VerticaWriteBuilder.this.writeSetupInterface)
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          1786
        </td>
        <td>
          2140
          -
          2159
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaWriteBuilder.writeSetupInterface
        </td>
        <td style="background: #AEF1AE">
          VerticaWriteBuilder.this.writeSetupInterface
        </td>
      </tr><tr>
        <td>
          50
        </td>
        <td>
          1785
        </td>
        <td>
          2132
          -
          2138
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaWriteBuilder.config
        </td>
        <td style="background: #AEF1AE">
          VerticaWriteBuilder.this.config
        </td>
      </tr><tr>
        <td>
          54
        </td>
        <td>
          1788
        </td>
        <td>
          2203
          -
          2228
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.config.WriteConfig.setOverwrite
        </td>
        <td style="background: #F0ADAD">
          VerticaWriteBuilder.this.config.setOverwrite(true)
        </td>
      </tr><tr>
        <td>
          66
        </td>
        <td>
          1789
        </td>
        <td>
          2567
          -
          2617
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.config.LogProvider.getLogger
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.config.LogProvider.getLogger(classOf[com.vertica.spark.datasource.v2.VerticaBatchReader])
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          1791
        </td>
        <td>
          2672
          -
          2719
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSConfigSetupInterface.performInitialSetup
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWrite.this.writeSetupInterface.performInitialSetup(VerticaBatchWrite.this.config)
        </td>
      </tr><tr>
        <td>
          69
        </td>
        <td>
          1790
        </td>
        <td>
          2712
          -
          2718
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWrite.config
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWrite.this.config
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          1793
        </td>
        <td>
          2750
          -
          2793
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError(VerticaBatchWrite.this.logger, err)
        </td>
      </tr><tr>
        <td>
          70
        </td>
        <td>
          1792
        </td>
        <td>
          2781
          -
          2787
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWrite.logger
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWrite.this.logger
        </td>
      </tr><tr>
        <td>
          71
        </td>
        <td>
          1794
        </td>
        <td>
          2815
          -
          2817
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          1796
        </td>
        <td>
          3122
          -
          3154
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaWriterFactory.&lt;init&gt;
        </td>
        <td style="background: #AEF1AE">
          new VerticaWriterFactory(VerticaBatchWrite.this.config)
        </td>
      </tr><tr>
        <td>
          81
        </td>
        <td>
          1795
        </td>
        <td>
          3147
          -
          3153
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWrite.config
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWrite.this.config
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          1797
        </td>
        <td>
          3515
          -
          3521
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWrite.config
        </td>
        <td style="background: #F0ADAD">
          VerticaBatchWrite.this.config
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          1799
        </td>
        <td>
          3502
          -
          3502
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriter.&lt;init&gt;$default$3
        </td>
        <td style="background: #F0ADAD">
          core.this.DSWriter.&lt;init&gt;$default$3
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          1798
        </td>
        <td>
          3523
          -
          3525
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #F0ADAD">
          &quot;&quot;
        </td>
      </tr><tr>
        <td>
          90
        </td>
        <td>
          1800
        </td>
        <td>
          3502
          -
          3526
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriter.&lt;init&gt;
        </td>
        <td style="background: #F0ADAD">
          new com.vertica.spark.datasource.core.DSWriter(VerticaBatchWrite.this.config, &quot;&quot;, core.this.DSWriter.&lt;init&gt;$default$3)
        </td>
      </tr><tr>
        <td>
          91
        </td>
        <td>
          1801
        </td>
        <td>
          3531
          -
          3550
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriter.commitRows
        </td>
        <td style="background: #F0ADAD">
          writer.commitRows()
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          1802
        </td>
        <td>
          3614
          -
          3620
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWrite.logger
        </td>
        <td style="background: #F0ADAD">
          VerticaBatchWrite.this.logger
        </td>
      </tr><tr>
        <td>
          92
        </td>
        <td>
          1803
        </td>
        <td>
          3583
          -
          3626
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError(VerticaBatchWrite.this.logger, err)
        </td>
      </tr><tr>
        <td>
          93
        </td>
        <td>
          1804
        </td>
        <td>
          3650
          -
          3652
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          1806
        </td>
        <td>
          4018
          -
          4035
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.JobAbortedError.apply
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.JobAbortedError.apply()
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          1805
        </td>
        <td>
          4010
          -
          4016
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWrite.logger
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWrite.this.logger
        </td>
      </tr><tr>
        <td>
          104
        </td>
        <td>
          1807
        </td>
        <td>
          3979
          -
          4036
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError(VerticaBatchWrite.this.logger, com.vertica.spark.util.error.JobAbortedError.apply())
        </td>
      </tr><tr>
        <td>
          123
        </td>
        <td>
          1808
        </td>
        <td>
          4795
          -
          4821
        </td>
        <td>
          Apply
        </td>
        <td>
          java.lang.String.+
        </td>
        <td style="background: #F0ADAD">
          partitionId.+(&quot;-&quot;).+(taskId)
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          1811
        </td>
        <td>
          4839
          -
          4869
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriter.&lt;init&gt;
        </td>
        <td style="background: #F0ADAD">
          new com.vertica.spark.datasource.core.DSWriter(VerticaWriterFactory.this.config, uniqueId, core.this.DSWriter.&lt;init&gt;$default$3)
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          1810
        </td>
        <td>
          4839
          -
          4839
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriter.&lt;init&gt;$default$3
        </td>
        <td style="background: #F0ADAD">
          core.this.DSWriter.&lt;init&gt;$default$3
        </td>
      </tr><tr>
        <td>
          124
        </td>
        <td>
          1809
        </td>
        <td>
          4852
          -
          4858
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaWriterFactory.config
        </td>
        <td style="background: #F0ADAD">
          VerticaWriterFactory.this.config
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          1813
        </td>
        <td>
          4874
          -
          4912
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWriter.&lt;init&gt;
        </td>
        <td style="background: #F0ADAD">
          new VerticaBatchWriter(VerticaWriterFactory.this.config, writer)
        </td>
      </tr><tr>
        <td>
          125
        </td>
        <td>
          1812
        </td>
        <td>
          4897
          -
          4903
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaWriterFactory.config
        </td>
        <td style="background: #F0ADAD">
          VerticaWriterFactory.this.config
        </td>
      </tr><tr>
        <td>
          133
        </td>
        <td>
          1814
        </td>
        <td>
          5144
          -
          5194
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.config.LogProvider.getLogger
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.config.LogProvider.getLogger(classOf[com.vertica.spark.datasource.v2.VerticaBatchReader])
        </td>
      </tr><tr>
        <td>
          137
        </td>
        <td>
          1815
        </td>
        <td>
          5314
          -
          5320
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWriter.config
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWriter.this.config
        </td>
      </tr><tr>
        <td>
          139
        </td>
        <td>
          1816
        </td>
        <td>
          5385
          -
          5408
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.config.DistributedFilesystemWriteConfig.createExternalTable
        </td>
        <td style="background: #AEF1AE">
          cfg.createExternalTable
        </td>
      </tr><tr>
        <td>
          142
        </td>
        <td>
          1817
        </td>
        <td>
          5502
          -
          5504
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          144
        </td>
        <td>
          1818
        </td>
        <td>
          5547
          -
          5565
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriterInterface.openWrite
        </td>
        <td style="background: #F0ADAD">
          VerticaBatchWriter.this.writer.openWrite()
        </td>
      </tr><tr>
        <td>
          145
        </td>
        <td>
          1819
        </td>
        <td>
          5607
          -
          5609
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #F0ADAD">
          ()
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          1820
        </td>
        <td>
          5675
          -
          5681
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWriter.logger
        </td>
        <td style="background: #F0ADAD">
          VerticaBatchWriter.this.logger
        </td>
      </tr><tr>
        <td>
          146
        </td>
        <td>
          1821
        </td>
        <td>
          5644
          -
          5687
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError
        </td>
        <td style="background: #F0ADAD">
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError(VerticaBatchWriter.this.logger, err)
        </td>
      </tr><tr>
        <td>
          150
        </td>
        <td>
          1822
        </td>
        <td>
          5747
          -
          5765
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriterInterface.openWrite
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWriter.this.writer.openWrite()
        </td>
      </tr><tr>
        <td>
          151
        </td>
        <td>
          1823
        </td>
        <td>
          5803
          -
          5805
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          152
        </td>
        <td>
          1824
        </td>
        <td>
          5867
          -
          5873
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWriter.logger
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWriter.this.logger
        </td>
      </tr><tr>
        <td>
          152
        </td>
        <td>
          1825
        </td>
        <td>
          5836
          -
          5879
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError(VerticaBatchWriter.this.logger, err)
        </td>
      </tr><tr>
        <td>
          164
        </td>
        <td>
          1826
        </td>
        <td>
          6117
          -
          6140
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriterInterface.writeRow
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWriter.this.writer.writeRow(record)
        </td>
      </tr><tr>
        <td>
          165
        </td>
        <td>
          1827
        </td>
        <td>
          6172
          -
          6174
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          1829
        </td>
        <td>
          6199
          -
          6242
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError(VerticaBatchWriter.this.logger, err)
        </td>
      </tr><tr>
        <td>
          166
        </td>
        <td>
          1828
        </td>
        <td>
          6230
          -
          6236
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWriter.logger
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWriter.this.logger
        </td>
      </tr><tr>
        <td>
          176
        </td>
        <td>
          1830
        </td>
        <td>
          6574
          -
          6593
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriterInterface.closeWrite
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWriter.this.writer.closeWrite()
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          1832
        </td>
        <td>
          6626
          -
          6669
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.error.ErrorHandling.logAndThrowError(VerticaBatchWriter.this.logger, err)
        </td>
      </tr><tr>
        <td>
          177
        </td>
        <td>
          1831
        </td>
        <td>
          6657
          -
          6663
        </td>
        <td>
          Select
        </td>
        <td>
          com.vertica.spark.datasource.v2.VerticaBatchWriter.logger
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWriter.this.logger
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          1833
        </td>
        <td>
          6940
          -
          6959
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.datasource.core.DSWriterInterface.closeWrite
        </td>
        <td style="background: #AEF1AE">
          VerticaBatchWriter.this.writer.closeWrite()
        </td>
      </tr><tr>
        <td>
          187
        </td>
        <td>
          1834
        </td>
        <td>
          6927
          -
          6960
        </td>
        <td>
          Apply
        </td>
        <td>
          com.vertica.spark.util.general.Utils.ignore
        </td>
        <td style="background: #AEF1AE">
          com.vertica.spark.util.general.Utils.ignore[com.vertica.spark.util.error.ErrorHandling.ConnectorResult[Unit]](VerticaBatchWriter.this.writer.closeWrite())
        </td>
      </tr><tr>
        <td>
          195
        </td>
        <td>
          1835
        </td>
        <td>
          7117
          -
          7119
        </td>
        <td>
          Literal
        </td>
        <td>
          &lt;nosymbol&gt;
        </td>
        <td style="background: #AEF1AE">
          ()
        </td>
      </tr>
    </table>
          </div>
        </div>
      </body>
    </html>