[info] welcome to sbt 1.4.1 (AdoptOpenJDK Java 1.8.0_265)
[info] loading global plugins from /Users/alexrehnbymartin/.sbt/1.0/plugins
[info] loading project definition from /Users/alexrehnbymartin/dev/spark-connector/examples/basic-write/project
[info] loading settings for project basic-write from build.sbt ...
[info] set current project to spark-vertica-connector-functional-tests (in build file:/Users/alexrehnbymartin/dev/spark-connector/examples/basic-write/)
[info] running example.Main 
13:33:16.646 [run-main-0] INFO org.apache.spark.SparkContext - Running Spark version 3.0.0
13:33:16.693 [run-main-0] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
13:33:16.699 [run-main-0] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
13:33:16.699 [run-main-0] DEBUG org.apache.hadoop.metrics2.lib.MutableMetricsFactory - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.getGroups with annotation @org.apache.hadoop.metrics2.annotation.Metric(sampleName=Ops, always=false, about=, type=DEFAULT, valueName=Time, value=[GetGroups])
13:33:16.700 [run-main-0] DEBUG org.apache.hadoop.metrics2.impl.MetricsSystemImpl - UgiMetrics, User and group related metrics
13:33:16.925 [run-main-0] DEBUG org.apache.hadoop.util.Shell - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:329)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:354)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:80)
	at org.apache.hadoop.security.SecurityUtil.getAuthenticationMethod(SecurityUtil.java:611)
	at org.apache.hadoop.security.UserGroupInformation.initialize(UserGroupInformation.java:274)
	at org.apache.hadoop.security.UserGroupInformation.ensureInitialized(UserGroupInformation.java:262)
	at org.apache.hadoop.security.UserGroupInformation.loginUserFromSubject(UserGroupInformation.java:807)
	at org.apache.hadoop.security.UserGroupInformation.getLoginUser(UserGroupInformation.java:777)
	at org.apache.hadoop.security.UserGroupInformation.getCurrentUser(UserGroupInformation.java:650)
	at org.apache.spark.util.Utils$.$anonfun$getCurrentUserName$1(Utils.scala:2412)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.util.Utils$.getCurrentUserName(Utils.scala:2412)
	at org.apache.spark.SparkContext.<init>(SparkContext.scala:303)
	at org.apache.spark.SparkContext$.getOrCreate(SparkContext.scala:2555)
	at org.apache.spark.sql.SparkSession$Builder.$anonfun$getOrCreate$1(SparkSession.scala:930)
	at scala.Option.getOrElse(Option.scala:189)
	at org.apache.spark.sql.SparkSession$Builder.getOrCreate(SparkSession.scala:921)
	at example.Main$.delayedEndpoint$example$Main$1(Main.scala:37)
	at example.Main$delayedInit$body.apply(Main.scala:23)
	at scala.Function0.apply$mcV$sp(Function0.scala:39)
	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
	at scala.App.$anonfun$main$1$adapted(App.scala:80)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at scala.App.main(App.scala:80)
	at scala.App.main$(App.scala:78)
	at example.Main$.main(Main.scala:23)
	at example.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sbt.Run.invokeMain(Run.scala:133)
	at sbt.Run.execute$1(Run.scala:82)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:110)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at sbt.util.InterfaceUtil$$anon$1.get(InterfaceUtil.scala:17)
	at sbt.TrapExit$App.run(TrapExit.scala:258)
	at java.lang.Thread.run(Thread.java:748)
13:33:16.932 [run-main-0] DEBUG org.apache.hadoop.util.Shell - setsid is not available on this machine. So not using it.
13:33:16.932 [run-main-0] DEBUG org.apache.hadoop.util.Shell - setsid exited with exit code 0
13:33:16.944 [run-main-0] DEBUG org.apache.hadoop.security.authentication.util.KerberosName - Kerberos krb5 configuration not found, setting default realm to empty
13:33:16.950 [run-main-0] DEBUG org.apache.hadoop.security.Groups -  Creating new Groups object
13:33:16.951 [run-main-0] DEBUG org.apache.hadoop.util.NativeCodeLoader - Trying to load the custom-built native-hadoop library...
13:33:16.952 [run-main-0] DEBUG org.apache.hadoop.util.NativeCodeLoader - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
13:33:16.953 [run-main-0] DEBUG org.apache.hadoop.util.NativeCodeLoader - java.library.path=/Users/alexrehnbymartin/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
13:33:16.954 [run-main-0] WARN org.apache.hadoop.util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
13:33:16.954 [run-main-0] DEBUG org.apache.hadoop.util.PerformanceAdvisory - Falling back to shell based
13:33:16.954 [run-main-0] DEBUG org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
13:33:16.997 [run-main-0] DEBUG org.apache.hadoop.security.Groups - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000; warningDeltaMs=5000
13:33:17.002 [run-main-0] DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login
13:33:17.003 [run-main-0] DEBUG org.apache.hadoop.security.UserGroupInformation - hadoop login commit
13:33:17.006 [run-main-0] DEBUG org.apache.hadoop.security.UserGroupInformation - using local user:UnixPrincipal: alexrehnbymartin
13:33:17.006 [run-main-0] DEBUG org.apache.hadoop.security.UserGroupInformation - Using user: "UnixPrincipal: alexrehnbymartin" with name alexrehnbymartin
13:33:17.006 [run-main-0] DEBUG org.apache.hadoop.security.UserGroupInformation - User entry: "alexrehnbymartin"
13:33:17.006 [run-main-0] DEBUG org.apache.hadoop.security.UserGroupInformation - Assuming keytab is managed externally since logged in from subject.
13:33:17.006 [run-main-0] DEBUG org.apache.hadoop.security.UserGroupInformation - UGI loginUser:alexrehnbymartin (auth:SIMPLE)
13:33:17.019 [run-main-0] INFO org.apache.spark.resource.ResourceUtils - ==============================================================
13:33:17.020 [run-main-0] INFO org.apache.spark.resource.ResourceUtils - Resources for spark.driver:

13:33:17.020 [run-main-0] INFO org.apache.spark.resource.ResourceUtils - ==============================================================
13:33:17.020 [run-main-0] INFO org.apache.spark.SparkContext - Submitted application: Vertica Connector Test Prototype
13:33:17.060 [run-main-0] INFO org.apache.spark.SecurityManager - Changing view acls to: alexrehnbymartin
13:33:17.060 [run-main-0] INFO org.apache.spark.SecurityManager - Changing modify acls to: alexrehnbymartin
13:33:17.060 [run-main-0] INFO org.apache.spark.SecurityManager - Changing view acls groups to: 
13:33:17.061 [run-main-0] INFO org.apache.spark.SecurityManager - Changing modify acls groups to: 
13:33:17.061 [run-main-0] INFO org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(alexrehnbymartin); groups with view permissions: Set(); users  with modify permissions: Set(alexrehnbymartin); groups with modify permissions: Set()
13:33:17.136 [run-main-0] DEBUG io.netty.util.internal.logging.InternalLoggerFactory - Using SLF4J as the default logging framework
13:33:17.137 [run-main-0] DEBUG io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.initialSize: 1024
13:33:17.137 [run-main-0] DEBUG io.netty.util.internal.InternalThreadLocalMap - -Dio.netty.threadLocalMap.stringBuilder.maxSize: 4096
13:33:17.146 [run-main-0] DEBUG io.netty.channel.MultithreadEventLoopGroup - -Dio.netty.eventLoopThreads: 32
13:33:17.160 [run-main-0] DEBUG io.netty.channel.nio.NioEventLoop - -Dio.netty.noKeySetOptimization: false
13:33:17.160 [run-main-0] DEBUG io.netty.channel.nio.NioEventLoop - -Dio.netty.selectorAutoRebuildThreshold: 512
13:33:17.172 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent - Platform: MacOS
13:33:17.173 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent0 - -Dio.netty.noUnsafe: false
13:33:17.173 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent0 - Java version: 8
13:33:17.174 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.theUnsafe: available
13:33:17.174 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent0 - sun.misc.Unsafe.copyMemory: available
13:33:17.174 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent0 - java.nio.Buffer.address: available
13:33:17.174 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent0 - direct buffer constructor: available
13:33:17.175 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent0 - java.nio.Bits.unaligned: available, true
13:33:17.175 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent0 - jdk.internal.misc.Unsafe.allocateUninitializedArray(int): unavailable prior to Java9
13:33:17.175 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent0 - java.nio.DirectByteBuffer.<init>(long, int): available
13:33:17.175 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent - sun.misc.Unsafe: available
13:33:17.175 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent - -Dio.netty.tmpdir: /var/folders/qc/3jl77x7x5p7b_n53kxh549300000gp/T (java.io.tmpdir)
13:33:17.175 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent - -Dio.netty.bitMode: 64 (sun.arch.data.model)
13:33:17.176 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent - -Dio.netty.maxDirectMemory: 1029177344 bytes
13:33:17.176 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent - -Dio.netty.uninitializedArrayAllocationThreshold: -1
13:33:17.177 [run-main-0] DEBUG io.netty.util.internal.CleanerJava6 - java.nio.ByteBuffer.cleaner(): available
13:33:17.177 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent - -Dio.netty.noPreferDirect: false
13:33:17.182 [run-main-0] DEBUG io.netty.util.internal.PlatformDependent - org.jctools-core.MpscChunkedArrayQueue: available
13:33:17.195 [run-main-0] DEBUG io.netty.util.ResourceLeakDetector - -Dio.netty.leakDetection.level: simple
13:33:17.195 [run-main-0] DEBUG io.netty.util.ResourceLeakDetector - -Dio.netty.leakDetection.targetRecords: 4
13:33:17.196 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numHeapArenas: 10
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.numDirectArenas: 10
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.pageSize: 8192
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxOrder: 11
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.chunkSize: 16777216
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.tinyCacheSize: 512
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.smallCacheSize: 256
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.normalCacheSize: 64
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimInterval: 8192
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.cacheTrimIntervalMillis: 0
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.useCacheForAllThreads: true
13:33:17.197 [run-main-0] DEBUG io.netty.buffer.PooledByteBufAllocator - -Dio.netty.allocator.maxCachedByteBuffersPerChunk: 1023
13:33:22.220 [run-main-0] DEBUG io.netty.channel.DefaultChannelId - -Dio.netty.processId: 95947 (auto-detected)
13:33:22.226 [run-main-0] DEBUG io.netty.util.NetUtil - -Djava.net.preferIPv4Stack: false
13:33:22.226 [run-main-0] DEBUG io.netty.util.NetUtil - -Djava.net.preferIPv6Addresses: false
13:33:22.231 [run-main-0] DEBUG io.netty.util.NetUtil - Loopback interface: lo0 (lo0, 0:0:0:0:0:0:0:1%lo0)
13:33:22.232 [run-main-0] DEBUG io.netty.util.NetUtil - Failed to get SOMAXCONN from sysctl and file /proc/sys/net/core/somaxconn. Default: 128
13:33:22.234 [run-main-0] DEBUG io.netty.channel.DefaultChannelId - -Dio.netty.machineId: 14:7d:da:ff:fe:44:17:15 (auto-detected)
13:33:22.265 [run-main-0] DEBUG io.netty.buffer.ByteBufUtil - -Dio.netty.allocator.type: pooled
13:33:22.265 [run-main-0] DEBUG io.netty.buffer.ByteBufUtil - -Dio.netty.threadLocalDirectBufferSize: 0
13:33:22.265 [run-main-0] DEBUG io.netty.buffer.ByteBufUtil - -Dio.netty.maxThreadLocalCharBufferSize: 16384
13:33:22.280 [run-main-0] DEBUG org.apache.spark.network.server.TransportServer - Shuffle server started on port: 54330
13:33:22.290 [run-main-0] INFO org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 54330.
13:33:22.290 [run-main-0] DEBUG org.apache.spark.SparkEnv - Using serializer: class org.apache.spark.serializer.JavaSerializer
13:33:22.314 [run-main-0] INFO org.apache.spark.SparkEnv - Registering MapOutputTracker
13:33:22.314 [run-main-0] DEBUG org.apache.spark.MapOutputTrackerMasterEndpoint - init
13:33:22.329 [run-main-0] INFO org.apache.spark.SparkEnv - Registering BlockManagerMaster
13:33:22.344 [run-main-0] INFO org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
13:33:22.344 [run-main-0] INFO org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
13:33:22.347 [run-main-0] INFO org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
13:33:22.358 [run-main-0] INFO org.apache.spark.storage.DiskBlockManager - Created local directory at /private/var/folders/qc/3jl77x7x5p7b_n53kxh549300000gp/T/blockmgr-9e01f7f2-b214-4c5c-8215-12fbf02cfee1
13:33:22.359 [run-main-0] DEBUG org.apache.spark.storage.DiskBlockManager - Adding shutdown hook
13:33:22.360 [run-main-0] DEBUG org.apache.spark.util.ShutdownHookManager - Adding shutdown hook
13:33:22.371 [run-main-0] INFO org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 417.9 MiB
13:33:22.383 [run-main-0] INFO org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
13:33:22.384 [run-main-0] DEBUG org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - init
13:33:22.393 [run-main-0] DEBUG org.apache.spark.SecurityManager - Created SSL options for ui: SSLOptions{enabled=false, port=None, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
13:33:22.455 [run-main-0] DEBUG org.sparkproject.jetty.util.log - Logging to Logger[org.sparkproject.jetty.util.log] via org.sparkproject.jetty.util.log.Slf4jLog
13:33:22.457 [run-main-0] INFO org.sparkproject.jetty.util.log - Logging initialized @27328ms to org.sparkproject.jetty.util.log.Slf4jLog
13:33:22.466 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@2088b1f1
13:33:22.472 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@6ec1f6cb{/,null,UNAVAILABLE} added {ServletHandler@77b65561{STOPPED},MANAGED}
13:33:22.478 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@58624ebc
13:33:22.479 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@20993309{/,null,UNAVAILABLE} added {ServletHandler@5b54ca69{STOPPED},MANAGED}
13:33:22.480 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@368e14d5
13:33:22.480 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@34f9bf66{/,null,UNAVAILABLE} added {ServletHandler@3f7eee1{STOPPED},MANAGED}
13:33:22.480 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@6cfe2ee3
13:33:22.480 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@1585ae95{/,null,UNAVAILABLE} added {ServletHandler@29b9ca22{STOPPED},MANAGED}
13:33:22.487 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@26ff9595
13:33:22.487 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@576a576a{/,null,UNAVAILABLE} added {ServletHandler@1fc99fa5{STOPPED},MANAGED}
13:33:22.487 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@2f8c92c3
13:33:22.488 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@2ad8515f{/,null,UNAVAILABLE} added {ServletHandler@793fd716{STOPPED},MANAGED}
13:33:22.488 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@1d1315
13:33:22.488 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@79df367{/,null,UNAVAILABLE} added {ServletHandler@17756aa5{STOPPED},MANAGED}
13:33:22.488 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@28c70b4a
13:33:22.488 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@4029d3fe{/,null,UNAVAILABLE} added {ServletHandler@7c35b91c{STOPPED},MANAGED}
13:33:22.488 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@73d40713
13:33:22.488 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@22f8bd2c{/,null,UNAVAILABLE} added {ServletHandler@45c8581b{STOPPED},MANAGED}
13:33:22.489 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@fe9aa52
13:33:22.489 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@681f775e{/,null,UNAVAILABLE} added {ServletHandler@6f10f2c6{STOPPED},MANAGED}
13:33:22.492 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@3342ed85
13:33:22.492 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@344240e1{/,null,UNAVAILABLE} added {ServletHandler@277ab3a5{STOPPED},MANAGED}
13:33:22.492 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@1e119c31
13:33:22.492 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@3872925a{/,null,UNAVAILABLE} added {ServletHandler@4ae7e96a{STOPPED},MANAGED}
13:33:22.492 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@15325e15
13:33:22.492 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@60eb4960{/,null,UNAVAILABLE} added {ServletHandler@2b6f2033{STOPPED},MANAGED}
13:33:22.492 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@6243c1c4
13:33:22.492 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@58d924a5{/,null,UNAVAILABLE} added {ServletHandler@a65f935{STOPPED},MANAGED}
13:33:22.494 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@237fa6c4
13:33:22.494 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@6151a2c2{/,null,UNAVAILABLE} added {ServletHandler@5d4d16c5{STOPPED},MANAGED}
13:33:22.494 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@55fb47c5
13:33:22.494 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@39d0b80a{/,null,UNAVAILABLE} added {ServletHandler@c1e7acb{STOPPED},MANAGED}
13:33:22.495 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@375dcda
13:33:22.496 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@35d5d01b{/,null,UNAVAILABLE} added {ServletHandler@2476ef5d{STOPPED},MANAGED}
13:33:22.496 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@57063d32
13:33:22.496 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@4cc86ac1{/,null,UNAVAILABLE} added {ServletHandler@5f577802{STOPPED},MANAGED}
13:33:22.496 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@9a52183
13:33:22.496 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@6dd6dfdd{/,null,UNAVAILABLE} added {ServletHandler@617c87ea{STOPPED},MANAGED}
13:33:22.496 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@610eb5c4
13:33:22.496 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@3a7db60f{/,null,UNAVAILABLE} added {ServletHandler@3f3b357d{STOPPED},MANAGED}
13:33:22.497 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@400268f
13:33:22.497 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@62f67baf{/,null,UNAVAILABLE} added {ServletHandler@557b17a2{STOPPED},MANAGED}
13:33:22.501 [run-main-0] DEBUG org.sparkproject.jetty.http.PreEncodedHttpField - HttpField encoders loaded: []
13:33:22.505 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@1acd56ed
13:33:22.506 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@5b2f8aec{/,null,UNAVAILABLE} added {ServletHandler@68547e39{STOPPED},MANAGED}
13:33:22.506 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@28527577
13:33:22.506 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@5150614c{/,null,UNAVAILABLE} added {ServletHandler@a68d02b{STOPPED},MANAGED}
13:33:22.508 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@39b21d43
13:33:22.508 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@5110fe15{/,null,UNAVAILABLE} added {ServletHandler@1e99e239{STOPPED},MANAGED}
13:33:22.508 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@e26deb9
13:33:22.508 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@6ab155fa{/,null,UNAVAILABLE} added {ServletHandler@2d3ea8ab{STOPPED},MANAGED}
13:33:22.514 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - Server@6979db37{STOPPED}[9.4.z-SNAPSHOT] added {QueuedThreadPool[SparkUI]@24bcd30{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY],AUTO}
13:33:22.515 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - Server@6979db37{STOPPED}[9.4.z-SNAPSHOT] added {ErrorHandler@52bffbf7{STOPPED},AUTO}
13:33:22.516 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - Server@6979db37{STOPPED}[9.4.z-SNAPSHOT] added {ContextHandlerCollection@6bcc8098{STOPPED},MANAGED}
13:33:22.517 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting Server@6979db37{STOPPED}[9.4.z-SNAPSHOT]
13:33:22.518 [run-main-0] INFO org.sparkproject.jetty.server.Server - jetty-9.4.z-SNAPSHOT; built: 2019-04-29T20:42:08.989Z; git: e1bc35120a6617ee3df052294e433f3a25ce7097; jvm 1.8.0_265-b01
13:33:22.531 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting Server@6979db37{STARTING}[9.4.z-SNAPSHOT]
13:33:22.531 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting QueuedThreadPool[SparkUI]@24bcd30{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]
13:33:22.533 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.ReservedThreadExecutor - ReservedThreadExecutor@115ea1a4{s=0/16,p=0}
13:33:22.533 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - QueuedThreadPool[SparkUI]@24bcd30{STARTING,8<=0<=200,i=0,r=-1,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}] added {ReservedThreadExecutor@115ea1a4{s=0/16,p=0},AUTO}
13:33:22.533 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ReservedThreadExecutor@115ea1a4{s=0/16,p=0}
13:33:22.535 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27406ms ReservedThreadExecutor@115ea1a4{s=0/16,p=0}
13:33:22.535 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-181,5,run-main-group-0]
13:33:22.535 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-182,5,run-main-group-0]
13:33:22.535 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-183,5,run-main-group-0]
13:33:22.536 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-184,5,run-main-group-0]
13:33:22.536 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-185,5,run-main-group-0]
13:33:22.536 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-186,5,run-main-group-0]
13:33:22.536 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-187,5,run-main-group-0]
13:33:22.536 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-188,5,run-main-group-0]
13:33:22.536 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27408ms QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=7,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}]
13:33:22.536 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ErrorHandler@52bffbf7{STOPPED}
13:33:22.537 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ErrorHandler@52bffbf7{STARTING}
13:33:22.537 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27408ms ErrorHandler@52bffbf7{STARTED}
13:33:22.537 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ContextHandlerCollection@6bcc8098{STOPPED}
13:33:22.537 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ContextHandlerCollection@6bcc8098{STARTING}
13:33:22.537 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27408ms ContextHandlerCollection@6bcc8098{STARTED}
13:33:22.537 [run-main-0] INFO org.sparkproject.jetty.server.Server - Started @27408ms
13:33:22.537 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27408ms Server@6979db37{STARTED}[9.4.z-SNAPSHOT]
13:33:22.539 [run-main-0] DEBUG org.apache.spark.ui.JettyUtils - Using requestHeaderSize: 8192
13:33:22.546 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - HttpConnectionFactory@c49ed67[HTTP/1.1] added {HttpConfiguration@1807a380{32768/8192,8192/8192,https://:0,[]},POJO}
13:33:22.552 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ServerConnector@ccf366d{null,[]}{0.0.0.0:0} added {Server@6979db37{STARTED}[9.4.z-SNAPSHOT],UNMANAGED}
13:33:22.552 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ServerConnector@ccf366d{null,[]}{0.0.0.0:0} added {QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}],UNMANAGED}
13:33:22.552 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ServerConnector@ccf366d{null,[]}{0.0.0.0:0} added {ScheduledExecutorScheduler@37c0bc42{STOPPED},AUTO}
13:33:22.552 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ServerConnector@ccf366d{null,[]}{0.0.0.0:0} added {org.sparkproject.jetty.io.ArrayByteBufferPool@40ce8085,POJO}
13:33:22.553 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ServerConnector@ccf366d{null,[http/1.1]}{0.0.0.0:0} added {HttpConnectionFactory@c49ed67[HTTP/1.1],AUTO}
13:33:22.553 [run-main-0] DEBUG org.sparkproject.jetty.server.AbstractConnector - ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added HttpConnectionFactory@c49ed67[HTTP/1.1]
13:33:22.554 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:0} added {SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:0},MANAGED}
13:33:22.554 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:22.555 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {sun.nio.ch.ServerSocketChannelImpl[localhost/127.0.0.1:4040],POJO}
13:33:22.556 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ScheduledExecutorScheduler@37c0bc42{STOPPED}
13:33:22.556 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27427ms ScheduledExecutorScheduler@37c0bc42{STARTED}
13:33:22.556 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting HttpConnectionFactory@c49ed67[HTTP/1.1]
13:33:22.556 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27427ms HttpConnectionFactory@c49ed67[HTTP/1.1]
13:33:22.556 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:22.562 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@4cdb93f3/SelectorProducer@6b9c9613/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.561-08:00 added {SelectorProducer@6b9c9613,POJO}
13:33:22.562 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@4cdb93f3/SelectorProducer@6b9c9613/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.562-08:00 added {QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}],UNMANAGED}
13:33:22.562 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@4cdb93f3/SelectorProducer@6b9c9613/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.562-08:00 created
13:33:22.562 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ManagedSelector@24867183{STOPPED} id=0 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@4cdb93f3/SelectorProducer@6b9c9613/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.562-08:00,MANAGED}
13:33:22.563 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {ManagedSelector@24867183{STOPPED} id=0 keys=-1 selected=-1 updates=0,AUTO}
13:33:22.563 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@68212f3c/SelectorProducer@25d55ed0/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.563-08:00 added {SelectorProducer@25d55ed0,POJO}
13:33:22.563 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@68212f3c/SelectorProducer@25d55ed0/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.563-08:00 added {QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}],UNMANAGED}
13:33:22.563 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@68212f3c/SelectorProducer@25d55ed0/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.563-08:00 created
13:33:22.564 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ManagedSelector@7ec85a96{STOPPED} id=1 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@68212f3c/SelectorProducer@25d55ed0/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.564-08:00,MANAGED}
13:33:22.564 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {ManagedSelector@7ec85a96{STOPPED} id=1 keys=-1 selected=-1 updates=0,AUTO}
13:33:22.564 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@695526a5/SelectorProducer@8ecbc7c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.564-08:00 added {SelectorProducer@8ecbc7c,POJO}
13:33:22.564 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@695526a5/SelectorProducer@8ecbc7c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.564-08:00 added {QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}],UNMANAGED}
13:33:22.564 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@695526a5/SelectorProducer@8ecbc7c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.564-08:00 created
13:33:22.564 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ManagedSelector@7c0506f{STOPPED} id=2 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@695526a5/SelectorProducer@8ecbc7c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.564-08:00,MANAGED}
13:33:22.565 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {ManagedSelector@7c0506f{STOPPED} id=2 keys=-1 selected=-1 updates=0,AUTO}
13:33:22.565 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@3b60b6eb/SelectorProducer@7bc0df2c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.565-08:00 added {SelectorProducer@7bc0df2c,POJO}
13:33:22.565 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@3b60b6eb/SelectorProducer@7bc0df2c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.565-08:00 added {QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}],UNMANAGED}
13:33:22.565 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@3b60b6eb/SelectorProducer@7bc0df2c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.565-08:00 created
13:33:22.565 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ManagedSelector@16229374{STOPPED} id=3 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@3b60b6eb/SelectorProducer@7bc0df2c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.565-08:00,MANAGED}
13:33:22.565 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {ManagedSelector@16229374{STOPPED} id=3 keys=-1 selected=-1 updates=0,AUTO}
13:33:22.566 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@13e4faf7/SelectorProducer@2d0dd18e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.566-08:00 added {SelectorProducer@2d0dd18e,POJO}
13:33:22.566 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@13e4faf7/SelectorProducer@2d0dd18e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.566-08:00 added {QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}],UNMANAGED}
13:33:22.566 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@13e4faf7/SelectorProducer@2d0dd18e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.566-08:00 created
13:33:22.566 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ManagedSelector@50c942bc{STOPPED} id=4 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@13e4faf7/SelectorProducer@2d0dd18e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.566-08:00,MANAGED}
13:33:22.566 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {ManagedSelector@50c942bc{STOPPED} id=4 keys=-1 selected=-1 updates=0,AUTO}
13:33:22.567 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@5272c2e2/SelectorProducer@66f5b919/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.566-08:00 added {SelectorProducer@66f5b919,POJO}
13:33:22.567 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@5272c2e2/SelectorProducer@66f5b919/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.567-08:00 added {QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}],UNMANAGED}
13:33:22.567 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@5272c2e2/SelectorProducer@66f5b919/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.567-08:00 created
13:33:22.567 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ManagedSelector@25b785e8{STOPPED} id=5 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@5272c2e2/SelectorProducer@66f5b919/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.567-08:00,MANAGED}
13:33:22.567 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {ManagedSelector@25b785e8{STOPPED} id=5 keys=-1 selected=-1 updates=0,AUTO}
13:33:22.567 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@3f71ff40/SelectorProducer@7bd04f9e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.567-08:00 added {SelectorProducer@7bd04f9e,POJO}
13:33:22.567 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@3f71ff40/SelectorProducer@7bd04f9e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.567-08:00 added {QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}],UNMANAGED}
13:33:22.568 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@3f71ff40/SelectorProducer@7bd04f9e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.567-08:00 created
13:33:22.568 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ManagedSelector@30a61c8c{STOPPED} id=6 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@3f71ff40/SelectorProducer@7bd04f9e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.568-08:00,MANAGED}
13:33:22.568 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {ManagedSelector@30a61c8c{STOPPED} id=6 keys=-1 selected=-1 updates=0,AUTO}
13:33:22.568 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@29a757b5/SelectorProducer@199c263e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.568-08:00 added {SelectorProducer@199c263e,POJO}
13:33:22.568 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - EatWhatYouKill@29a757b5/SelectorProducer@199c263e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.568-08:00 added {QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}],UNMANAGED}
13:33:22.568 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@29a757b5/SelectorProducer@199c263e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.568-08:00 created
13:33:22.568 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ManagedSelector@6049262c{STOPPED} id=7 keys=-1 selected=-1 updates=0 added {EatWhatYouKill@29a757b5/SelectorProducer@199c263e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.568-08:00,MANAGED}
13:33:22.569 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {ManagedSelector@6049262c{STOPPED} id=7 keys=-1 selected=-1 updates=0,AUTO}
13:33:22.569 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ManagedSelector@24867183{STOPPED} id=0 keys=-1 selected=-1 updates=0
13:33:22.569 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting EatWhatYouKill@4cdb93f3/SelectorProducer@6b9c9613/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.569-08:00
13:33:22.569 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27440ms EatWhatYouKill@4cdb93f3/SelectorProducer@6b9c9613/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.569-08:00
13:33:22.569 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@2286a716
13:33:22.570 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$Start@1a13b23f on ManagedSelector@24867183{STARTING} id=0 keys=0 selected=0 updates=0
13:33:22.570 [SparkUI-181] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@2286a716
13:33:22.570 [SparkUI-181] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@4cdb93f3/SelectorProducer@6b9c9613/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=7,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.57-08:00 tryProduce false
13:33:22.571 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:22.571 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$Start@1a13b23f
13:33:22.571 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:22.571 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@3c45467f waiting with 0 keys
13:33:22.571 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27442ms ManagedSelector@24867183{STARTED} id=0 keys=0 selected=0 updates=0
13:33:22.571 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ManagedSelector@7ec85a96{STOPPED} id=1 keys=-1 selected=-1 updates=0
13:33:22.571 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting EatWhatYouKill@68212f3c/SelectorProducer@25d55ed0/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=7,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.571-08:00
13:33:22.571 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27443ms EatWhatYouKill@68212f3c/SelectorProducer@25d55ed0/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=7,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.571-08:00
13:33:22.572 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@7e99d26e
13:33:22.572 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$Start@49b97283 on ManagedSelector@7ec85a96{STARTING} id=1 keys=0 selected=0 updates=0
13:33:22.572 [SparkUI-182] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@7e99d26e
13:33:22.572 [SparkUI-182] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@68212f3c/SelectorProducer@25d55ed0/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=6,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.572-08:00 tryProduce false
13:33:22.572 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:22.572 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$Start@49b97283
13:33:22.572 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:22.572 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@63047db3 waiting with 0 keys
13:33:22.572 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27444ms ManagedSelector@7ec85a96{STARTED} id=1 keys=0 selected=0 updates=0
13:33:22.572 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ManagedSelector@7c0506f{STOPPED} id=2 keys=-1 selected=-1 updates=0
13:33:22.573 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting EatWhatYouKill@695526a5/SelectorProducer@8ecbc7c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=6,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.573-08:00
13:33:22.573 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27444ms EatWhatYouKill@695526a5/SelectorProducer@8ecbc7c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=6,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.573-08:00
13:33:22.573 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@5e90d2b5
13:33:22.573 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$Start@59150112 on ManagedSelector@7c0506f{STARTING} id=2 keys=0 selected=0 updates=0
13:33:22.573 [SparkUI-183] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@5e90d2b5
13:33:22.573 [SparkUI-183] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@695526a5/SelectorProducer@8ecbc7c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=5,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.573-08:00 tryProduce false
13:33:22.573 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:22.573 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$Start@59150112
13:33:22.573 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:22.573 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@5bd57ed3 waiting with 0 keys
13:33:22.573 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27444ms ManagedSelector@7c0506f{STARTED} id=2 keys=0 selected=0 updates=0
13:33:22.573 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ManagedSelector@16229374{STOPPED} id=3 keys=-1 selected=-1 updates=0
13:33:22.573 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting EatWhatYouKill@3b60b6eb/SelectorProducer@7bc0df2c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=5,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.573-08:00
13:33:22.574 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27445ms EatWhatYouKill@3b60b6eb/SelectorProducer@7bc0df2c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=5,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.574-08:00
13:33:22.574 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@6b80e830
13:33:22.574 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$Start@33dd9a8f on ManagedSelector@16229374{STARTING} id=3 keys=0 selected=0 updates=0
13:33:22.574 [SparkUI-184] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@6b80e830
13:33:22.574 [SparkUI-184] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@3b60b6eb/SelectorProducer@7bc0df2c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=4,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.574-08:00 tryProduce false
13:33:22.574 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:22.574 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$Start@33dd9a8f
13:33:22.574 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:22.574 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6f8ab739 waiting with 0 keys
13:33:22.574 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27446ms ManagedSelector@16229374{STARTED} id=3 keys=0 selected=0 updates=0
13:33:22.574 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ManagedSelector@50c942bc{STOPPED} id=4 keys=-1 selected=-1 updates=0
13:33:22.575 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting EatWhatYouKill@13e4faf7/SelectorProducer@2d0dd18e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=4,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.574-08:00
13:33:22.575 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27446ms EatWhatYouKill@13e4faf7/SelectorProducer@2d0dd18e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=4,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.575-08:00
13:33:22.575 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@42b11077
13:33:22.575 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$Start@569df28f on ManagedSelector@50c942bc{STARTING} id=4 keys=0 selected=0 updates=0
13:33:22.575 [SparkUI-185] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@42b11077
13:33:22.575 [SparkUI-185] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@13e4faf7/SelectorProducer@2d0dd18e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=3,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.575-08:00 tryProduce false
13:33:22.575 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:22.575 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$Start@569df28f
13:33:22.575 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:22.575 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@c25d651 waiting with 0 keys
13:33:22.575 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27446ms ManagedSelector@50c942bc{STARTED} id=4 keys=0 selected=0 updates=0
13:33:22.575 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ManagedSelector@25b785e8{STOPPED} id=5 keys=-1 selected=-1 updates=0
13:33:22.575 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting EatWhatYouKill@5272c2e2/SelectorProducer@66f5b919/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=3,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.575-08:00
13:33:22.575 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27447ms EatWhatYouKill@5272c2e2/SelectorProducer@66f5b919/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=3,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.575-08:00
13:33:22.575 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@3a304104
13:33:22.576 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$Start@65e6bd2f on ManagedSelector@25b785e8{STARTING} id=5 keys=0 selected=0 updates=0
13:33:22.576 [SparkUI-186] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@3a304104
13:33:22.576 [SparkUI-186] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@5272c2e2/SelectorProducer@66f5b919/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=2,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.576-08:00 tryProduce false
13:33:22.576 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:22.576 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$Start@65e6bd2f
13:33:22.576 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:22.576 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6667e8b6 waiting with 0 keys
13:33:22.576 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27447ms ManagedSelector@25b785e8{STARTED} id=5 keys=0 selected=0 updates=0
13:33:22.576 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ManagedSelector@30a61c8c{STOPPED} id=6 keys=-1 selected=-1 updates=0
13:33:22.576 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting EatWhatYouKill@3f71ff40/SelectorProducer@7bd04f9e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=2,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.576-08:00
13:33:22.576 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27447ms EatWhatYouKill@3f71ff40/SelectorProducer@7bd04f9e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=2,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.576-08:00
13:33:22.576 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@2f1e2b4c
13:33:22.576 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$Start@162ebdaa on ManagedSelector@30a61c8c{STARTING} id=6 keys=0 selected=0 updates=0
13:33:22.576 [SparkUI-187] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@2f1e2b4c
13:33:22.577 [SparkUI-187] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@3f71ff40/SelectorProducer@7bd04f9e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=1,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.576-08:00 tryProduce false
13:33:22.577 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:22.577 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$Start@162ebdaa
13:33:22.577 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:22.577 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@29fdf911 waiting with 0 keys
13:33:22.577 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27448ms ManagedSelector@30a61c8c{STARTED} id=6 keys=0 selected=0 updates=0
13:33:22.577 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ManagedSelector@6049262c{STOPPED} id=7 keys=-1 selected=-1 updates=0
13:33:22.577 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting EatWhatYouKill@29a757b5/SelectorProducer@199c263e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=1,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.577-08:00
13:33:22.577 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27448ms EatWhatYouKill@29a757b5/SelectorProducer@199c263e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=8<=200,i=1,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.577-08:00
13:33:22.577 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@2e2ef60a
13:33:22.577 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$Start@7e712925 on ManagedSelector@6049262c{STARTING} id=7 keys=0 selected=0 updates=0
13:33:22.577 [SparkUI-188] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-189,5,run-main-group-0]
13:33:22.577 [SparkUI-188] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@2e2ef60a
13:33:22.577 [SparkUI-188] DEBUG org.sparkproject.jetty.util.thread.strategy.EatWhatYouKill - EatWhatYouKill@29a757b5/SelectorProducer@199c263e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=9<=200,i=1,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:22.577-08:00 tryProduce false
13:33:22.577 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:22.578 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$Start@7e712925
13:33:22.578 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:22.578 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@f0b3b92 waiting with 0 keys
13:33:22.578 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27449ms ManagedSelector@6049262c{STARTED} id=7 keys=0 selected=0 updates=0
13:33:22.578 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27449ms SelectorManager@ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:22.578 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-0@1a0c3363,POJO}
13:33:22.578 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue acceptor-0@1a0c3363
13:33:22.578 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040} added {acceptor-1@6d431906,POJO}
13:33:22.578 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - queue acceptor-1@6d431906
13:33:22.578 [SparkUI-189] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-190,5,run-main-group-0]
13:33:22.579 [SparkUI-189] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run acceptor-0@1a0c3363
13:33:22.579 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-191,5,run-main-group-0]
13:33:22.579 [SparkUI-190] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Starting Thread[SparkUI-192,5,run-main-group-0]
13:33:22.579 [run-main-0] INFO org.sparkproject.jetty.server.AbstractConnector - Started ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:22.579 [SparkUI-190] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run acceptor-1@6d431906
13:33:22.579 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27450ms ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:22.579 [run-main-0] INFO org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
13:33:22.579 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - Server@6979db37{STARTED}[9.4.z-SNAPSHOT] added {Spark@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040},UNMANAGED}
13:33:22.590 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.590 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@7e90d931{STOPPED} mime types IncludeExclude@980b2ff{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@47349638,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@7a039cd5}
13:33:22.591 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@7e90d931{STOPPED} added {o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.591 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STOPPED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,UNAVAILABLE,@Spark}]}]
13:33:22.591 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@7e90d931{STOPPED},UNMANAGED}
13:33:22.591 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,UNAVAILABLE,@Spark}
13:33:22.592 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,STARTING,@Spark}
13:33:22.592 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@77b65561{STOPPED}
13:33:22.593 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-496e3101[EMBEDDED:null]
13:33:22.593 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-496e3101@db287ec1==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.593 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-464db1f7=org.apache.spark.ui.HttpSecurityFilter-464db1f7@464db1f7==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.596 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-464db1f7]
13:33:22.596 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.597 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.597 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-496e3101=org.apache.spark.ui.JettyUtils$$anon$1-496e3101@db287ec1==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.597 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@77b65561{STARTING}
13:33:22.597 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27468ms ServletHandler@77b65561{STARTED}
13:33:22.598 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-464db1f7@464db1f7==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.598 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27469ms org.apache.spark.ui.HttpSecurityFilter-464db1f7@464db1f7==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.599 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@1d2d536c
13:33:22.599 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-496e3101@db287ec1==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.600 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27471ms org.apache.spark.ui.JettyUtils$$anon$1-496e3101@db287ec1==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.601 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@65ad6531 for org.apache.spark.ui.JettyUtils$$anon$1-496e3101
13:33:22.601 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}
13:33:22.601 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27472ms o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}
13:33:22.601 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@7e90d931{STOPPED}
13:33:22.602 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@7e90d931{STARTING}
13:33:22.602 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27474ms GzipHandler@7e90d931{STARTED}
13:33:22.602 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.602 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@58ceda2b{STOPPED} mime types IncludeExclude@73ed60a6{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@5d6132a,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@31cc14a3}
13:33:22.603 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@58ceda2b{STOPPED} added {o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.603 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STOPPED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.603 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.603 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@58ceda2b{STOPPED},UNMANAGED}
13:33:22.603 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,UNAVAILABLE,@Spark}
13:33:22.603 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,STARTING,@Spark}
13:33:22.603 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@5b54ca69{STOPPED}
13:33:22.603 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-5f16bdfe[EMBEDDED:null]
13:33:22.603 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-5f16bdfe@8479ade5==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.604 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-3e6f91a=org.apache.spark.ui.HttpSecurityFilter-3e6f91a@3e6f91a==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.604 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-3e6f91a]
13:33:22.604 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.604 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.604 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5f16bdfe=org.apache.spark.ui.JettyUtils$$anon$1-5f16bdfe@8479ade5==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.604 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@5b54ca69{STARTING}
13:33:22.604 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27476ms ServletHandler@5b54ca69{STARTED}
13:33:22.604 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-3e6f91a@3e6f91a==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.604 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27476ms org.apache.spark.ui.HttpSecurityFilter-3e6f91a@3e6f91a==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@1ffd8f33
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-5f16bdfe@8479ade5==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27476ms org.apache.spark.ui.JettyUtils$$anon$1-5f16bdfe@8479ade5==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@78d343a for org.apache.spark.ui.JettyUtils$$anon$1-5f16bdfe
13:33:22.605 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27476ms o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@58ceda2b{STOPPED}
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@58ceda2b{STARTING}
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27476ms GzipHandler@58ceda2b{STARTED}
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@634f4b43{STOPPED} mime types IncludeExclude@1038d40e{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@7efa0ed7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@75430b92}
13:33:22.605 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@634f4b43{STOPPED} added {o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STOPPED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,UNAVAILABLE,@Spark}]}]
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@634f4b43{STOPPED},UNMANAGED}
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,UNAVAILABLE,@Spark}
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,STARTING,@Spark}
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@3f7eee1{STOPPED}
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-2a90bfd8[EMBEDDED:null]
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-2a90bfd8@51a93e0c==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-327728a2=org.apache.spark.ui.HttpSecurityFilter-327728a2@327728a2==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-327728a2]
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2a90bfd8=org.apache.spark.ui.JettyUtils$$anon$1-2a90bfd8@51a93e0c==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.606 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@3f7eee1{STARTING}
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27478ms ServletHandler@3f7eee1{STARTED}
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-327728a2@327728a2==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27478ms org.apache.spark.ui.HttpSecurityFilter-327728a2@327728a2==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@6c4f532a
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-2a90bfd8@51a93e0c==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27478ms org.apache.spark.ui.JettyUtils$$anon$1-2a90bfd8@51a93e0c==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@3a817209 for org.apache.spark.ui.JettyUtils$$anon$1-2a90bfd8
13:33:22.607 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27478ms o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@634f4b43{STOPPED}
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@634f4b43{STARTING}
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27478ms GzipHandler@634f4b43{STARTED}
13:33:22.607 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@6f1113a6{STOPPED} mime types IncludeExclude@5eb13577{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@50e5eb06,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@270e9c4e}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@6f1113a6{STOPPED} added {o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STOPPED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@6f1113a6{STOPPED},UNMANAGED}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,UNAVAILABLE,@Spark}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,STARTING,@Spark}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@29b9ca22{STOPPED}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-678ceb2[EMBEDDED:null]
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-678ceb2@3c043c9b==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-14a35f38=org.apache.spark.ui.HttpSecurityFilter-14a35f38@14a35f38==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-14a35f38]
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-678ceb2=org.apache.spark.ui.JettyUtils$$anon$1-678ceb2@3c043c9b==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@29b9ca22{STARTING}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27480ms ServletHandler@29b9ca22{STARTED}
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-14a35f38@14a35f38==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27480ms org.apache.spark.ui.HttpSecurityFilter-14a35f38@14a35f38==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.608 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@4065272a
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-678ceb2@3c043c9b==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27480ms org.apache.spark.ui.JettyUtils$$anon$1-678ceb2@3c043c9b==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@1728b8dc for org.apache.spark.ui.JettyUtils$$anon$1-678ceb2
13:33:22.609 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27480ms o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@6f1113a6{STOPPED}
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@6f1113a6{STARTING}
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27480ms GzipHandler@6f1113a6{STARTED}
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@3b55c14b{STOPPED} mime types IncludeExclude@5260ed7c{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@dc51b4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@3eef20b7}
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@3b55c14b{STOPPED} added {o.s.j.s.ServletContextHandler@576a576a{/stages,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.609 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STOPPED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,UNAVAILABLE,@Spark}]}]
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@3b55c14b{STOPPED},UNMANAGED}
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@576a576a{/stages,null,UNAVAILABLE,@Spark}
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@576a576a{/stages,null,STARTING,@Spark}
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@1fc99fa5{STOPPED}
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-7585e2db[EMBEDDED:null]
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-7585e2db@400f2634==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-686adce4=org.apache.spark.ui.HttpSecurityFilter-686adce4@686adce4==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-686adce4]
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7585e2db=org.apache.spark.ui.JettyUtils$$anon$1-7585e2db@400f2634==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.610 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@1fc99fa5{STARTING}
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27482ms ServletHandler@1fc99fa5{STARTED}
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-686adce4@686adce4==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27482ms org.apache.spark.ui.HttpSecurityFilter-686adce4@686adce4==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@2b25f1b8
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-7585e2db@400f2634==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27482ms org.apache.spark.ui.JettyUtils$$anon$1-7585e2db@400f2634==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@7e7bf2ad for org.apache.spark.ui.JettyUtils$$anon$1-7585e2db
13:33:22.611 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27482ms o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@3b55c14b{STOPPED}
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@3b55c14b{STARTING}
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27482ms GzipHandler@3b55c14b{STARTED}
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@5be53c91{STOPPED} mime types IncludeExclude@5f49ae64{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@7e06d1ba,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@20f98a38}
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@5be53c91{STOPPED} added {o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STOPPED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.611 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@5be53c91{STOPPED},UNMANAGED}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,UNAVAILABLE,@Spark}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,STARTING,@Spark}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@793fd716{STOPPED}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-237661d0[EMBEDDED:null]
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-237661d0@cd20acd5==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-1cc85d27=org.apache.spark.ui.HttpSecurityFilter-1cc85d27@1cc85d27==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-1cc85d27]
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-237661d0=org.apache.spark.ui.JettyUtils$$anon$1-237661d0@cd20acd5==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@793fd716{STARTING}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27483ms ServletHandler@793fd716{STARTED}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-1cc85d27@1cc85d27==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27483ms org.apache.spark.ui.HttpSecurityFilter-1cc85d27@1cc85d27==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@528a3b02
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-237661d0@cd20acd5==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27484ms org.apache.spark.ui.JettyUtils$$anon$1-237661d0@cd20acd5==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@40a285b9 for org.apache.spark.ui.JettyUtils$$anon$1-237661d0
13:33:22.612 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27484ms o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@5be53c91{STOPPED}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@5be53c91{STARTING}
13:33:22.612 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27484ms GzipHandler@5be53c91{STARTED}
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@64a5f478{STOPPED} mime types IncludeExclude@67f481c5{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@332f4fcf,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@3376270b}
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@64a5f478{STOPPED} added {o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STOPPED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,UNAVAILABLE,@Spark}]}]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@64a5f478{STOPPED},UNMANAGED}
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,UNAVAILABLE,@Spark}
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,STARTING,@Spark}
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@17756aa5{STOPPED}
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-40aa3df1[EMBEDDED:null]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-40aa3df1@48393426==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-8e10716=org.apache.spark.ui.HttpSecurityFilter-8e10716@8e10716==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.613 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-8e10716]
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-40aa3df1=org.apache.spark.ui.JettyUtils$$anon$1-40aa3df1@48393426==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@17756aa5{STARTING}
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27485ms ServletHandler@17756aa5{STARTED}
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-8e10716@8e10716==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27485ms org.apache.spark.ui.HttpSecurityFilter-8e10716@8e10716==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@783b0329
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-40aa3df1@48393426==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27485ms org.apache.spark.ui.JettyUtils$$anon$1-40aa3df1@48393426==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@3b024f42 for org.apache.spark.ui.JettyUtils$$anon$1-40aa3df1
13:33:22.614 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27485ms o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@64a5f478{STOPPED}
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@64a5f478{STARTING}
13:33:22.614 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27485ms GzipHandler@64a5f478{STARTED}
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@79055b92{STOPPED} mime types IncludeExclude@5acac696{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@1ad37d5b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@69c0c0da}
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@79055b92{STOPPED} added {o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STOPPED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@79055b92{STOPPED},UNMANAGED}
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,UNAVAILABLE,@Spark}
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,STARTING,@Spark}
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@7c35b91c{STOPPED}
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-6d6146de[EMBEDDED:null]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-6d6146de@8aba93da==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.615 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-721a2eda=org.apache.spark.ui.HttpSecurityFilter-721a2eda@721a2eda==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-721a2eda]
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6d6146de=org.apache.spark.ui.JettyUtils$$anon$1-6d6146de@8aba93da==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@7c35b91c{STARTING}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27487ms ServletHandler@7c35b91c{STARTED}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-721a2eda@721a2eda==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27487ms org.apache.spark.ui.HttpSecurityFilter-721a2eda@721a2eda==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@3a4acfbb
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-6d6146de@8aba93da==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27487ms org.apache.spark.ui.JettyUtils$$anon$1-6d6146de@8aba93da==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@36385012 for org.apache.spark.ui.JettyUtils$$anon$1-6d6146de
13:33:22.616 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27487ms o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@79055b92{STOPPED}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@79055b92{STARTING}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27487ms GzipHandler@79055b92{STARTED}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@58a90a11{STOPPED} mime types IncludeExclude@347221a8{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@403e4ff4,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@715e044a}
13:33:22.616 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@58a90a11{STOPPED} added {o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STOPPED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,UNAVAILABLE,@Spark}]}]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@58a90a11{STOPPED},UNMANAGED}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,UNAVAILABLE,@Spark}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,STARTING,@Spark}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@45c8581b{STOPPED}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-5c56c254[EMBEDDED:null]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-5c56c254@ec9a112b==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-3780ca2b=org.apache.spark.ui.HttpSecurityFilter-3780ca2b@3780ca2b==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-3780ca2b]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5c56c254=org.apache.spark.ui.JettyUtils$$anon$1-5c56c254@ec9a112b==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@45c8581b{STARTING}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27489ms ServletHandler@45c8581b{STARTED}
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-3780ca2b@3780ca2b==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27489ms org.apache.spark.ui.HttpSecurityFilter-3780ca2b@3780ca2b==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@61b761f2
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-5c56c254@ec9a112b==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.617 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27489ms org.apache.spark.ui.JettyUtils$$anon$1-5c56c254@ec9a112b==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@44ed630d for org.apache.spark.ui.JettyUtils$$anon$1-5c56c254
13:33:22.618 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27489ms o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@58a90a11{STOPPED}
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@58a90a11{STARTING}
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27489ms GzipHandler@58a90a11{STARTED}
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@7763f356{STOPPED} mime types IncludeExclude@2d81b4b9{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@2db4f0f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@2e96052}
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@7763f356{STOPPED} added {o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.618 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STOPPED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@7763f356{STOPPED},UNMANAGED}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,UNAVAILABLE,@Spark}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,STARTING,@Spark}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@6f10f2c6{STOPPED}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-53ed912[EMBEDDED:null]
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-53ed912@2c489cf==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-761ed58b=org.apache.spark.ui.HttpSecurityFilter-761ed58b@761ed58b==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-761ed58b]
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-53ed912=org.apache.spark.ui.JettyUtils$$anon$1-53ed912@2c489cf==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@6f10f2c6{STARTING}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27490ms ServletHandler@6f10f2c6{STARTED}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-761ed58b@761ed58b==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27490ms org.apache.spark.ui.HttpSecurityFilter-761ed58b@761ed58b==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@6a78da1a
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-53ed912@2c489cf==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27490ms org.apache.spark.ui.JettyUtils$$anon$1-53ed912@2c489cf==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@4a7c8f90 for org.apache.spark.ui.JettyUtils$$anon$1-53ed912
13:33:22.619 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27490ms o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@7763f356{STOPPED}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@7763f356{STARTING}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27491ms GzipHandler@7763f356{STARTED}
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.619 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@5b250b15{STOPPED} mime types IncludeExclude@7721a261{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@598fb31a,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@73b582e6}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@5b250b15{STOPPED} added {o.s.j.s.ServletContextHandler@344240e1{/storage,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STOPPED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,UNAVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@5b250b15{STOPPED},UNMANAGED}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@344240e1{/storage,null,UNAVAILABLE,@Spark}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@344240e1{/storage,null,STARTING,@Spark}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@277ab3a5{STOPPED}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-3a9b6022[EMBEDDED:null]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-3a9b6022@bc3630ff==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-128712e7=org.apache.spark.ui.HttpSecurityFilter-128712e7@128712e7==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-128712e7]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3a9b6022=org.apache.spark.ui.JettyUtils$$anon$1-3a9b6022@bc3630ff==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@277ab3a5{STARTING}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27492ms ServletHandler@277ab3a5{STARTED}
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-128712e7@128712e7==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27492ms org.apache.spark.ui.HttpSecurityFilter-128712e7@128712e7==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.620 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@bb5226
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-3a9b6022@bc3630ff==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27492ms org.apache.spark.ui.JettyUtils$$anon$1-3a9b6022@bc3630ff==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@7a73cafa for org.apache.spark.ui.JettyUtils$$anon$1-3a9b6022
13:33:22.621 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27492ms o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@5b250b15{STOPPED}
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@5b250b15{STARTING}
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27492ms GzipHandler@5b250b15{STARTED}
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@13daa51{STOPPED} mime types IncludeExclude@5bcde232{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@3f8dc7ab,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@6418575e}
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@13daa51{STOPPED} added {o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STOPPED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.621 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@13daa51{STOPPED},UNMANAGED}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,UNAVAILABLE,@Spark}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,STARTING,@Spark}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@4ae7e96a{STOPPED}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-2b1c0a64[EMBEDDED:null]
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-2b1c0a64@7ba0901f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-5e40a1cd=org.apache.spark.ui.HttpSecurityFilter-5e40a1cd@5e40a1cd==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-5e40a1cd]
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2b1c0a64=org.apache.spark.ui.JettyUtils$$anon$1-2b1c0a64@7ba0901f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@4ae7e96a{STARTING}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27493ms ServletHandler@4ae7e96a{STARTED}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-5e40a1cd@5e40a1cd==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27493ms org.apache.spark.ui.HttpSecurityFilter-5e40a1cd@5e40a1cd==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@89b16ae
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-2b1c0a64@7ba0901f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27493ms org.apache.spark.ui.JettyUtils$$anon$1-2b1c0a64@7ba0901f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@3cf3a9fd for org.apache.spark.ui.JettyUtils$$anon$1-2b1c0a64
13:33:22.622 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27493ms o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@13daa51{STOPPED}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@13daa51{STARTING}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27493ms GzipHandler@13daa51{STARTED}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@4b96991c{STOPPED} mime types IncludeExclude@1be8d8a6{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@3af52667,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@43149057}
13:33:22.622 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@4b96991c{STOPPED} added {o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STOPPED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,UNAVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@4b96991c{STOPPED},UNMANAGED}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,UNAVAILABLE,@Spark}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,STARTING,@Spark}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@2b6f2033{STOPPED}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-6506e987[EMBEDDED:null]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-6506e987@ca9560a6==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-6d928157=org.apache.spark.ui.HttpSecurityFilter-6d928157@6d928157==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-6d928157]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6506e987=org.apache.spark.ui.JettyUtils$$anon$1-6506e987@ca9560a6==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@2b6f2033{STARTING}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27495ms ServletHandler@2b6f2033{STARTED}
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-6d928157@6d928157==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27495ms org.apache.spark.ui.HttpSecurityFilter-6d928157@6d928157==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.623 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@3cb5af50
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-6506e987@ca9560a6==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27495ms org.apache.spark.ui.JettyUtils$$anon$1-6506e987@ca9560a6==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@61c56d88 for org.apache.spark.ui.JettyUtils$$anon$1-6506e987
13:33:22.624 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27495ms o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@4b96991c{STOPPED}
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@4b96991c{STARTING}
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27495ms GzipHandler@4b96991c{STARTED}
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@15e109f4{STOPPED} mime types IncludeExclude@4bfeb37{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@4e5c7f05,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@397549f6}
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@15e109f4{STOPPED} added {o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STOPPED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@15e109f4{STOPPED},UNMANAGED}
13:33:22.624 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,UNAVAILABLE,@Spark}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,STARTING,@Spark}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@a65f935{STOPPED}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-58fd732f[EMBEDDED:null]
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-58fd732f@5fffd01f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7210b9c9=org.apache.spark.ui.HttpSecurityFilter-7210b9c9@7210b9c9==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-7210b9c9]
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-58fd732f=org.apache.spark.ui.JettyUtils$$anon$1-58fd732f@5fffd01f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@a65f935{STARTING}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27496ms ServletHandler@a65f935{STARTED}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-7210b9c9@7210b9c9==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27496ms org.apache.spark.ui.HttpSecurityFilter-7210b9c9@7210b9c9==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@24c64985
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-58fd732f@5fffd01f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27496ms org.apache.spark.ui.JettyUtils$$anon$1-58fd732f@5fffd01f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@5f5bf879 for org.apache.spark.ui.JettyUtils$$anon$1-58fd732f
13:33:22.625 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27496ms o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@15e109f4{STOPPED}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@15e109f4{STARTING}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27497ms GzipHandler@15e109f4{STARTED}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@617bcd95{STOPPED} mime types IncludeExclude@77e73a5e{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@77ff8ceb,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@15c956d4}
13:33:22.625 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@617bcd95{STOPPED} added {o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STOPPED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,UNAVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@617bcd95{STOPPED},UNMANAGED}
13:33:22.626 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,UNAVAILABLE,@Spark}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,STARTING,@Spark}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@5d4d16c5{STOPPED}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-bec89fa[EMBEDDED:null]
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-bec89fa@a45f1a8e==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-72d200c0=org.apache.spark.ui.HttpSecurityFilter-72d200c0@72d200c0==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-72d200c0]
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-bec89fa=org.apache.spark.ui.JettyUtils$$anon$1-bec89fa@a45f1a8e==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@5d4d16c5{STARTING}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27498ms ServletHandler@5d4d16c5{STARTED}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-72d200c0@72d200c0==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27498ms org.apache.spark.ui.HttpSecurityFilter-72d200c0@72d200c0==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@2ae1369d
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-bec89fa@a45f1a8e==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27498ms org.apache.spark.ui.JettyUtils$$anon$1-bec89fa@a45f1a8e==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@641adc55 for org.apache.spark.ui.JettyUtils$$anon$1-bec89fa
13:33:22.627 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27498ms o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@617bcd95{STOPPED}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@617bcd95{STARTING}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27498ms GzipHandler@617bcd95{STARTED}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@30a9082a{STOPPED} mime types IncludeExclude@135f857c{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@21151b36,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@2582529}
13:33:22.627 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@30a9082a{STOPPED} added {o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STOPPED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@30a9082a{STOPPED},UNMANAGED}
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,UNAVAILABLE,@Spark}
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,STARTING,@Spark}
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@c1e7acb{STOPPED}
13:33:22.628 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-63d281eb[EMBEDDED:null]
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-63d281eb@b937ff4f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-6f099ce9=org.apache.spark.ui.HttpSecurityFilter-6f099ce9@6f099ce9==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-6f099ce9]
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-63d281eb=org.apache.spark.ui.JettyUtils$$anon$1-63d281eb@b937ff4f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@c1e7acb{STARTING}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27500ms ServletHandler@c1e7acb{STARTED}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-6f099ce9@6f099ce9==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27500ms org.apache.spark.ui.HttpSecurityFilter-6f099ce9@6f099ce9==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@7ac88510
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-63d281eb@b937ff4f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27500ms org.apache.spark.ui.JettyUtils$$anon$1-63d281eb@b937ff4f==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@15d38b50 for org.apache.spark.ui.JettyUtils$$anon$1-63d281eb
13:33:22.629 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27500ms o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@30a9082a{STOPPED}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@30a9082a{STARTING}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27500ms GzipHandler@30a9082a{STARTED}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@5fa4e1a1{STOPPED} mime types IncludeExclude@61fa0f40{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@687a9124,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@43b4af1a}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@5fa4e1a1{STOPPED} added {o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.629 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STOPPED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,UNAVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@5fa4e1a1{STOPPED},UNMANAGED}
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,UNAVAILABLE,@Spark}
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,STARTING,@Spark}
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@2476ef5d{STOPPED}
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-7ab8adb3[EMBEDDED:null]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-7ab8adb3@9f760fc2==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.630 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-1c96fe77=org.apache.spark.ui.HttpSecurityFilter-1c96fe77@1c96fe77==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-1c96fe77]
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7ab8adb3=org.apache.spark.ui.JettyUtils$$anon$1-7ab8adb3@9f760fc2==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@2476ef5d{STARTING}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27502ms ServletHandler@2476ef5d{STARTED}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-1c96fe77@1c96fe77==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27502ms org.apache.spark.ui.HttpSecurityFilter-1c96fe77@1c96fe77==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@3b65e724
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-7ab8adb3@9f760fc2==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27502ms org.apache.spark.ui.JettyUtils$$anon$1-7ab8adb3@9f760fc2==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@ad46f07 for org.apache.spark.ui.JettyUtils$$anon$1-7ab8adb3
13:33:22.631 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27502ms o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@5fa4e1a1{STOPPED}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@5fa4e1a1{STARTING}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27502ms GzipHandler@5fa4e1a1{STARTED}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@5031996e{STOPPED} mime types IncludeExclude@4479188b{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@6d7cfb54,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@2eee75f}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@5031996e{STOPPED} added {o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.631 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STOPPED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@5031996e{STOPPED},UNMANAGED}
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,UNAVAILABLE,@Spark}
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,STARTING,@Spark}
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@5f577802{STOPPED}
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-603d936e[EMBEDDED:null]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-603d936e@c9a8e482==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-361b2cc8=org.apache.spark.ui.HttpSecurityFilter-361b2cc8@361b2cc8==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-361b2cc8]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-603d936e=org.apache.spark.ui.JettyUtils$$anon$1-603d936e@c9a8e482==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@5f577802{STARTING}
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27504ms ServletHandler@5f577802{STARTED}
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-361b2cc8@361b2cc8==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27504ms org.apache.spark.ui.HttpSecurityFilter-361b2cc8@361b2cc8==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@5e48e485
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-603d936e@c9a8e482==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27504ms org.apache.spark.ui.JettyUtils$$anon$1-603d936e@c9a8e482==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.632 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@52f90287 for org.apache.spark.ui.JettyUtils$$anon$1-603d936e
13:33:22.632 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27504ms o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@5031996e{STOPPED}
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@5031996e{STARTING}
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27504ms GzipHandler@5031996e{STARTED}
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@2df4258d{STOPPED} mime types IncludeExclude@3401907a{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@2ef64147,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@59fae213}
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@2df4258d{STOPPED} added {o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.633 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STOPPED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,UNAVAILABLE,@Spark}]}]
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@2df4258d{STOPPED},UNMANAGED}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,UNAVAILABLE,@Spark}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,STARTING,@Spark}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@617c87ea{STOPPED}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-41873d4e[EMBEDDED:null]
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-41873d4e@34d8dcec==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-58d5e5d7=org.apache.spark.ui.HttpSecurityFilter-58d5e5d7@58d5e5d7==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-58d5e5d7]
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-41873d4e=org.apache.spark.ui.JettyUtils$$anon$1-41873d4e@34d8dcec==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@617c87ea{STARTING}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27505ms ServletHandler@617c87ea{STARTED}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-58d5e5d7@58d5e5d7==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27505ms org.apache.spark.ui.HttpSecurityFilter-58d5e5d7@58d5e5d7==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@552e6cec
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-41873d4e@34d8dcec==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27505ms org.apache.spark.ui.JettyUtils$$anon$1-41873d4e@34d8dcec==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@6d94b473 for org.apache.spark.ui.JettyUtils$$anon$1-41873d4e
13:33:22.634 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27506ms o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@2df4258d{STOPPED}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@2df4258d{STARTING}
13:33:22.634 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27506ms GzipHandler@2df4258d{STARTED}
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@7f10b2a8{STOPPED} mime types IncludeExclude@59fff8aa{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@1180f8ca,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@41c3add1}
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@7f10b2a8{STOPPED} added {o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STOPPED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.635 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@7f10b2a8{STOPPED},UNMANAGED}
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,UNAVAILABLE,@Spark}
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,STARTING,@Spark}
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@3f3b357d{STOPPED}
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-47ae0299[EMBEDDED:null]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-47ae0299@babb12b7==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-71f42cff=org.apache.spark.ui.HttpSecurityFilter-71f42cff@71f42cff==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-71f42cff]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-47ae0299=org.apache.spark.ui.JettyUtils$$anon$1-47ae0299@babb12b7==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@3f3b357d{STARTING}
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27508ms ServletHandler@3f3b357d{STARTED}
13:33:22.636 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-71f42cff@71f42cff==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27508ms org.apache.spark.ui.HttpSecurityFilter-71f42cff@71f42cff==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@3bbcd2b3
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-47ae0299@babb12b7==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27508ms org.apache.spark.ui.JettyUtils$$anon$1-47ae0299@babb12b7==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@1da057c6 for org.apache.spark.ui.JettyUtils$$anon$1-47ae0299
13:33:22.637 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27508ms o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@7f10b2a8{STOPPED}
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@7f10b2a8{STARTING}
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27508ms GzipHandler@7f10b2a8{STARTED}
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@5781238a{STOPPED} mime types IncludeExclude@af54a83{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@1574327c,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@1bda2ae8}
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@5781238a{STOPPED} added {o.s.j.s.ServletContextHandler@62f67baf{/static,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STOPPED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,UNAVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.637 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@5781238a{STOPPED},UNMANAGED}
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@62f67baf{/static,null,UNAVAILABLE,@Spark}
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@62f67baf{/static,null,STARTING,@Spark}
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@557b17a2{STOPPED}
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.DefaultServlet-37308f07[EMBEDDED:null]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.sparkproject.jetty.servlet.DefaultServlet-37308f07@3d49687e==org.sparkproject.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-b70aa10=org.apache.spark.ui.HttpSecurityFilter-b70aa10@b70aa10==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-b70aa10]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.sparkproject.jetty.servlet.DefaultServlet-37308f07=org.sparkproject.jetty.servlet.DefaultServlet-37308f07@3d49687e==org.sparkproject.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,async=true}
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@557b17a2{STARTING}
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27509ms ServletHandler@557b17a2{STARTED}
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-b70aa10@b70aa10==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27509ms org.apache.spark.ui.HttpSecurityFilter-b70aa10@b70aa10==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@4519c76a
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.sparkproject.jetty.servlet.DefaultServlet-37308f07@3d49687e==org.sparkproject.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,async=true
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27510ms org.sparkproject.jetty.servlet.DefaultServlet-37308f07@3d49687e==org.sparkproject.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,async=true
13:33:22.638 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.sparkproject.jetty.servlet.DefaultServlet@65183c18 for org.sparkproject.jetty.servlet.DefaultServlet-37308f07
13:33:22.645 [run-main-0] DEBUG org.sparkproject.jetty.servlet.DefaultServlet - resource base = jar:file:/Users/alexrehnbymartin/dev/spark-connector/examples/basic-write/target/bg-jobs/sbt_e870df37/target/6b739db9/34ac2578/spark-vertica-connector-assembly-1.0.jar!/org/apache/spark/ui/static
13:33:22.645 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}
13:33:22.645 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27516ms o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}
13:33:22.645 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@5781238a{STOPPED}
13:33:22.645 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@5781238a{STARTING}
13:33:22.645 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27517ms GzipHandler@5781238a{STARTED}
13:33:22.645 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.645 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@35fbf6fa{STOPPED} mime types IncludeExclude@3a77a066{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@67f4aaf,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@67a772b8}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@35fbf6fa{STOPPED} added {o.s.j.s.ServletContextHandler@5b2f8aec{/,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STOPPED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,UNAVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@35fbf6fa{STOPPED},UNMANAGED}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@5b2f8aec{/,null,UNAVAILABLE,@Spark}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@5b2f8aec{/,null,STARTING,@Spark}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@68547e39{STOPPED}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-34e9b25b[EMBEDDED:null]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$2-34e9b25b@aceeb7bf==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7bf34959=org.apache.spark.ui.HttpSecurityFilter-7bf34959@7bf34959==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-7bf34959]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-34e9b25b=org.apache.spark.ui.JettyUtils$$anon$2-34e9b25b@aceeb7bf==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@68547e39{STARTING}
13:33:22.646 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27518ms ServletHandler@68547e39{STARTED}
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-7bf34959@7bf34959==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27518ms org.apache.spark.ui.HttpSecurityFilter-7bf34959@7bf34959==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@d811490
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$2-34e9b25b@aceeb7bf==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27518ms org.apache.spark.ui.JettyUtils$$anon$2-34e9b25b@aceeb7bf==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@af2f1d6 for org.apache.spark.ui.JettyUtils$$anon$2-34e9b25b
13:33:22.647 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27518ms o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@35fbf6fa{STOPPED}
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@35fbf6fa{STARTING}
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27518ms GzipHandler@35fbf6fa{STARTED}
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@2a4a76db{STOPPED} mime types IncludeExclude@2f6ad296{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@328bfaec,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@633ed8e8}
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@2a4a76db{STOPPED} added {o.s.j.s.ServletContextHandler@5150614c{/api,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STARTED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}]}]
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:22.647 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - api->[{GzipHandler@2a4a76db{STOPPED},[o.s.j.s.ServletContextHandler@5150614c{/api,null,UNAVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@2a4a76db{STOPPED},UNMANAGED}
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@5150614c{/api,null,UNAVAILABLE,@Spark}
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@5150614c{/api,null,STARTING,@Spark}
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@a68d02b{STOPPED}
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-30c891f9[EMBEDDED:null]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/*",pathDepth=1,group=PREFIX_GLOB],resource=org.glassfish.jersey.servlet.ServletContainer-30c891f9@2221308b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,async=true] to PathMappings[size=1]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7624e815=org.apache.spark.ui.HttpSecurityFilter-7624e815@7624e815==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-7624e815]
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.648 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-30c891f9=org.glassfish.jersey.servlet.ServletContainer-30c891f9@2221308b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,async=true}
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Adding Default404Servlet to ServletHandler@a68d02b{STARTING}
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/*[EMBEDDED:null] mapped to servlet=org.glassfish.jersey.servlet.ServletContainer-30c891f9[EMBEDDED:null]
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/*",pathDepth=1,group=PREFIX_GLOB],resource=org.glassfish.jersey.servlet.ServletContainer-30c891f9@2221308b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,async=true] to PathMappings[size=1]
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-e0dd358[EMBEDDED:null]
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-e0dd358@fb4076ae==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,async=true] to PathMappings[size=2]
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-7624e815=org.apache.spark.ui.HttpSecurityFilter-7624e815@7624e815==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-7624e815]
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=2]
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.glassfish.jersey.servlet.ServletContainer-30c891f9=org.glassfish.jersey.servlet.ServletContainer-30c891f9@2221308b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,async=true, org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-e0dd358=org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-e0dd358@fb4076ae==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,async=true}
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@a68d02b{STARTING}
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27520ms ServletHandler@a68d02b{STARTED}
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-7624e815@7624e815==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27520ms org.apache.spark.ui.HttpSecurityFilter-7624e815@7624e815==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@1be1a3e9
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.glassfish.jersey.servlet.ServletContainer-30c891f9@2221308b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,async=true
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27521ms org.glassfish.jersey.servlet.ServletContainer-30c891f9@2221308b==org.glassfish.jersey.servlet.ServletContainer,jsp=null,order=-1,inst=false,async=true
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-e0dd358@fb4076ae==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,async=true
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27521ms org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet-e0dd358@fb4076ae==org.sparkproject.jetty.servlet.ServletHandler$Default404Servlet,jsp=null,order=-1,inst=false,async=true
13:33:22.649 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27521ms o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}
13:33:22.649 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@2a4a76db{STOPPED}
13:33:22.650 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@2a4a76db{STARTING}
13:33:22.650 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27521ms GzipHandler@2a4a76db{STARTED}
13:33:22.650 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.650 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@5ede4694{STOPPED} mime types IncludeExclude@3ea9c904{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@28c1cbd3,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@2ebd86d0}
13:33:22.650 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@5ede4694{STOPPED} added {o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.650 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STARTED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}]}]
13:33:22.650 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - api->[{GzipHandler@2a4a76db{STARTED},[o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/kill->[{GzipHandler@5ede4694{STOPPED},[o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,UNAVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@5ede4694{STOPPED},UNMANAGED}
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,UNAVAILABLE,@Spark}
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,STARTING,@Spark}
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@1e99e239{STOPPED}
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-20b8996e[EMBEDDED:null]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$2-20b8996e@6c3573b0==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-5dab7a29=org.apache.spark.ui.HttpSecurityFilter-5dab7a29@5dab7a29==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-5dab7a29]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-20b8996e=org.apache.spark.ui.JettyUtils$$anon$2-20b8996e@6c3573b0==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true}
13:33:22.651 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@1e99e239{STARTING}
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27523ms ServletHandler@1e99e239{STARTED}
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-5dab7a29@5dab7a29==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27523ms org.apache.spark.ui.HttpSecurityFilter-5dab7a29@5dab7a29==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@2fb8f75
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$2-20b8996e@6c3573b0==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27523ms org.apache.spark.ui.JettyUtils$$anon$2-20b8996e@6c3573b0==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@72ea97c7 for org.apache.spark.ui.JettyUtils$$anon$2-20b8996e
13:33:22.652 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,AVAILABLE,@Spark}
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27523ms o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,AVAILABLE,@Spark}
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@5ede4694{STOPPED}
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@5ede4694{STARTING}
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27523ms GzipHandler@5ede4694{STARTED}
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@161ad246{STOPPED} mime types IncludeExclude@48c467d7{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@6eb685a7,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@2083e6ee}
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@161ad246{STOPPED} added {o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STARTED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}]}]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - api->[{GzipHandler@2a4a76db{STARTED},[o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}]}]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:22.652 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/kill->[{GzipHandler@161ad246{STOPPED},[o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,UNAVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/kill->[{GzipHandler@5ede4694{STARTED},[o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@161ad246{STOPPED},UNMANAGED}
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,UNAVAILABLE,@Spark}
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,STARTING,@Spark}
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@2d3ea8ab{STOPPED}
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$2-95f3716[EMBEDDED:null]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$2-95f3716@6e0360e6==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-5453551a=org.apache.spark.ui.HttpSecurityFilter-5453551a@5453551a==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-5453551a]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-95f3716=org.apache.spark.ui.JettyUtils$$anon$2-95f3716@6e0360e6==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true}
13:33:22.653 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@2d3ea8ab{STARTING}
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27525ms ServletHandler@2d3ea8ab{STARTED}
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-5453551a@5453551a==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27525ms org.apache.spark.ui.HttpSecurityFilter-5453551a@5453551a==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@604b885a
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$2-95f3716@6e0360e6==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27525ms org.apache.spark.ui.JettyUtils$$anon$2-95f3716@6e0360e6==org.apache.spark.ui.JettyUtils$$anon$2,jsp=null,order=-1,inst=true,async=true
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$2@b5aa15b for org.apache.spark.ui.JettyUtils$$anon$2-95f3716
13:33:22.654 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,AVAILABLE,@Spark}
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27525ms o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,AVAILABLE,@Spark}
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@161ad246{STOPPED}
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@161ad246{STARTING}
13:33:22.654 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27525ms GzipHandler@161ad246{STARTED}
13:33:22.655 [run-main-0] INFO org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.0.26:4040
13:33:22.746 [run-main-0] INFO org.apache.spark.executor.Executor - Starting executor ID driver on host 192.168.0.26
13:33:22.765 [run-main-0] DEBUG org.apache.spark.network.server.TransportServer - Shuffle server started on port: 54331
13:33:22.765 [run-main-0] INFO org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 54331.
13:33:22.766 [run-main-0] INFO org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.0.26:54331
13:33:22.767 [run-main-0] INFO org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
13:33:22.772 [run-main-0] INFO org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.0.26, 54331, None)
13:33:22.774 [dispatcher-BlockManagerMaster] DEBUG org.apache.spark.storage.DefaultTopologyMapper - Got a request for 192.168.0.26
13:33:22.774 [dispatcher-BlockManagerMaster] INFO org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.0.26:54331 with 417.9 MiB RAM, BlockManagerId(driver, 192.168.0.26, 54331, None)
13:33:22.776 [run-main-0] INFO org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.0.26, 54331, None)
13:33:22.777 [run-main-0] INFO org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.0.26, 54331, None)
13:33:22.944 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@5f10d67c
13:33:22.945 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@45201e20{/,null,UNAVAILABLE} added {ServletHandler@55627090{STOPPED},MANAGED}
13:33:22.946 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:22.946 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@382bed39{STOPPED} mime types IncludeExclude@3ce74065{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@40a7c71f,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@59236460}
13:33:22.946 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@382bed39{STOPPED} added {o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:22.946 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STARTED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - api->[{GzipHandler@2a4a76db{STARTED},[o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/kill->[{GzipHandler@161ad246{STARTED},[o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/kill->[{GzipHandler@5ede4694{STARTED},[o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - metrics/json->[{GzipHandler@382bed39{STOPPED},[o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,UNAVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@382bed39{STOPPED},UNMANAGED}
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,UNAVAILABLE,@Spark}
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,STARTING,@Spark}
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@55627090{STOPPED}
13:33:22.947 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-78471bcb[EMBEDDED:null]
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-78471bcb@d7f3b542==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-43eb5edd=org.apache.spark.ui.HttpSecurityFilter-43eb5edd@43eb5edd==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-43eb5edd]
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-78471bcb=org.apache.spark.ui.JettyUtils$$anon$1-78471bcb@d7f3b542==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@55627090{STARTING}
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27819ms ServletHandler@55627090{STARTED}
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-43eb5edd@43eb5edd==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27819ms org.apache.spark.ui.HttpSecurityFilter-43eb5edd@43eb5edd==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@3e861858
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-78471bcb@d7f3b542==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27819ms org.apache.spark.ui.JettyUtils$$anon$1-78471bcb@d7f3b542==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@38649385 for org.apache.spark.ui.JettyUtils$$anon$1-78471bcb
13:33:22.948 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,AVAILABLE,@Spark}
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27819ms o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,AVAILABLE,@Spark}
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@382bed39{STOPPED}
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@382bed39{STARTING}
13:33:22.948 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @27819ms GzipHandler@382bed39{STARTED}
13:33:22.963 [run-main-0] DEBUG org.apache.spark.SparkContext - Adding shutdown hook
13:33:24.206 [run-main-0] INFO org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/Users/alexrehnbymartin/dev/spark-connector/examples/basic-write/spark-warehouse').
13:33:24.207 [run-main-0] INFO org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/Users/alexrehnbymartin/dev/spark-connector/examples/basic-write/spark-warehouse'.
13:33:24.208 [run-main-0] DEBUG org.apache.spark.sql.internal.SharedState - Applying initial SparkSession options to SparkConf/HadoopConf: spark.app.name -> Vertica Connector Test Prototype
13:33:24.208 [run-main-0] DEBUG org.apache.spark.sql.internal.SharedState - Applying initial SparkSession options to SparkConf/HadoopConf: spark.master -> local[*]
13:33:24.221 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@5f8bff68
13:33:24.221 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@1ba6cd92{/,null,UNAVAILABLE} added {ServletHandler@43ab28df{STOPPED},MANAGED}
13:33:24.221 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@e4b9f51
13:33:24.221 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@232c1957{/,null,UNAVAILABLE} added {ServletHandler@39db203d{STOPPED},MANAGED}
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@7cf83472{STOPPED} mime types IncludeExclude@1cc22918{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@79bc7b1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@53b12521}
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@7cf83472{STOPPED} added {o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,UNAVAILABLE,@Spark},MANAGED}
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STARTED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - api->[{GzipHandler@2a4a76db{STARTED},[o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL->[{GzipHandler@7cf83472{STOPPED},[o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,UNAVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/kill->[{GzipHandler@161ad246{STARTED},[o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/kill->[{GzipHandler@5ede4694{STARTED},[o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - metrics/json->[{GzipHandler@382bed39{STARTED},[o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@7cf83472{STOPPED},UNMANAGED}
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,UNAVAILABLE,@Spark}
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,STARTING,@Spark}
13:33:24.222 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@43ab28df{STOPPED}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-ebb5151[EMBEDDED:null]
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-ebb5151@3de3a9af==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-3f5d746f=org.apache.spark.ui.HttpSecurityFilter-3f5d746f@3f5d746f==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-3f5d746f]
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-ebb5151=org.apache.spark.ui.JettyUtils$$anon$1-ebb5151@3de3a9af==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@43ab28df{STARTING}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29094ms ServletHandler@43ab28df{STARTED}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-3f5d746f@3f5d746f==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29094ms org.apache.spark.ui.HttpSecurityFilter-3f5d746f@3f5d746f==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@6e57d081
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-ebb5151@3de3a9af==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29094ms org.apache.spark.ui.JettyUtils$$anon$1-ebb5151@3de3a9af==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@6350aeba for org.apache.spark.ui.JettyUtils$$anon$1-ebb5151
13:33:24.223 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,AVAILABLE,@Spark}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29094ms o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,AVAILABLE,@Spark}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@7cf83472{STOPPED}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@7cf83472{STARTING}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29094ms GzipHandler@7cf83472{STARTED}
13:33:24.223 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@60edf977{STOPPED} mime types IncludeExclude@306eee33{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@56ada3fa,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@161b643a}
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@60edf977{STOPPED} added {o.s.j.s.ServletContextHandler@232c1957{/SQL/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STARTED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - api->[{GzipHandler@2a4a76db{STARTED},[o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL->[{GzipHandler@7cf83472{STARTED},[o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,AVAILABLE,@Spark}]}]
13:33:24.224 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/kill->[{GzipHandler@161ad246{STARTED},[o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL/json->[{GzipHandler@60edf977{STOPPED},[o.s.j.s.ServletContextHandler@232c1957{/SQL/json,null,UNAVAILABLE,@Spark}]}]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/kill->[{GzipHandler@5ede4694{STARTED},[o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - metrics/json->[{GzipHandler@382bed39{STARTED},[o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,AVAILABLE,@Spark}]}]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@60edf977{STOPPED},UNMANAGED}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@232c1957{/SQL/json,null,UNAVAILABLE,@Spark}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@232c1957{/SQL/json,null,STARTING,@Spark}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@39db203d{STOPPED}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-6d3ecf8e[EMBEDDED:null]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-6d3ecf8e@888edc7e==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-3aaf4b2e=org.apache.spark.ui.HttpSecurityFilter-3aaf4b2e@3aaf4b2e==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-3aaf4b2e]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6d3ecf8e=org.apache.spark.ui.JettyUtils$$anon$1-6d3ecf8e@888edc7e==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@39db203d{STARTING}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29096ms ServletHandler@39db203d{STARTED}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-3aaf4b2e@3aaf4b2e==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29096ms org.apache.spark.ui.HttpSecurityFilter-3aaf4b2e@3aaf4b2e==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@19b201cf
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-6d3ecf8e@888edc7e==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29096ms org.apache.spark.ui.JettyUtils$$anon$1-6d3ecf8e@888edc7e==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@5e6a7bbc for org.apache.spark.ui.JettyUtils$$anon$1-6d3ecf8e
13:33:24.225 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@232c1957{/SQL/json,null,AVAILABLE,@Spark}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29097ms o.s.j.s.ServletContextHandler@232c1957{/SQL/json,null,AVAILABLE,@Spark}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@60edf977{STOPPED}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@60edf977{STARTING}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29097ms GzipHandler@60edf977{STARTED}
13:33:24.225 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@281433ca
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@21a1e37e{/,null,UNAVAILABLE} added {ServletHandler@2c1bdb6d{STOPPED},MANAGED}
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@5d8c204f
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@73989293{/,null,UNAVAILABLE} added {ServletHandler@12aef3e{STOPPED},MANAGED}
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@209d579f{STOPPED} mime types IncludeExclude@76980fad{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@7907a9c1,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@5c9b4c40}
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@209d579f{STOPPED} added {o.s.j.s.ServletContextHandler@21a1e37e{/SQL/execution,null,UNAVAILABLE,@Spark},MANAGED}
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STARTED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - api->[{GzipHandler@2a4a76db{STARTED},[o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL->[{GzipHandler@7cf83472{STARTED},[o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/kill->[{GzipHandler@161ad246{STARTED},[o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL/json->[{GzipHandler@60edf977{STARTED},[o.s.j.s.ServletContextHandler@232c1957{/SQL/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/kill->[{GzipHandler@5ede4694{STARTED},[o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - metrics/json->[{GzipHandler@382bed39{STARTED},[o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,AVAILABLE,@Spark}]}]
13:33:24.226 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL/execution->[{GzipHandler@209d579f{STOPPED},[o.s.j.s.ServletContextHandler@21a1e37e{/SQL/execution,null,UNAVAILABLE,@Spark}]}]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@209d579f{STOPPED},UNMANAGED}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@21a1e37e{/SQL/execution,null,UNAVAILABLE,@Spark}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@21a1e37e{/SQL/execution,null,STARTING,@Spark}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@2c1bdb6d{STOPPED}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-540fd367[EMBEDDED:null]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-540fd367@3071d593==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-172653e2=org.apache.spark.ui.HttpSecurityFilter-172653e2@172653e2==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-172653e2]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-540fd367=org.apache.spark.ui.JettyUtils$$anon$1-540fd367@3071d593==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@2c1bdb6d{STARTING}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29098ms ServletHandler@2c1bdb6d{STARTED}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-172653e2@172653e2==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29098ms org.apache.spark.ui.HttpSecurityFilter-172653e2@172653e2==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@16f0d9e3
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-540fd367@3071d593==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29098ms org.apache.spark.ui.JettyUtils$$anon$1-540fd367@3071d593==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@202349f7 for org.apache.spark.ui.JettyUtils$$anon$1-540fd367
13:33:24.227 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@21a1e37e{/SQL/execution,null,AVAILABLE,@Spark}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29098ms o.s.j.s.ServletContextHandler@21a1e37e{/SQL/execution,null,AVAILABLE,@Spark}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@209d579f{STOPPED}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@209d579f{STARTING}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29098ms GzipHandler@209d579f{STARTED}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@62510c0a{STOPPED} mime types IncludeExclude@727efe62{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@48a86d2b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@59bb5b80}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@62510c0a{STOPPED} added {o.s.j.s.ServletContextHandler@73989293{/SQL/execution/json,null,UNAVAILABLE,@Spark},MANAGED}
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STARTED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}]}]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL/execution/json->[{GzipHandler@62510c0a{STOPPED},[o.s.j.s.ServletContextHandler@73989293{/SQL/execution/json,null,UNAVAILABLE,@Spark}]}]
13:33:24.227 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - api->[{GzipHandler@2a4a76db{STARTED},[o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}]}]
13:33:24.241 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:24.241 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:24.241 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL->[{GzipHandler@7cf83472{STARTED},[o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/kill->[{GzipHandler@161ad246{STARTED},[o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL/json->[{GzipHandler@60edf977{STARTED},[o.s.j.s.ServletContextHandler@232c1957{/SQL/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/kill->[{GzipHandler@5ede4694{STARTED},[o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - metrics/json->[{GzipHandler@382bed39{STARTED},[o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL/execution->[{GzipHandler@209d579f{STARTED},[o.s.j.s.ServletContextHandler@21a1e37e{/SQL/execution,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@62510c0a{STOPPED},UNMANAGED}
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@73989293{/SQL/execution/json,null,UNAVAILABLE,@Spark}
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@73989293{/SQL/execution/json,null,STARTING,@Spark}
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@12aef3e{STOPPED}
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.apache.spark.ui.JettyUtils$$anon$1-2b149097[EMBEDDED:null]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.apache.spark.ui.JettyUtils$$anon$1-2b149097@790d9f36==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:24.242 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-64aeb593=org.apache.spark.ui.HttpSecurityFilter-64aeb593@64aeb593==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-64aeb593]
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2b149097=org.apache.spark.ui.JettyUtils$$anon$1-2b149097@790d9f36==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@12aef3e{STARTING}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29114ms ServletHandler@12aef3e{STARTED}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-64aeb593@64aeb593==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29114ms org.apache.spark.ui.HttpSecurityFilter-64aeb593@64aeb593==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@33602de1
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.JettyUtils$$anon$1-2b149097@790d9f36==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29114ms org.apache.spark.ui.JettyUtils$$anon$1-2b149097@790d9f36==org.apache.spark.ui.JettyUtils$$anon$1,jsp=null,order=-1,inst=true,async=true
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.apache.spark.ui.JettyUtils$$anon$1@36684801 for org.apache.spark.ui.JettyUtils$$anon$1-2b149097
13:33:24.243 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@73989293{/SQL/execution/json,null,AVAILABLE,@Spark}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29114ms o.s.j.s.ServletContextHandler@73989293{/SQL/execution/json,null,AVAILABLE,@Spark}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@62510c0a{STOPPED}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@62510c0a{STARTING}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29114ms GzipHandler@62510c0a{STARTED}
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.DecoratedObjectFactory - Adding Decorator: org.sparkproject.jetty.util.DeprecationWarning@78a7d56f
13:33:24.243 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - o.s.j.s.ServletContextHandler@50fb8493{/,null,UNAVAILABLE} added {ServletHandler@5a3aacd8{STOPPED},MANAGED}
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["*.svgz",pathDepth=0,group=SUFFIX_GLOB],resource=true] to PathMappings[size=1]
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.gzip.GzipHandler - GzipHandler@2ff7a5d0{STOPPED} mime types IncludeExclude@c503cce{i=[],ip=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@6857905b,e=[image/ief, image/vnd.wap.wbmp, image/jpeg, application/bzip2, image/x-portable-graymap, application/brotli, image/bmp, image/gif, image/x-icon, audio/midi, video/x-msvideo, image/x-xbitmap, application/x-rar-compressed, image/x-portable-bitmap, image/x-rgb, image/x-cmu-raster, application/gzip, audio/x-wav, audio/x-pn-realaudio, audio/basic, application/compress, audio/x-aiff, video/x.ms.asx, video/x.ms.asf, image/png, video/vnd.rn-realvideo, image/x-xwindowdump, image/jpeg2000, video/x-sgi-movie, audio/mpeg, image/xcf, video/mpeg, image/x-portable-pixmap, image/tiff, image/x-portable-anymap, image/x-xpixmap, application/zip, video/quicktime, application/x-xz, video/mp4],ep=org.sparkproject.jetty.util.IncludeExcludeSet$SetContainsPredicate@7bd4eb33}
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - GzipHandler@2ff7a5d0{STOPPED} added {o.s.j.s.ServletContextHandler@50fb8493{/static/sql,null,UNAVAILABLE,@Spark},MANAGED}
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - ->[{GzipHandler@35fbf6fa{STARTED},[o.s.j.s.ServletContextHandler@5b2f8aec{/,null,AVAILABLE,@Spark}]}]
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd->[{GzipHandler@4b96991c{STARTED},[o.s.j.s.ServletContextHandler@60eb4960{/storage/rdd,null,AVAILABLE,@Spark}]}]
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage->[{GzipHandler@5b250b15{STARTED},[o.s.j.s.ServletContextHandler@344240e1{/storage,null,AVAILABLE,@Spark}]}]
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/rdd/json->[{GzipHandler@15e109f4{STARTED},[o.s.j.s.ServletContextHandler@58d924a5{/storage/rdd/json,null,AVAILABLE,@Spark}]}]
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL/execution/json->[{GzipHandler@62510c0a{STARTED},[o.s.j.s.ServletContextHandler@73989293{/SQL/execution/json,null,AVAILABLE,@Spark}]}]
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - api->[{GzipHandler@2a4a76db{STARTED},[o.s.j.s.ServletContextHandler@5150614c{/api,null,AVAILABLE,@Spark}]}]
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool/json->[{GzipHandler@7763f356{STARTED},[o.s.j.s.ServletContextHandler@681f775e{/stages/pool/json,null,AVAILABLE,@Spark}]}]
13:33:24.263 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/pool->[{GzipHandler@58a90a11{STARTED},[o.s.j.s.ServletContextHandler@22f8bd2c{/stages/pool,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/json->[{GzipHandler@58ceda2b{STARTED},[o.s.j.s.ServletContextHandler@20993309{/jobs/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static->[{GzipHandler@5781238a{STARTED},[o.s.j.s.ServletContextHandler@62f67baf{/static,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/json->[{GzipHandler@5031996e{STARTED},[o.s.j.s.ServletContextHandler@4cc86ac1{/executors/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/json->[{GzipHandler@79055b92{STARTED},[o.s.j.s.ServletContextHandler@4029d3fe{/stages/stage/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump/json->[{GzipHandler@7f10b2a8{STARTED},[o.s.j.s.ServletContextHandler@3a7db60f{/executors/threadDump/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment/json->[{GzipHandler@30a9082a{STARTED},[o.s.j.s.ServletContextHandler@39d0b80a{/environment/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/json->[{GzipHandler@6f1113a6{STARTED},[o.s.j.s.ServletContextHandler@1585ae95{/jobs/job/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs->[{GzipHandler@7e90d931{STARTED},[o.s.j.s.ServletContextHandler@6ec1f6cb{/jobs,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/json->[{GzipHandler@5be53c91{STARTED},[o.s.j.s.ServletContextHandler@2ad8515f{/stages/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage->[{GzipHandler@64a5f478{STARTED},[o.s.j.s.ServletContextHandler@79df367{/stages/stage,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - storage/json->[{GzipHandler@13daa51{STARTED},[o.s.j.s.ServletContextHandler@3872925a{/storage/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL->[{GzipHandler@7cf83472{STARTED},[o.s.j.s.ServletContextHandler@1ba6cd92{/SQL,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - static/sql->[{GzipHandler@2ff7a5d0{STOPPED},[o.s.j.s.ServletContextHandler@50fb8493{/static/sql,null,UNAVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages/stage/kill->[{GzipHandler@161ad246{STARTED},[o.s.j.s.ServletContextHandler@6ab155fa{/stages/stage/kill,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job->[{GzipHandler@634f4b43{STARTED},[o.s.j.s.ServletContextHandler@34f9bf66{/jobs/job,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - environment->[{GzipHandler@617bcd95{STARTED},[o.s.j.s.ServletContextHandler@6151a2c2{/environment,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - stages->[{GzipHandler@3b55c14b{STARTED},[o.s.j.s.ServletContextHandler@576a576a{/stages,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors->[{GzipHandler@5fa4e1a1{STARTED},[o.s.j.s.ServletContextHandler@35d5d01b{/executors,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL/json->[{GzipHandler@60edf977{STARTED},[o.s.j.s.ServletContextHandler@232c1957{/SQL/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - jobs/job/kill->[{GzipHandler@5ede4694{STARTED},[o.s.j.s.ServletContextHandler@5110fe15{/jobs/job/kill,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - metrics/json->[{GzipHandler@382bed39{STARTED},[o.s.j.s.ServletContextHandler@45201e20{/metrics/json,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - SQL/execution->[{GzipHandler@209d579f{STARTED},[o.s.j.s.ServletContextHandler@21a1e37e{/SQL/execution,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.ContextHandlerCollection - executors/threadDump->[{GzipHandler@2df4258d{STARTED},[o.s.j.s.ServletContextHandler@6dd6dfdd{/executors/threadDump,null,AVAILABLE,@Spark}]}]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.util.component.ContainerLifeCycle - ContextHandlerCollection@6bcc8098{STARTED} added {GzipHandler@2ff7a5d0{STOPPED},UNMANAGED}
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting o.s.j.s.ServletContextHandler@50fb8493{/static/sql,null,UNAVAILABLE,@Spark}
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting o.s.j.s.ServletContextHandler@50fb8493{/static/sql,null,STARTING,@Spark}
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting ServletHandler@5a3aacd8{STOPPED}
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - Path=/[EMBEDDED:null] mapped to servlet=org.sparkproject.jetty.servlet.DefaultServlet-b759d8a[EMBEDDED:null]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.http.pathmap.PathMappings - Added MappedResource[pathSpec=ServletPathSpec["/",pathDepth=-1,group=DEFAULT],resource=org.sparkproject.jetty.servlet.DefaultServlet-b759d8a@23bab9ec==org.sparkproject.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,async=true] to PathMappings[size=1]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - filterNameMap={org.apache.spark.ui.HttpSecurityFilter-15a0d614=org.apache.spark.ui.HttpSecurityFilter-15a0d614@15a0d614==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true}
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - pathFilters=[[/*]/[]/[ERROR, FORWARD, REQUEST, ASYNC, INCLUDE]=>org.apache.spark.ui.HttpSecurityFilter-15a0d614]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletFilterMap={}
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletPathMap=PathMappings[size=1]
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHandler - servletNameMap={org.sparkproject.jetty.servlet.DefaultServlet-b759d8a=org.sparkproject.jetty.servlet.DefaultServlet-b759d8a@23bab9ec==org.sparkproject.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,async=true}
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting ServletHandler@5a3aacd8{STARTING}
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29136ms ServletHandler@5a3aacd8{STARTED}
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.apache.spark.ui.HttpSecurityFilter-15a0d614@15a0d614==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.264 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29136ms org.apache.spark.ui.HttpSecurityFilter-15a0d614@15a0d614==org.apache.spark.ui.HttpSecurityFilter,inst=true,async=true
13:33:24.265 [run-main-0] DEBUG org.sparkproject.jetty.servlet.FilterHolder - Filter.init org.apache.spark.ui.HttpSecurityFilter@699f18bc
13:33:24.265 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting org.sparkproject.jetty.servlet.DefaultServlet-b759d8a@23bab9ec==org.sparkproject.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,async=true
13:33:24.265 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29136ms org.sparkproject.jetty.servlet.DefaultServlet-b759d8a@23bab9ec==org.sparkproject.jetty.servlet.DefaultServlet,jsp=null,order=-1,inst=true,async=true
13:33:24.265 [run-main-0] DEBUG org.sparkproject.jetty.servlet.ServletHolder - Servlet.init org.sparkproject.jetty.servlet.DefaultServlet@64a4ff0d for org.sparkproject.jetty.servlet.DefaultServlet-b759d8a
13:33:24.265 [run-main-0] DEBUG org.sparkproject.jetty.servlet.DefaultServlet - resource base = jar:file:/Users/alexrehnbymartin/dev/spark-connector/examples/basic-write/target/bg-jobs/sbt_e870df37/target/6b739db9/34ac2578/spark-vertica-connector-assembly-1.0.jar!/org/apache/spark/sql/execution/ui/static
13:33:24.265 [run-main-0] INFO org.sparkproject.jetty.server.handler.ContextHandler - Started o.s.j.s.ServletContextHandler@50fb8493{/static/sql,null,AVAILABLE,@Spark}
13:33:24.265 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29136ms o.s.j.s.ServletContextHandler@50fb8493{/static/sql,null,AVAILABLE,@Spark}
13:33:24.265 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - starting GzipHandler@2ff7a5d0{STOPPED}
13:33:24.265 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - starting GzipHandler@2ff7a5d0{STARTING}
13:33:24.265 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STARTED @29136ms GzipHandler@2ff7a5d0{STARTED}
13:33:24.867 [run-main-0] DEBUG org.apache.spark.util.ClosureCleaner - Expected a closure; got org.apache.spark.sql.catalyst.encoders.ExpressionEncoder$Serializer
[col1: int]
EXTRACT CATALOG OPTIONS: 
>>> key=host, value=localhost
>>> key=db, value=docker
>>> key=staging_fs_url, value=hdfs://hdfs:8020/data/
>>> key=logging_level, value=DEBUG
>>> key=user, value=dbadmin
>>> key=table, value=dftest
>>> key=password, value=
CATALOG OPTIONS: 
Loading table with OPTIONS: 
>>> key=host, value=localhost
>>> key=db, value=docker
>>> key=staging_fs_url, value=hdfs://hdfs:8020/data/
>>> key=logging_level, value=DEBUG
>>> key=user, value=dbadmin
>>> key=table, value=dftest
>>> key=password, value=
13:33:25.665 [run-main-0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Connecting to Vertica with URI: jdbc:vertica://localhost:5433/docker
13:33:30.797 [run-main-0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Successfully connected to Vertica.
13:33:30.800 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to send query: SELECT * FROM "dftest" WHERE 1=0
The type is: -5
The type name is: Integer
13:33:30.917 [run-main-0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Connecting to Vertica with URI: jdbc:vertica://localhost:5433/docker
13:33:35.929 [run-main-0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Successfully connected to Vertica.
13:33:35.929 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to send query: SELECT * FROM "dftest" WHERE 1=0
The type is: -5
The type name is: Integer
13:33:35.935 [run-main-0] DEBUG com.vertica.spark.datasource.v2.VerticaTable - Config loaded
13:33:36.258 [run-main-0] DEBUG com.vertica.spark.datasource.v2.VerticaTable - Config loaded
13:33:36.259 [run-main-0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Connecting to Vertica with URI: jdbc:vertica://localhost:5433/docker
13:33:41.270 [run-main-0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Successfully connected to Vertica.
13:33:41.317 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to execute statement: DROP TABLE IF EXISTS "dftest"
13:33:41.359 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to send query: select count(*) from v_catalog.tables where table_schema ILIKE 'public' and table_name ILIKE 'dftest'
13:33:41.405 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to send query: select count(*) from views where table_schema ILIKE 'public' and table_name ILIKE 'dftest'
13:33:41.634 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to send query:  select is_temp_table as t from v_catalog.tables where table_name='dftest' and table_schema='public'
13:33:41.651 [run-main-0] DEBUG com.vertica.spark.util.table.TableUtils - colname="col1"; type=IntegerType; nullable=true
13:33:41.652 [run-main-0] DEBUG com.vertica.spark.util.table.TableUtils - BUILDING TABLE WITH COMMAND: CREATE table "dftest" ("col1" INTEGER)  INCLUDE SCHEMA PRIVILEGES 
13:33:41.652 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to execute statement: CREATE table "dftest" ("col1" INTEGER)  INCLUDE SCHEMA PRIVILEGES 
13:33:41.664 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to send query: select count(*) from v_catalog.tables where table_schema ILIKE 'public' and table_name ILIKE 'dftest'
13:33:41.673 [run-main-0] DEBUG com.vertica.spark.datasource.fs.HadoopFileStoreLayer - Filestore path: hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0
13:33:41.731 [run-main-0] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.use.legacy.blockreader.local = false
13:33:41.731 [run-main-0] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.read.shortcircuit = false
13:33:41.731 [run-main-0] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal - dfs.client.domain.socket.data.traffic = false
13:33:41.731 [run-main-0] DEBUG org.apache.hadoop.hdfs.BlockReaderLocal - dfs.domain.socket.path = 
13:33:41.784 [run-main-0] DEBUG org.apache.hadoop.io.retry.RetryUtils - multipleLinearRandomRetry = null
13:33:41.801 [run-main-0] DEBUG org.apache.hadoop.ipc.Server - rpcKind=RPC_PROTOCOL_BUFFER, rpcRequestWrapperClass=class org.apache.hadoop.ipc.ProtobufRpcEngine$RpcRequestWrapper, rpcInvoker=org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker@427d86a0
13:33:41.805 [run-main-0] DEBUG org.apache.hadoop.ipc.Client - getting client out of cache: org.apache.hadoop.ipc.Client@309107b1
13:33:42.052 [run-main-0] DEBUG org.apache.hadoop.util.PerformanceAdvisory - Both short-circuit local reads and UNIX domain socket are disabled.
13:33:42.059 [run-main-0] DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.DataTransferSaslUtil - DataTransferProtocol not using SaslPropertiesResolver, no QOP found in configuration for dfs.data.transfer.protection
13:33:42.084 [run-main-0] DEBUG org.apache.hadoop.ipc.Client - The ping interval is 60000 ms.
13:33:42.086 [run-main-0] DEBUG org.apache.hadoop.ipc.Client - Connecting to hdfs/127.0.0.1:8020
13:33:42.098 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin: starting, having connections 1
13:33:42.100 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #0
13:33:42.141 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #0
13:33:42.141 [run-main-0] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 73ms
13:33:42.155 [run-main-0] DEBUG org.apache.hadoop.hdfs.DFSClient - /data/0aff0984_55cf_4cef_9cf5_4d2146411eb0: masked=rwxr-xr-x
13:33:42.175 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #1
13:33:42.192 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #1
13:33:42.192 [run-main-0] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: mkdirs took 18ms
13:33:42.194 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to send query: select count(*) from v_catalog.tables where table_schema ILIKE 'public' and table_name ILIKE 'S2V_JOB_STATUS_USER_DBADMIN'
13:33:42.204 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to execute statement: INSERT into public.S2V_JOB_STATUS_USER_DBADMIN VALUES ('public','dftest','OVERWRITE','0aff0984_55cf_4cef_9cf5_4d2146411eb0','2021-03-01 13:33:42.194',false,false,-1.0)
13:33:42.235 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Commiting.
13:33:42.299 [run-main-0] DEBUG org.apache.spark.sql.execution.WholeStageCodegenExec - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator rdd_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] rdd_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     rdd_input_0 = inputs[0];
/* 020 */     rdd_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( rdd_input_0.hasNext()) {
/* 026 */       InternalRow rdd_row_0 = (InternalRow) rdd_input_0.next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       boolean rdd_isNull_0 = rdd_row_0.isNullAt(0);
/* 029 */       int rdd_value_0 = rdd_isNull_0 ?
/* 030 */       -1 : (rdd_row_0.getInt(0));
/* 031 */       rdd_mutableStateArray_0[0].reset();
/* 032 */
/* 033 */       rdd_mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */       if (rdd_isNull_0) {
/* 036 */         rdd_mutableStateArray_0[0].setNullAt(0);
/* 037 */       } else {
/* 038 */         rdd_mutableStateArray_0[0].write(0, rdd_value_0);
/* 039 */       }
/* 040 */       append((rdd_mutableStateArray_0[0].getRow()));
/* 041 */       if (shouldStop()) return;
/* 042 */     }
/* 043 */   }
/* 044 */
/* 045 */ }

13:33:42.314 [run-main-0] DEBUG org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator rdd_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] rdd_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     rdd_input_0 = inputs[0];
/* 020 */     rdd_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( rdd_input_0.hasNext()) {
/* 026 */       InternalRow rdd_row_0 = (InternalRow) rdd_input_0.next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       boolean rdd_isNull_0 = rdd_row_0.isNullAt(0);
/* 029 */       int rdd_value_0 = rdd_isNull_0 ?
/* 030 */       -1 : (rdd_row_0.getInt(0));
/* 031 */       rdd_mutableStateArray_0[0].reset();
/* 032 */
/* 033 */       rdd_mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */       if (rdd_isNull_0) {
/* 036 */         rdd_mutableStateArray_0[0].setNullAt(0);
/* 037 */       } else {
/* 038 */         rdd_mutableStateArray_0[0].write(0, rdd_value_0);
/* 039 */       }
/* 040 */       append((rdd_mutableStateArray_0[0].getRow()));
/* 041 */       if (shouldStop()) return;
/* 042 */     }
/* 043 */   }
/* 044 */
/* 045 */ }

13:33:42.466 [run-main-0] INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 165.398497 ms
13:33:42.468 [run-main-0] DEBUG org.apache.spark.util.ClosureCleaner - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
13:33:42.486 [run-main-0] DEBUG org.apache.spark.util.ClosureCleaner -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
13:33:42.545 [run-main-0] DEBUG org.apache.spark.sql.execution.WholeStageCodegenExec - 
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIteratorForCodegenStage1(references);
/* 003 */ }
/* 004 */
/* 005 */ // codegenStageId=1
/* 006 */ final class GeneratedIteratorForCodegenStage1 extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 007 */   private Object[] references;
/* 008 */   private scala.collection.Iterator[] inputs;
/* 009 */   private scala.collection.Iterator rdd_input_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] rdd_mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public GeneratedIteratorForCodegenStage1(Object[] references) {
/* 013 */     this.references = references;
/* 014 */   }
/* 015 */
/* 016 */   public void init(int index, scala.collection.Iterator[] inputs) {
/* 017 */     partitionIndex = index;
/* 018 */     this.inputs = inputs;
/* 019 */     rdd_input_0 = inputs[0];
/* 020 */     rdd_mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 021 */
/* 022 */   }
/* 023 */
/* 024 */   protected void processNext() throws java.io.IOException {
/* 025 */     while ( rdd_input_0.hasNext()) {
/* 026 */       InternalRow rdd_row_0 = (InternalRow) rdd_input_0.next();
/* 027 */       ((org.apache.spark.sql.execution.metric.SQLMetric) references[0] /* numOutputRows */).add(1);
/* 028 */       boolean rdd_isNull_0 = rdd_row_0.isNullAt(0);
/* 029 */       int rdd_value_0 = rdd_isNull_0 ?
/* 030 */       -1 : (rdd_row_0.getInt(0));
/* 031 */       rdd_mutableStateArray_0[0].reset();
/* 032 */
/* 033 */       rdd_mutableStateArray_0[0].zeroOutNullBytes();
/* 034 */
/* 035 */       if (rdd_isNull_0) {
/* 036 */         rdd_mutableStateArray_0[0].setNullAt(0);
/* 037 */       } else {
/* 038 */         rdd_mutableStateArray_0[0].write(0, rdd_value_0);
/* 039 */       }
/* 040 */       append((rdd_mutableStateArray_0[0].getRow()));
/* 041 */       if (shouldStop()) return;
/* 042 */     }
/* 043 */   }
/* 044 */
/* 045 */ }

13:33:42.546 [run-main-0] DEBUG org.apache.spark.util.ClosureCleaner - Cleaning indylambda closure: $anonfun$doExecute$4$adapted
13:33:42.548 [run-main-0] DEBUG org.apache.spark.util.ClosureCleaner -  +++ indylambda closure ($anonfun$doExecute$4$adapted) is now cleaned +++
13:33:42.566 [run-main-0] INFO org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec - Start processing data source write support: com.vertica.spark.datasource.v2.VerticaBatchWrite@18af712b. The input RDD has 1 partitions.
13:33:42.569 [run-main-0] DEBUG org.apache.spark.util.ClosureCleaner - Cleaning indylambda closure: $anonfun$writeWithV2$2
13:33:42.570 [run-main-0] DEBUG org.apache.spark.util.ClosureCleaner -  +++ indylambda closure ($anonfun$writeWithV2$2) is now cleaned +++
13:33:42.583 [run-main-0] INFO org.apache.spark.SparkContext - Starting job: save at Main.scala:49
13:33:42.598 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Got job 0 (save at Main.scala:49) with 1 output partitions
13:33:42.598 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (save at Main.scala:49)
13:33:42.599 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
13:33:42.599 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
13:33:42.601 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler - submitStage(ResultStage 0 (name=save at Main.scala:49;jobs=0))
13:33:42.601 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler - missing: List()
13:33:42.602 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (CoalescedRDD[4] at save at Main.scala:49), which has no missing parents
13:33:42.603 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler - submitMissingTasks(ResultStage 0)
13:33:42.692 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 11.4 KiB, free 417.9 MiB)
13:33:42.693 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager - Put block broadcast_0 locally took 22 ms
13:33:42.694 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager - Putting block broadcast_0 without replication took 23 ms
13:33:42.722 [dag-scheduler-event-loop] INFO org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 5.8 KiB, free 417.9 MiB)
13:33:42.724 [dispatcher-BlockManagerMaster] INFO org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 192.168.0.26:54331 (size: 5.8 KiB, free: 417.9 MiB)
13:33:42.725 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManagerMaster - Updated info of block broadcast_0_piece0
13:33:42.725 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager - Told master about block broadcast_0_piece0
13:33:42.725 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager - Put block broadcast_0_piece0 locally took 4 ms
13:33:42.725 [dag-scheduler-event-loop] DEBUG org.apache.spark.storage.BlockManager - Putting block broadcast_0_piece0 without replication took 4 ms
13:33:42.726 [dag-scheduler-event-loop] INFO org.apache.spark.SparkContext - Created broadcast 0 from broadcast at DAGScheduler.scala:1200
13:33:42.738 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (CoalescedRDD[4] at save at Main.scala:49) (first 15 tasks are for partitions Vector(0))
13:33:42.739 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks
13:33:42.757 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager - Epoch for TaskSet 0.0: 0
13:33:42.759 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager - Adding pending tasks took 1 ms
13:33:42.760 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.TaskSetManager - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
13:33:42.768 [dispatcher-event-loop-12] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0.0, runningTasks: 0
13:33:42.768 [dispatcher-event-loop-12] DEBUG org.apache.spark.scheduler.TaskSetManager - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
13:33:42.783 [dispatcher-event-loop-12] INFO org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0, 192.168.0.26, executor driver, partition 0, PROCESS_LOCAL, 8256 bytes)
13:33:42.785 [dispatcher-event-loop-12] DEBUG org.apache.spark.scheduler.TaskSetManager - No tasks for locality level NO_PREF, so moving to locality level ANY
13:33:42.791 [Executor task launch worker for task 0] INFO org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
13:33:42.801 [Executor task launch worker for task 0] DEBUG org.apache.spark.executor.ExecutorMetricsPoller - stageTCMP: (0, 0) -> 1
13:33:42.824 [Executor task launch worker for task 0] DEBUG org.apache.spark.storage.BlockManager - Getting local block broadcast_0
13:33:42.825 [Executor task launch worker for task 0] DEBUG org.apache.spark.storage.BlockManager - Level for block broadcast_0 is StorageLevel(disk, memory, deserialized, 1 replicas)
13:33:42.960 [Executor task launch worker for task 0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Connecting to Vertica with URI: jdbc:vertica://localhost:5433/docker
13:33:47.972 [Executor task launch worker for task 0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Successfully connected to Vertica.
13:33:47.982 [Executor task launch worker for task 0] DEBUG com.vertica.spark.datasource.fs.HadoopFileStoreLayer - Opening write to file: hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet
13:33:48.005 [Executor task launch worker for task 0] DEBUG com.vertica.spark.datasource.fs.HadoopFileStoreLayer - Filestore path: hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet
13:33:48.006 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #2
13:33:48.009 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #2
13:33:48.009 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 3ms
13:33:48.051 [Executor task launch worker for task 0] INFO org.apache.spark.sql.execution.datasources.parquet.ParquetWriteSupport - Initialized Parquet WriteSupport with Catalyst schema:
{
  "type" : "struct",
  "fields" : [ {
    "name" : "col1",
    "type" : "integer",
    "nullable" : true,
    "metadata" : { }
  } ]
}
and corresponding Parquet message type:
message spark_schema {
  optional int32 col1;
}

       
13:33:48.069 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.hdfs.DFSClient - /data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet: masked=rw-r--r--
13:33:48.097 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #3
13:33:48.110 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #3
13:33:48.110 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: create took 14ms
13:33:48.117 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.hdfs.DFSClient - computePacketChunkSize: src=/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet, chunkSize=516, chunksPerPacket=126, packetSize=65016
13:33:48.126 [LeaseRenewer:alexrehnbymartin@hdfs:8020] DEBUG org.apache.hadoop.hdfs.LeaseRenewer - Lease renewer daemon for [DFSClient_NONMAPREDUCE_1720432260_150] with renew id 1 started
13:33:48.129 [Executor task launch worker for task 0] DEBUG org.apache.parquet.hadoop.ParquetFileWriter - 0: start
13:33:48.152 [Executor task launch worker for task 0] DEBUG org.apache.parquet.column.values.rle.RunLengthBitPackingHybridEncoder - Encoding: RunLengthBitPackingHybridEncoder with bithWidth: 1 initialCapacity 64
13:33:48.152 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.CapacityByteArrayOutputStream - initial slab of size 64
13:33:48.280 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.CapacityByteArrayOutputStream - initial slab of size 1024
13:33:48.316 [Executor task launch worker for task 0] DEBUG org.apache.spark.sql.catalyst.expressions.codegen.GenerateUnsafeProjection - code for if (assertnotnull(input[0, org.apache.spark.sql.Row, true]).isNullAt) null else validateexternaltype(getexternalrowfield(assertnotnull(input[0, org.apache.spark.sql.Row, true]), 0, col1), IntegerType):
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private int argValue_0;
/* 009 */   private boolean globalIsNull_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public SpecificUnsafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */
/* 015 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   // Scala.Function1 need this
/* 024 */   public java.lang.Object apply(java.lang.Object row) {
/* 025 */     return apply((InternalRow) row);
/* 026 */   }
/* 027 */
/* 028 */   public UnsafeRow apply(InternalRow i) {
/* 029 */     mutableStateArray_0[0].reset();
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 033 */
/* 034 */     int value_10 = If_0(i);
/* 035 */     if (globalIsNull_0) {
/* 036 */       mutableStateArray_0[0].setNullAt(0);
/* 037 */     } else {
/* 038 */       mutableStateArray_0[0].write(0, value_10);
/* 039 */     }
/* 040 */     return (mutableStateArray_0[0].getRow());
/* 041 */   }
/* 042 */
/* 043 */
/* 044 */   private int If_0(InternalRow i) {
/* 045 */     boolean isNull_3 = i.isNullAt(0);
/* 046 */     org.apache.spark.sql.Row value_3 = isNull_3 ?
/* 047 */     null : ((org.apache.spark.sql.Row)i.get(0, null));
/* 048 */     if (isNull_3) {
/* 049 */       throw new NullPointerException(((java.lang.String) references[0] /* errMsg */));
/* 050 */     }
/* 051 */     boolean isNull_1 = true;
/* 052 */     boolean value_1 = false;
/* 053 */     if (!false) {
/* 054 */
/* 055 */
/* 056 */       argValue_0 = 0;
/* 057 */
/* 058 */       isNull_1 = false;
/* 059 */       if (!isNull_1) {
/* 060 */         value_1 = value_3.isNullAt(argValue_0);
/* 061 */       }
/* 062 */     }
/* 063 */     boolean isNull_0 = false;
/* 064 */     int value_0 = -1;
/* 065 */     if (!isNull_1 && value_1) {
/* 066 */
/* 067 */       isNull_0 = true;
/* 068 */       value_0 = -1;
/* 069 */     } else {
/* 070 */       boolean isNull_9 = i.isNullAt(0);
/* 071 */       org.apache.spark.sql.Row value_9 = isNull_9 ?
/* 072 */       null : ((org.apache.spark.sql.Row)i.get(0, null));
/* 073 */       if (isNull_9) {
/* 074 */         throw new NullPointerException(((java.lang.String) references[3] /* errMsg */));
/* 075 */       }
/* 076 */
/* 077 */       if (false) {
/* 078 */         throw new RuntimeException("The input external row cannot be null.");
/* 079 */       }
/* 080 */
/* 081 */       if (value_9.isNullAt(0)) {
/* 082 */         throw new RuntimeException(((java.lang.String) references[2] /* errMsg */));
/* 083 */       }
/* 084 */
/* 085 */       final Object value_7 = value_9.get(0);
/* 086 */       int value_6 = -1;
/* 087 */       if (!false) {
/* 088 */         if (value_7 instanceof Integer) {
/* 089 */           value_6 = (Integer) value_7;
/* 090 */         } else {
/* 091 */           throw new RuntimeException(value_7.getClass().getName() + ((java.lang.String) references[1] /* errMsg */));
/* 092 */         }
/* 093 */       }
/* 094 */       isNull_0 = false;
/* 095 */       value_0 = value_6;
/* 096 */     }
/* 097 */     globalIsNull_0 = isNull_0;
/* 098 */     return value_0;
/* 099 */   }
/* 100 */
/* 101 */ }

13:33:48.318 [Executor task launch worker for task 0] DEBUG org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - 
/* 001 */ public java.lang.Object generate(Object[] references) {
/* 002 */   return new SpecificUnsafeProjection(references);
/* 003 */ }
/* 004 */
/* 005 */ class SpecificUnsafeProjection extends org.apache.spark.sql.catalyst.expressions.UnsafeProjection {
/* 006 */
/* 007 */   private Object[] references;
/* 008 */   private int argValue_0;
/* 009 */   private boolean globalIsNull_0;
/* 010 */   private org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[] mutableStateArray_0 = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter[1];
/* 011 */
/* 012 */   public SpecificUnsafeProjection(Object[] references) {
/* 013 */     this.references = references;
/* 014 */
/* 015 */     mutableStateArray_0[0] = new org.apache.spark.sql.catalyst.expressions.codegen.UnsafeRowWriter(1, 0);
/* 016 */
/* 017 */   }
/* 018 */
/* 019 */   public void initialize(int partitionIndex) {
/* 020 */
/* 021 */   }
/* 022 */
/* 023 */   // Scala.Function1 need this
/* 024 */   public java.lang.Object apply(java.lang.Object row) {
/* 025 */     return apply((InternalRow) row);
/* 026 */   }
/* 027 */
/* 028 */   public UnsafeRow apply(InternalRow i) {
/* 029 */     mutableStateArray_0[0].reset();
/* 030 */
/* 031 */
/* 032 */     mutableStateArray_0[0].zeroOutNullBytes();
/* 033 */
/* 034 */     int value_10 = If_0(i);
/* 035 */     if (globalIsNull_0) {
/* 036 */       mutableStateArray_0[0].setNullAt(0);
/* 037 */     } else {
/* 038 */       mutableStateArray_0[0].write(0, value_10);
/* 039 */     }
/* 040 */     return (mutableStateArray_0[0].getRow());
/* 041 */   }
/* 042 */
/* 043 */
/* 044 */   private int If_0(InternalRow i) {
/* 045 */     boolean isNull_3 = i.isNullAt(0);
/* 046 */     org.apache.spark.sql.Row value_3 = isNull_3 ?
/* 047 */     null : ((org.apache.spark.sql.Row)i.get(0, null));
/* 048 */     if (isNull_3) {
/* 049 */       throw new NullPointerException(((java.lang.String) references[0] /* errMsg */));
/* 050 */     }
/* 051 */     boolean isNull_1 = true;
/* 052 */     boolean value_1 = false;
/* 053 */     if (!false) {
/* 054 */
/* 055 */
/* 056 */       argValue_0 = 0;
/* 057 */
/* 058 */       isNull_1 = false;
/* 059 */       if (!isNull_1) {
/* 060 */         value_1 = value_3.isNullAt(argValue_0);
/* 061 */       }
/* 062 */     }
/* 063 */     boolean isNull_0 = false;
/* 064 */     int value_0 = -1;
/* 065 */     if (!isNull_1 && value_1) {
/* 066 */
/* 067 */       isNull_0 = true;
/* 068 */       value_0 = -1;
/* 069 */     } else {
/* 070 */       boolean isNull_9 = i.isNullAt(0);
/* 071 */       org.apache.spark.sql.Row value_9 = isNull_9 ?
/* 072 */       null : ((org.apache.spark.sql.Row)i.get(0, null));
/* 073 */       if (isNull_9) {
/* 074 */         throw new NullPointerException(((java.lang.String) references[3] /* errMsg */));
/* 075 */       }
/* 076 */
/* 077 */       if (false) {
/* 078 */         throw new RuntimeException("The input external row cannot be null.");
/* 079 */       }
/* 080 */
/* 081 */       if (value_9.isNullAt(0)) {
/* 082 */         throw new RuntimeException(((java.lang.String) references[2] /* errMsg */));
/* 083 */       }
/* 084 */
/* 085 */       final Object value_7 = value_9.get(0);
/* 086 */       int value_6 = -1;
/* 087 */       if (!false) {
/* 088 */         if (value_7 instanceof Integer) {
/* 089 */           value_6 = (Integer) value_7;
/* 090 */         } else {
/* 091 */           throw new RuntimeException(value_7.getClass().getName() + ((java.lang.String) references[1] /* errMsg */));
/* 092 */         }
/* 093 */       }
/* 094 */       isNull_0 = false;
/* 095 */       value_0 = value_6;
/* 096 */     }
/* 097 */     globalIsNull_0 = isNull_0;
/* 098 */     return value_0;
/* 099 */   }
/* 100 */
/* 101 */ }

13:33:48.334 [Executor task launch worker for task 0] INFO org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 17.614275 ms
13:33:48.337 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.RecordConsumerLoggingWrapper - <!-- start message -->
13:33:48.337 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - < MESSAGE START >
13:33:48.337 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - 0, VistedIndex{vistedIndexes={}}: [] r:0
13:33:48.337 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.RecordConsumerLoggingWrapper - <col1>
13:33:48.337 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - startField(col1, 0)
13:33:48.337 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - 0, VistedIndex{vistedIndexes={}}: [col1] r:0
13:33:48.337 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.ValidatingRecordConsumer - validate INT32 for col1
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.RecordConsumerLoggingWrapper - 77
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - addInt(77)
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - r: 0
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - 0, VistedIndex{vistedIndexes={}}: [col1] r:0
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.RecordConsumerLoggingWrapper - </col1>
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - endField(col1, 0)
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - 0, VistedIndex{vistedIndexes={0}}: [] r:0
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - < MESSAGE END >
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.MessageColumnIO - 0, VistedIndex{vistedIndexes={0}}: [] r:0
13:33:48.338 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.RecordConsumerLoggingWrapper - <!-- end message -->
13:33:48.345 [dispatcher-event-loop-0] DEBUG org.apache.spark.scheduler.OutputCommitCoordinator - Commit allowed for stage=0.0, partition=0, task attempt 0
13:33:48.346 [Executor task launch worker for task 0] INFO org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Commit authorized for partition 0 (task 0, attempt 0, stage 0.0)
13:33:48.346 [Executor task launch worker for task 0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Closing connection.
13:33:48.347 [Executor task launch worker for task 0] DEBUG org.apache.parquet.io.RecordConsumerLoggingWrapper - <!-- flush -->
13:33:48.348 [Executor task launch worker for task 0] INFO org.apache.parquet.hadoop.InternalParquetRecordWriter - Flushing mem columnStore to file. allocated memory: 8
13:33:48.348 [Executor task launch worker for task 0] DEBUG org.apache.parquet.hadoop.ParquetFileWriter - 4: start block
13:33:48.348 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.CapacityByteArrayOutputStream - used 0 slabs, adding new slab of size 64
13:33:48.349 [Executor task launch worker for task 0] DEBUG org.apache.parquet.column.values.dictionary.DictionaryValuesWriter - max dic id 0
13:33:48.349 [Executor task launch worker for task 0] DEBUG org.apache.parquet.column.values.rle.RunLengthBitPackingHybridEncoder - Encoding: RunLengthBitPackingHybridEncoder with bithWidth: 0 initialCapacity 1024
13:33:48.349 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.CapacityByteArrayOutputStream - initial slab of size 1024
13:33:48.349 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.CapacityByteArrayOutputStream - used 0 slabs, adding new slab of size 1024
13:33:48.349 [Executor task launch worker for task 0] DEBUG org.apache.parquet.column.values.dictionary.DictionaryValuesWriter - rle encoded bytes 1
13:33:48.349 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput - BytesInput from array of 1 bytes
13:33:48.354 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.CapacityByteArrayOutputStream - used 0 slabs, adding new slab of size 1024
13:33:48.354 [Executor task launch worker for task 0] DEBUG org.apache.parquet.column.values.plain.PlainValuesWriter - writing a buffer of size 4
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - write 45 bytes to out
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - write 10 bytes to out
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - {
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - write 0 bytes to out
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - write 6 bytes to out
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - {
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - write 4 bytes to out
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesUtils - write le int: 2 => 2 0 0 0
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - write 2 bytes to out
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - }
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - write 4 bytes to out
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput$SequenceBytesIn - }
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesInput - converted 55 to byteArray of 55 bytes
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.CapacityByteArrayOutputStream - initial slab of size 64
13:33:48.376 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.CapacityByteArrayOutputStream - initial slab of size 1024
13:33:48.377 [Executor task launch worker for task 0] DEBUG org.apache.parquet.hadoop.ParquetFileWriter - 4: write data pages
13:33:48.377 [Executor task launch worker for task 0] DEBUG org.apache.parquet.hadoop.ParquetFileWriter - 4: write data pages content
13:33:48.377 [Executor task launch worker for task 0] DEBUG org.apache.parquet.hadoop.ParquetFileWriter - 59: end column
13:33:48.379 [Executor task launch worker for task 0] DEBUG org.apache.parquet.hadoop.ColumnChunkPageWriteStore - written 55B for [col1] optional int32 col1: 1 values, 10B raw, 10B comp, 1 pages, encodings: [PLAIN]
13:33:48.379 [Executor task launch worker for task 0] DEBUG org.apache.parquet.hadoop.ParquetFileWriter - 59: end block
13:33:48.379 [Executor task launch worker for task 0] DEBUG org.apache.parquet.hadoop.ParquetFileWriter - 59: end
13:33:48.406 [Executor task launch worker for task 0] DEBUG org.apache.parquet.hadoop.ParquetFileWriter - 423: footer length = 364
13:33:48.407 [Executor task launch worker for task 0] DEBUG org.apache.parquet.bytes.BytesUtils - write le int: 364 => 108 1 0 0
13:33:48.408 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.hdfs.DFSClient - DFSClient writeChunk allocating new packet seqno=0, src=/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet, packetSize=65016, chunksPerPacket=126, bytesCurBlock=0
13:33:48.408 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.hdfs.DFSClient - Queued packet 0
13:33:48.408 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.hdfs.DFSClient - Queued packet 1
13:33:48.408 [Thread-21] DEBUG org.apache.hadoop.hdfs.DFSClient - Allocating new block
13:33:48.409 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.hdfs.DFSClient - Waiting for ack for: 1
13:33:48.420 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #4
13:33:48.452 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #4
13:33:48.452 [Thread-21] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: addBlock took 32ms
13:33:48.459 [Thread-21] DEBUG org.apache.hadoop.hdfs.DFSClient - pipeline = DatanodeInfoWithStorage[127.0.0.1:50010,DS-dff28839-8b17-4288-8fc0-ca2a5fd4a20b,DISK]
13:33:48.459 [Thread-21] DEBUG org.apache.hadoop.hdfs.DFSClient - Connecting to datanode 127.0.0.1:50010
13:33:48.460 [Thread-21] DEBUG org.apache.hadoop.hdfs.DFSClient - Send buf size 131072
13:33:48.460 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #5
13:33:48.469 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #5
13:33:48.469 [Thread-21] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getServerDefaults took 9ms
13:33:48.473 [Thread-21] DEBUG org.apache.hadoop.hdfs.protocol.datatransfer.sasl.SaslDataTransferClient - SASL client skipping handshake in unsecured configuration for addr = /127.0.0.1, datanodeId = DatanodeInfoWithStorage[127.0.0.1:50010,DS-dff28839-8b17-4288-8fc0-ca2a5fd4a20b,DISK]
13:33:48.578 [DataStreamer for file /data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet block BP-534744838-172.17.0.3-1542834499713:blk_1073741831_1007] DEBUG org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-534744838-172.17.0.3-1542834499713:blk_1073741831_1007 sending packet packet seqno: 0 offsetInBlock: 0 lastPacketInBlock: false lastByteOffsetInBlock: 431
13:33:48.689 [ResponseProcessor for block BP-534744838-172.17.0.3-1542834499713:blk_1073741831_1007] DEBUG org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 0 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
13:33:48.690 [DataStreamer for file /data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet block BP-534744838-172.17.0.3-1542834499713:blk_1073741831_1007] DEBUG org.apache.hadoop.hdfs.DFSClient - DataStreamer block BP-534744838-172.17.0.3-1542834499713:blk_1073741831_1007 sending packet packet seqno: 1 offsetInBlock: 431 lastPacketInBlock: true lastByteOffsetInBlock: 431
13:33:48.693 [ResponseProcessor for block BP-534744838-172.17.0.3-1542834499713:blk_1073741831_1007] DEBUG org.apache.hadoop.hdfs.DFSClient - DFSClient seqno: 1 reply: SUCCESS downstreamAckTimeNanos: 0 flag: 0
13:33:48.693 [DataStreamer for file /data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet block BP-534744838-172.17.0.3-1542834499713:blk_1073741831_1007] DEBUG org.apache.hadoop.hdfs.DFSClient - Closing old block BP-534744838-172.17.0.3-1542834499713:blk_1073741831_1007
13:33:48.694 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #6
13:33:48.702 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #6
13:33:48.702 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 8ms
13:33:49.105 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #7
13:33:49.112 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #7
13:33:49.112 [Executor task launch worker for task 0] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: complete took 8ms
13:33:49.114 [Executor task launch worker for task 0] INFO org.apache.spark.sql.execution.datasources.v2.DataWritingSparkTask - Committed partition 0 (task 0, attempt 0, stage 0.0)
13:33:49.132 [Executor task launch worker for task 0] INFO org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1392 bytes result sent to driver
13:33:49.132 [Executor task launch worker for task 0] DEBUG org.apache.spark.executor.ExecutorMetricsPoller - removing (0, 0) from stageTCMP
13:33:49.134 [dispatcher-event-loop-1] DEBUG org.apache.spark.scheduler.TaskSchedulerImpl - parentName: , name: TaskSet_0.0, runningTasks: 0
13:33:49.138 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 6366 ms on 192.168.0.26 (executor driver) (1/1)
13:33:49.140 [task-result-getter-0] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
13:33:49.144 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (save at Main.scala:49) finished in 6.533 s
13:33:49.147 [dag-scheduler-event-loop] DEBUG org.apache.spark.scheduler.DAGScheduler - After removal of stage 0, remaining stages = 0
13:33:49.148 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
13:33:49.148 [dag-scheduler-event-loop] INFO org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
13:33:49.149 [run-main-0] INFO org.apache.spark.scheduler.DAGScheduler - Job 0 finished: save at Main.scala:49, took 6.565408 s
13:33:49.152 [run-main-0] INFO org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec - Data source write support com.vertica.spark.datasource.v2.VerticaBatchWrite@18af712b is committing.
13:33:49.152 [run-main-0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Connecting to Vertica with URI: jdbc:vertica://localhost:5433/docker
13:33:54.160 [run-main-0] INFO com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Successfully connected to Vertica.
13:33:54.169 [run-main-0] INFO com.vertica.spark.datasource.core.VerticaDistributedFilesystemWritePipe - Building default copy column list
13:33:54.169 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to send query: SELECT * FROM "dftest" WHERE 1=0
13:33:54.175 [run-main-0] DEBUG com.vertica.spark.util.schema.SchemaTools - Will check that target column: col1 exist in DF
13:33:54.176 [run-main-0] DEBUG com.vertica.spark.util.schema.SchemaTools - Comparing target table column: col1 with DF column: col1
13:33:54.176 [run-main-0] DEBUG com.vertica.spark.util.schema.SchemaTools - Column: col1 found in target table and DF
13:33:54.176 [run-main-0] INFO com.vertica.spark.util.schema.SchemaTools - Load by name. Column list: ("col1")
13:33:54.177 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to execute statement: COPY "dftest" FROM '';
13:33:54.219 [run-main-0] ERROR com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Unexpected SQL Error.
java.sql.SQLException: [Vertica][VJDBC](3664) ERROR: Invalid filename. Input filename is an empty string
	at com.vertica.util.ServerErrorData.buildException(Unknown Source)
	at com.vertica.dataengine.VQueryExecutor.executeSimpleProtocol(Unknown Source)
	at com.vertica.dataengine.VQueryExecutor.execute(Unknown Source)
	at com.vertica.jdbc.common.SStatement.executeNoParams(SStatement.java:3349)
	at com.vertica.jdbc.common.SStatement.executeAnyUpdate(SStatement.java:1266)
	at com.vertica.jdbc.common.SStatement.executeUpdate(SStatement.java:1215)
	at com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.executeUpdate(VerticaJdbcLayer.scala:183)
	at com.vertica.spark.datasource.core.VerticaDistributedFilesystemWritePipe.performCopy(VerticaDistributedFilesystemWritePipe.scala:196)
	at com.vertica.spark.datasource.core.VerticaDistributedFilesystemWritePipe.$anonfun$commit$2(VerticaDistributedFilesystemWritePipe.scala:235)
	at scala.util.Either.flatMap(Either.scala:341)
	at com.vertica.spark.datasource.core.VerticaDistributedFilesystemWritePipe.commit(VerticaDistributedFilesystemWritePipe.scala:222)
	at com.vertica.spark.datasource.core.DSWriter.commitRows(DSWriter.scala:90)
	at com.vertica.spark.datasource.v2.VerticaBatchWrite.commit(VerticaDatasourceV2Write.scala:73)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:396)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:361)
	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.writeWithV2(WriteToDataSourceV2Exec.scala:273)
	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:286)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.doExecute(V2CommandExec.scala:54)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:944)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:944)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:342)
	at example.Main$.delayedEndpoint$example$Main$1(Main.scala:49)
	at example.Main$delayedInit$body.apply(Main.scala:23)
	at scala.Function0.apply$mcV$sp(Function0.scala:39)
	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
	at scala.App.$anonfun$main$1$adapted(App.scala:80)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at scala.App.main(App.scala:80)
	at scala.App.main$(App.scala:78)
	at example.Main$.main(Main.scala:23)
	at example.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sbt.Run.invokeMain(Run.scala:133)
	at sbt.Run.execute$1(Run.scala:82)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:110)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at sbt.util.InterfaceUtil$$anon$1.get(InterfaceUtil.scala:17)
	at sbt.TrapExit$App.run(TrapExit.scala:258)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.vertica.support.exceptions.ErrorException: [Vertica][VJDBC](3664) ERROR: Invalid filename. Input filename is an empty string
	... 57 common frames omitted
13:33:54.220 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to send query: EXPLAIN COPY "dftest" ("col1") FROM 'hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/*.parquet' ON ANY NODE parquet REJECTED DATA AS TABLE "dftest_0aff0984_55cf_4cef_9cf5_4d2146411eb0_COMMITS" NO COMMIT
13:33:54.277 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Attempting to execute statement: COPY "dftest" ("col1") FROM 'hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/*.parquet' ON ANY NODE parquet REJECTED DATA AS TABLE "dftest_0aff0984_55cf_4cef_9cf5_4d2146411eb0_COMMITS" NO COMMIT
13:33:54.304 [run-main-0] ERROR com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Unexpected SQL Error.
java.sql.SQLException: [Vertica][VJDBC](7253) ERROR: Error reading from Parquet parser input stream [hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet]: Failed to read "hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet" because of error: No datanodes available
	at com.vertica.util.ServerErrorData.buildException(Unknown Source)
	at com.vertica.dataengine.VResultSet.fetchChunk(Unknown Source)
	at com.vertica.dataengine.VResultSet.initialize(Unknown Source)
	at com.vertica.dataengine.VQueryExecutor.readExecuteResponse(Unknown Source)
	at com.vertica.dataengine.VQueryExecutor.handleExecuteResponse(Unknown Source)
	at com.vertica.dataengine.VQueryExecutor.execute(Unknown Source)
	at com.vertica.jdbc.common.SStatement.executeNoParams(SStatement.java:3349)
	at com.vertica.jdbc.common.SStatement.executeAnyUpdate(SStatement.java:1266)
	at com.vertica.jdbc.common.SStatement.executeUpdate(SStatement.java:1215)
	at com.vertica.spark.datasource.jdbc.VerticaJdbcLayer.executeUpdate(VerticaJdbcLayer.scala:183)
	at com.vertica.spark.datasource.core.VerticaDistributedFilesystemWritePipe.$anonfun$performCopy$2(VerticaDistributedFilesystemWritePipe.scala:205)
	at scala.util.Either.flatMap(Either.scala:341)
	at com.vertica.spark.datasource.core.VerticaDistributedFilesystemWritePipe.performCopy(VerticaDistributedFilesystemWritePipe.scala:201)
	at com.vertica.spark.datasource.core.VerticaDistributedFilesystemWritePipe.$anonfun$commit$2(VerticaDistributedFilesystemWritePipe.scala:235)
	at scala.util.Either.flatMap(Either.scala:341)
	at com.vertica.spark.datasource.core.VerticaDistributedFilesystemWritePipe.commit(VerticaDistributedFilesystemWritePipe.scala:222)
	at com.vertica.spark.datasource.core.DSWriter.commitRows(DSWriter.scala:90)
	at com.vertica.spark.datasource.v2.VerticaBatchWrite.commit(VerticaDatasourceV2Write.scala:73)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:396)
	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:361)
	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.writeWithV2(WriteToDataSourceV2Exec.scala:273)
	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:286)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)
	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.doExecute(V2CommandExec.scala:54)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)
	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)
	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:944)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:944)
	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:342)
	at example.Main$.delayedEndpoint$example$Main$1(Main.scala:49)
	at example.Main$delayedInit$body.apply(Main.scala:23)
	at scala.Function0.apply$mcV$sp(Function0.scala:39)
	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
	at scala.App.$anonfun$main$1$adapted(App.scala:80)
	at scala.collection.immutable.List.foreach(List.scala:431)
	at scala.App.main(App.scala:80)
	at scala.App.main$(App.scala:78)
	at example.Main$.main(Main.scala:23)
	at example.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at sbt.Run.invokeMain(Run.scala:133)
	at sbt.Run.execute$1(Run.scala:82)
	at sbt.Run.$anonfun$runWithLoader$5(Run.scala:110)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)
	at sbt.util.InterfaceUtil$$anon$1.get(InterfaceUtil.scala:17)
	at sbt.TrapExit$App.run(TrapExit.scala:258)
	at java.lang.Thread.run(Thread.java:748)
Caused by: com.vertica.support.exceptions.ErrorException: [Vertica][VJDBC](7253) ERROR: Error reading from Parquet parser input stream [hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet]: Failed to read "hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet" because of error: No datanodes available
	... 62 common frames omitted
13:33:54.305 [run-main-0] ERROR com.vertica.spark.datasource.core.VerticaDistributedFilesystemWritePipe - JDBC error when trying to copy: JDBCLayerError(JDBC error,[Vertica][VJDBC](7253) ERROR: Error reading from Parquet parser input stream [hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet]: Failed to read "hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0/0-0.parquet" because of error: No datanodes available)
13:33:54.307 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Commiting.
13:33:54.310 [run-main-0] DEBUG com.vertica.spark.datasource.fs.HadoopFileStoreLayer - Filestore path: hdfs://hdfs:8020/data/0aff0984_55cf_4cef_9cf5_4d2146411eb0
13:33:54.311 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #8
13:33:54.313 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #8
13:33:54.313 [run-main-0] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: getFileInfo took 2ms
13:33:54.315 [IPC Parameter Sending Thread #0] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin sending #9
13:33:54.323 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin got value #9
13:33:54.323 [run-main-0] DEBUG org.apache.hadoop.ipc.ProtobufRpcEngine - Call: delete took 8ms
13:33:54.325 [run-main-0] DEBUG com.vertica.spark.datasource.jdbc.VerticaJdbcLayer - Closing connection.
13:33:54.326 [run-main-0] ERROR org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec - Data source write support com.vertica.spark.datasource.v2.VerticaBatchWrite@18af712b is aborting.
13:33:54.326 [run-main-0] ERROR org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec - Data source write support com.vertica.spark.datasource.v2.VerticaBatchWrite@18af712b failed to abort.
13:33:54.329 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping Server@6979db37{STARTED}[9.4.z-SNAPSHOT]
13:33:54.329 [run-main-0] DEBUG org.sparkproject.jetty.server.Server - doStop Server@6979db37{STOPPING}[9.4.z-SNAPSHOT]
13:33:54.329 [SparkUI-189] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran SparkUI-189-acceptor-0@1a0c3363-ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:54.329 [SparkUI-190] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran SparkUI-190-acceptor-1@6d431906-ServerConnector@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:54.331 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandlerContainer - Graceful shutdown Server@6979db37{STOPPING}[9.4.z-SNAPSHOT] by 
13:33:54.331 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping Spark@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:54.331 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping SelectorManager@Spark@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:54.331 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ManagedSelector@6049262c{STARTED} id=7 keys=0 selected=0 updates=0
13:33:54.332 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$CloseConnections@39f7d27 on ManagedSelector@6049262c{STOPPING} id=7 keys=0 selected=0 updates=0
13:33:54.332 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@6049262c{STOPPING} id=7 keys=0 selected=0 updates=1
13:33:54.332 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@f0b3b92 woken with none selected
13:33:54.332 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@f0b3b92 woken up from select, 0/0/0 selected
13:33:54.332 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@f0b3b92 processing 0 keys, 1 updates
13:33:54.332 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.332 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@39f7d27
13:33:54.332 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - Closing 0 connections on ManagedSelector@6049262c{STOPPING} id=7 keys=0 selected=0 updates=0
13:33:54.332 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.332 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@f0b3b92 waiting with 0 keys
13:33:54.332 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$StopSelector@7c886655 on ManagedSelector@6049262c{STOPPING} id=7 keys=0 selected=0 updates=0
13:33:54.333 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@6049262c{STOPPING} id=7 keys=0 selected=0 updates=1
13:33:54.333 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@f0b3b92 woken with none selected
13:33:54.333 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@f0b3b92 woken up from select, 0/0/0 selected
13:33:54.333 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@f0b3b92 processing 0 keys, 1 updates
13:33:54.333 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.333 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@7c886655
13:33:54.333 [SparkUI-188] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.333 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping EatWhatYouKill@29a757b5/SelectorProducer@199c263e/PRODUCING/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=4,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.333-08:00
13:33:54.333 [SparkUI-188] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@2e2ef60a
13:33:54.333 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED EatWhatYouKill@29a757b5/SelectorProducer@199c263e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=5,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.333-08:00
13:33:54.333 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ManagedSelector@6049262c{STOPPED} id=7 keys=-1 selected=-1 updates=0
13:33:54.333 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ManagedSelector@30a61c8c{STARTED} id=6 keys=0 selected=0 updates=0
13:33:54.333 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$CloseConnections@2c402a7e on ManagedSelector@30a61c8c{STOPPING} id=6 keys=0 selected=0 updates=0
13:33:54.333 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@30a61c8c{STOPPING} id=6 keys=0 selected=0 updates=1
13:33:54.333 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@29fdf911 woken with none selected
13:33:54.333 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@29fdf911 woken up from select, 0/0/0 selected
13:33:54.333 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@29fdf911 processing 0 keys, 1 updates
13:33:54.333 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.333 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@2c402a7e
13:33:54.333 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - Closing 0 connections on ManagedSelector@30a61c8c{STOPPING} id=6 keys=0 selected=0 updates=0
13:33:54.333 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.333 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@29fdf911 waiting with 0 keys
13:33:54.333 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$StopSelector@14e98f39 on ManagedSelector@30a61c8c{STOPPING} id=6 keys=0 selected=0 updates=0
13:33:54.333 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@30a61c8c{STOPPING} id=6 keys=0 selected=0 updates=1
13:33:54.333 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@29fdf911 woken with none selected
13:33:54.334 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@29fdf911 woken up from select, 0/0/0 selected
13:33:54.334 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@29fdf911 processing 0 keys, 1 updates
13:33:54.334 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.334 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@14e98f39
13:33:54.334 [SparkUI-187] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping EatWhatYouKill@3f71ff40/SelectorProducer@7bd04f9e/PRODUCING/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=5,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.334-08:00
13:33:54.334 [SparkUI-187] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@2f1e2b4c
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED EatWhatYouKill@3f71ff40/SelectorProducer@7bd04f9e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=5,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.334-08:00
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ManagedSelector@30a61c8c{STOPPED} id=6 keys=-1 selected=-1 updates=0
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ManagedSelector@25b785e8{STARTED} id=5 keys=0 selected=0 updates=0
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$CloseConnections@6c67aec6 on ManagedSelector@25b785e8{STOPPING} id=5 keys=0 selected=0 updates=0
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@25b785e8{STOPPING} id=5 keys=0 selected=0 updates=1
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6667e8b6 woken with none selected
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6667e8b6 woken up from select, 0/0/0 selected
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6667e8b6 processing 0 keys, 1 updates
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@6c67aec6
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - Closing 0 connections on ManagedSelector@25b785e8{STOPPING} id=5 keys=0 selected=0 updates=0
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6667e8b6 waiting with 0 keys
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$StopSelector@53e2d7d1 on ManagedSelector@25b785e8{STOPPING} id=5 keys=0 selected=0 updates=0
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@25b785e8{STOPPING} id=5 keys=0 selected=0 updates=1
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6667e8b6 woken with none selected
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6667e8b6 woken up from select, 0/0/0 selected
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6667e8b6 processing 0 keys, 1 updates
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@53e2d7d1
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping EatWhatYouKill@5272c2e2/SelectorProducer@66f5b919/PRODUCING/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=6,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.334-08:00
13:33:54.334 [SparkUI-186] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@3a304104
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED EatWhatYouKill@5272c2e2/SelectorProducer@66f5b919/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=6,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.334-08:00
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ManagedSelector@25b785e8{STOPPED} id=5 keys=-1 selected=-1 updates=0
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ManagedSelector@50c942bc{STARTED} id=4 keys=0 selected=0 updates=0
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$CloseConnections@7e5c1409 on ManagedSelector@50c942bc{STOPPING} id=4 keys=0 selected=0 updates=0
13:33:54.334 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@50c942bc{STOPPING} id=4 keys=0 selected=0 updates=1
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@c25d651 woken with none selected
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@c25d651 woken up from select, 0/0/0 selected
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@c25d651 processing 0 keys, 1 updates
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@7e5c1409
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - Closing 0 connections on ManagedSelector@50c942bc{STOPPING} id=4 keys=0 selected=0 updates=0
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@c25d651 waiting with 0 keys
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$StopSelector@2614dcbc on ManagedSelector@50c942bc{STOPPING} id=4 keys=0 selected=0 updates=0
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@50c942bc{STOPPING} id=4 keys=0 selected=0 updates=1
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@c25d651 woken with none selected
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@c25d651 woken up from select, 0/0/0 selected
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@c25d651 processing 0 keys, 1 updates
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@2614dcbc
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping EatWhatYouKill@13e4faf7/SelectorProducer@2d0dd18e/PRODUCING/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=7,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.335-08:00
13:33:54.335 [SparkUI-185] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@42b11077
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED EatWhatYouKill@13e4faf7/SelectorProducer@2d0dd18e/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.335-08:00
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ManagedSelector@50c942bc{STOPPED} id=4 keys=-1 selected=-1 updates=0
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ManagedSelector@16229374{STARTED} id=3 keys=0 selected=0 updates=0
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$CloseConnections@77545726 on ManagedSelector@16229374{STOPPING} id=3 keys=0 selected=0 updates=0
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@16229374{STOPPING} id=3 keys=0 selected=0 updates=1
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6f8ab739 woken with none selected
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6f8ab739 woken up from select, 0/0/0 selected
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6f8ab739 processing 0 keys, 1 updates
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@77545726
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - Closing 0 connections on ManagedSelector@16229374{STOPPING} id=3 keys=0 selected=0 updates=0
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6f8ab739 waiting with 0 keys
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$StopSelector@324d5a42 on ManagedSelector@16229374{STOPPING} id=3 keys=0 selected=0 updates=0
13:33:54.335 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@16229374{STOPPING} id=3 keys=0 selected=0 updates=1
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6f8ab739 woken with none selected
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6f8ab739 woken up from select, 0/0/0 selected
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@6f8ab739 processing 0 keys, 1 updates
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@324d5a42
13:33:54.335 [SparkUI-184] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.336 [SparkUI-184] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@6b80e830
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping EatWhatYouKill@3b60b6eb/SelectorProducer@7bc0df2c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=8,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.336-08:00
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED EatWhatYouKill@3b60b6eb/SelectorProducer@7bc0df2c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=9,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.336-08:00
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ManagedSelector@16229374{STOPPED} id=3 keys=-1 selected=-1 updates=0
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ManagedSelector@7c0506f{STARTED} id=2 keys=0 selected=0 updates=0
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$CloseConnections@2caffc5e on ManagedSelector@7c0506f{STOPPING} id=2 keys=0 selected=0 updates=0
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@7c0506f{STOPPING} id=2 keys=0 selected=0 updates=1
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@5bd57ed3 woken with none selected
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@5bd57ed3 woken up from select, 0/0/0 selected
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@5bd57ed3 processing 0 keys, 1 updates
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@2caffc5e
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - Closing 0 connections on ManagedSelector@7c0506f{STOPPING} id=2 keys=0 selected=0 updates=0
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@5bd57ed3 waiting with 0 keys
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$StopSelector@2cde344b on ManagedSelector@7c0506f{STOPPING} id=2 keys=0 selected=0 updates=0
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@7c0506f{STOPPING} id=2 keys=0 selected=0 updates=1
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@5bd57ed3 woken with none selected
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@5bd57ed3 woken up from select, 0/0/0 selected
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@5bd57ed3 processing 0 keys, 1 updates
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@2cde344b
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.336 [SparkUI-183] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@5e90d2b5
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping EatWhatYouKill@695526a5/SelectorProducer@8ecbc7c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=10,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.336-08:00
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED EatWhatYouKill@695526a5/SelectorProducer@8ecbc7c/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=10,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.336-08:00
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ManagedSelector@7c0506f{STOPPED} id=2 keys=-1 selected=-1 updates=0
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ManagedSelector@7ec85a96{STARTED} id=1 keys=0 selected=0 updates=0
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$CloseConnections@79e6ab91 on ManagedSelector@7ec85a96{STOPPING} id=1 keys=0 selected=0 updates=0
13:33:54.336 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@7ec85a96{STOPPING} id=1 keys=0 selected=0 updates=1
13:33:54.336 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@63047db3 woken with none selected
13:33:54.336 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@63047db3 woken up from select, 0/0/0 selected
13:33:54.336 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@63047db3 processing 0 keys, 1 updates
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@79e6ab91
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - Closing 0 connections on ManagedSelector@7ec85a96{STOPPING} id=1 keys=0 selected=0 updates=0
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@63047db3 waiting with 0 keys
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$StopSelector@212171a5 on ManagedSelector@7ec85a96{STOPPING} id=1 keys=0 selected=0 updates=0
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@7ec85a96{STOPPING} id=1 keys=0 selected=0 updates=1
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@63047db3 woken with none selected
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@63047db3 woken up from select, 0/0/0 selected
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@63047db3 processing 0 keys, 1 updates
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@212171a5
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.337 [SparkUI-182] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@7e99d26e
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping EatWhatYouKill@68212f3c/SelectorProducer@25d55ed0/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=11,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.337-08:00
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED EatWhatYouKill@68212f3c/SelectorProducer@25d55ed0/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=11,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.337-08:00
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ManagedSelector@7ec85a96{STOPPED} id=1 keys=-1 selected=-1 updates=0
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ManagedSelector@24867183{STARTED} id=0 keys=0 selected=0 updates=0
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$CloseConnections@723f34d3 on ManagedSelector@24867183{STOPPING} id=0 keys=0 selected=0 updates=0
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@24867183{STOPPING} id=0 keys=0 selected=0 updates=1
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@3c45467f woken with none selected
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@3c45467f woken up from select, 0/0/0 selected
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@3c45467f processing 0 keys, 1 updates
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$CloseConnections@723f34d3
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - Closing 0 connections on ManagedSelector@24867183{STOPPING} id=0 keys=0 selected=0 updates=0
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@3c45467f waiting with 0 keys
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Queued change org.sparkproject.jetty.io.ManagedSelector$StopSelector@2f1e2ab3 on ManagedSelector@24867183{STOPPING} id=0 keys=0 selected=0 updates=0
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.io.ManagedSelector - Wakeup on submit ManagedSelector@24867183{STOPPING} id=0 keys=0 selected=0 updates=1
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@3c45467f woken with none selected
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@3c45467f woken up from select, 0/0/0 selected
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - Selector sun.nio.ch.KQueueSelectorImpl@3c45467f processing 0 keys, 1 updates
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - updateable 1
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - update org.sparkproject.jetty.io.ManagedSelector$StopSelector@2f1e2ab3
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.io.ManagedSelector - updates 0
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping EatWhatYouKill@4cdb93f3/SelectorProducer@6b9c9613/PRODUCING/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=11,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.337-08:00
13:33:54.337 [SparkUI-181] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.io.ManagedSelector$$Lambda$4050/190289942@2286a716
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED EatWhatYouKill@4cdb93f3/SelectorProducer@6b9c9613/IDLE/p=false/QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=12,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}][pc=0,pic=0,pec=0,epc=0]@2021-03-01T13:33:54.337-08:00
13:33:54.337 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ManagedSelector@24867183{STOPPED} id=0 keys=-1 selected=-1 updates=0
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED SelectorManager@Spark@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping HttpConnectionFactory@c49ed67[HTTP/1.1]
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED HttpConnectionFactory@c49ed67[HTTP/1.1]
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ScheduledExecutorScheduler@37c0bc42{STARTED}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ScheduledExecutorScheduler@37c0bc42{STOPPED}
13:33:54.338 [run-main-0] INFO org.sparkproject.jetty.server.AbstractConnector - Stopped Spark@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED Spark@ccf366d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - stopping Server@6979db37{STOPPING}[9.4.z-SNAPSHOT]
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ContextHandlerCollection@6bcc8098{STARTED}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - stopping ContextHandlerCollection@6bcc8098{STOPPING}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ContextHandlerCollection@6bcc8098{STOPPED}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ErrorHandler@52bffbf7{STARTED}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.server.handler.AbstractHandler - stopping ErrorHandler@52bffbf7{STOPPING}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ErrorHandler@52bffbf7{STOPPED}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping QueuedThreadPool[SparkUI]@24bcd30{STARTED,8<=12<=200,i=12,r=16,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}]
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Stopping QueuedThreadPool[SparkUI]@24bcd30{STOPPING,8<=12<=200,i=12,r=-1,q=0}[ReservedThreadExecutor@115ea1a4{s=0/16,p=0}]
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - stopping ReservedThreadExecutor@115ea1a4{s=0/16,p=0}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED ReservedThreadExecutor@115ea1a4{s=0/16,p=0}
13:33:54.338 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Waiting for Thread[SparkUI-188,5,run-main-group-0] for 14999
13:33:54.338 [SparkUI-191] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-192] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-187] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-192] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-189] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-182] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-190] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.339 [SparkUI-190] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-191] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-188] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-186] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-187] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-185] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-184] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-183] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-189] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.338 [SparkUI-181] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - run org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.339 [SparkUI-182] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.339 [SparkUI-188] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.339 [SparkUI-186] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.339 [SparkUI-185] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.339 [SparkUI-184] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.339 [SparkUI-183] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.339 [SparkUI-181] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - ran org.sparkproject.jetty.util.thread.QueuedThreadPool$$Lambda$5629/1676195554@6d1b98e4
13:33:54.339 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Waiting for Thread[SparkUI-183,5,run-main-group-0] for 14999
13:33:54.339 [run-main-0] DEBUG org.sparkproject.jetty.util.thread.QueuedThreadPool - Waiting for Thread[SparkUI-184,5,] for 14999
13:33:54.339 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED QueuedThreadPool[SparkUI]@24bcd30{STOPPED,8<=0<=200,i=0,r=-1,q=0}[NO_TRY]
13:33:54.339 [run-main-0] DEBUG org.sparkproject.jetty.util.component.AbstractLifeCycle - STOPPED Server@6979db37{STOPPED}[9.4.z-SNAPSHOT]
13:33:54.339 [run-main-0] INFO org.apache.spark.ui.SparkUI - Stopped Spark web UI at http://192.168.0.26:4040
13:33:54.350 [dispatcher-event-loop-4] INFO org.apache.spark.MapOutputTrackerMasterEndpoint - MapOutputTrackerMasterEndpoint stopped!
13:33:54.359 [run-main-0] INFO org.apache.spark.storage.memory.MemoryStore - MemoryStore cleared
13:33:54.360 [run-main-0] INFO org.apache.spark.storage.BlockManager - BlockManager stopped
13:33:54.366 [run-main-0] INFO org.apache.spark.storage.BlockManagerMaster - BlockManagerMaster stopped
13:33:54.372 [dispatcher-event-loop-8] INFO org.apache.spark.scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint - OutputCommitCoordinator stopped!
13:33:54.380 [run-main-0] INFO org.apache.spark.SparkContext - Successfully stopped SparkContext
[error] (run-main-0) org.apache.spark.SparkException: Writing job failed.
[error] org.apache.spark.SparkException: Writing job failed.
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:408)
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:361)
[error] 	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.writeWithV2(WriteToDataSourceV2Exec.scala:273)
[error] 	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:286)
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.doExecute(V2CommandExec.scala:54)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
[error] 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
[error] 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
[error] 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
[error] 	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)
[error] 	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)
[error] 	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:944)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
[error] 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
[error] 	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:944)
[error] 	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:342)
[error] 	at example.Main$.delayedEndpoint$example$Main$1(Main.scala:49)
[error] 	at example.Main$delayedInit$body.apply(Main.scala:23)
[error] 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
[error] 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
[error] 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
[error] 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
[error] 	at scala.collection.immutable.List.foreach(List.scala:431)
[error] 	at scala.App.main(App.scala:80)
[error] 	at scala.App.main$(App.scala:78)
[error] 	at example.Main$.main(Main.scala:23)
[error] 	at example.Main.main(Main.scala)
[error] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[error] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[error] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[error] 	at java.lang.reflect.Method.invoke(Method.java:498)
[error] Caused by: java.lang.Exception: Error in commit step of write to Vertica. There was a failure copying data from the intermediary into Vertica.
[error] 	at com.vertica.spark.datasource.v2.VerticaBatchWrite.commit(VerticaDatasourceV2Write.scala:74)
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2(WriteToDataSourceV2Exec.scala:396)
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2TableWriteExec.writeWithV2$(WriteToDataSourceV2Exec.scala:361)
[error] 	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.writeWithV2(WriteToDataSourceV2Exec.scala:273)
[error] 	at org.apache.spark.sql.execution.datasources.v2.OverwriteByExpressionExec.run(WriteToDataSourceV2Exec.scala:286)
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result$lzycompute(V2CommandExec.scala:39)
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.result(V2CommandExec.scala:39)
[error] 	at org.apache.spark.sql.execution.datasources.v2.V2CommandExec.doExecute(V2CommandExec.scala:54)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:175)
[error] 	at org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:213)
[error] 	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
[error] 	at org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:210)
[error] 	at org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:171)
[error] 	at org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:122)
[error] 	at org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:121)
[error] 	at org.apache.spark.sql.DataFrameWriter.$anonfun$runCommand$1(DataFrameWriter.scala:944)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:100)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:160)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:87)
[error] 	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:763)
[error] 	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)
[error] 	at org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:944)
[error] 	at org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:342)
[error] 	at example.Main$.delayedEndpoint$example$Main$1(Main.scala:49)
[error] 	at example.Main$delayedInit$body.apply(Main.scala:23)
[error] 	at scala.Function0.apply$mcV$sp(Function0.scala:39)
[error] 	at scala.Function0.apply$mcV$sp$(Function0.scala:39)
[error] 	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:17)
[error] 	at scala.App.$anonfun$main$1$adapted(App.scala:80)
[error] 	at scala.collection.immutable.List.foreach(List.scala:431)
[error] 	at scala.App.main(App.scala:80)
[error] 	at scala.App.main$(App.scala:78)
[error] 	at example.Main$.main(Main.scala:23)
[error] 	at example.Main.main(Main.scala)
[error] 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
[error] 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
[error] 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
[error] 	at java.lang.reflect.Method.invoke(Method.java:498)
[error] stack trace is suppressed; run 'last Compile / bgRun' for the full output
13:33:54.410 [org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner] WARN org.apache.hadoop.fs.FileSystem - exception in the cleaner thread but it will continue to run
java.lang.InterruptedException: null
	at java.lang.Object.wait(Native Method)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:144)
	at java.lang.ref.ReferenceQueue.remove(ReferenceQueue.java:165)
	at org.apache.hadoop.fs.FileSystem$Statistics$StatisticsDataReferenceCleaner.run(FileSystem.java:3063)
	at java.lang.Thread.run(Thread.java:748)
13:33:54.411 [LeaseRenewer:alexrehnbymartin@hdfs:8020] DEBUG org.apache.hadoop.hdfs.LeaseRenewer - LeaseRenewer is interrupted.
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.LeaseRenewer.run(LeaseRenewer.java:444)
	at org.apache.hadoop.hdfs.LeaseRenewer.access$700(LeaseRenewer.java:71)
	at org.apache.hadoop.hdfs.LeaseRenewer$1.run(LeaseRenewer.java:304)
	at java.lang.Thread.run(Thread.java:748)
13:33:54.411 [LeaseRenewer:alexrehnbymartin@hdfs:8020] DEBUG org.apache.hadoop.hdfs.LeaseRenewer - Lease renewer daemon for [] with renew id 1 exited
13:33:54.411 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin: closed
13:33:54.412 [IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin] DEBUG org.apache.hadoop.ipc.Client - IPC Client (435209877) connection to hdfs/127.0.0.1:8020 from alexrehnbymartin: stopped, remaining connections 0
[error] Nonzero exit code: 1
[error] (Compile / run) Nonzero exit code: 1
[error] Total time: 45 s, completed 1-Mar-2021 1:33:54 PM
13:33:54.671 [Thread-2] INFO org.apache.spark.util.ShutdownHookManager - Shutdown hook called
13:33:54.672 [Thread-2] INFO org.apache.spark.util.ShutdownHookManager - Deleting directory /private/var/folders/qc/3jl77x7x5p7b_n53kxh549300000gp/T/spark-f652cbbc-fa14-4b74-b247-9b88ba9327eb
13:33:54.676 [Thread-2] DEBUG org.apache.hadoop.ipc.Client - stopping client from cache: org.apache.hadoop.ipc.Client@309107b1
13:33:54.676 [Thread-2] DEBUG org.apache.hadoop.ipc.Client - removing client from cache: org.apache.hadoop.ipc.Client@309107b1
13:33:54.676 [Thread-2] DEBUG org.apache.hadoop.ipc.Client - stopping actual client because no more references remain: org.apache.hadoop.ipc.Client@309107b1
13:33:54.676 [Thread-2] DEBUG org.apache.hadoop.ipc.Client - Stopping client
