version: "3.9"
services:
  client:
    build: .
    container_name: docker_client_1
    volumes:
      - ./..:/spark-connector
      - ./vertica-hdfs-config/hadoop:/etc/hadoop/conf
    stdin_open: true
    ports:
#      JVM Remote debug port
      - "5005:5005"
    environment:
      - HADOOP_VERSION
      - SPARK_VERSION
      - GCS_FILEPATH
      - GCS_HMAC_KEY_ID
      - GCS_HMAC_KEY_SECRET
      - GCS_SERVICE_KEY_ID
      - GCS_SERVICE_KEY
      - GCS_SERVICE_EMAIL
      - AWS_ACCESS_KEY_ID
      - AWS_SECRET_ACCESS_KEY
  spark-driver:
    build: .
    container_name: spark-driver
    ports:
      - "8080:8080"
      - "4040:4040"
    volumes:
      - ./..:/spark-connector
      - ./vertica-hdfs-config/hadoop:/etc/hadoop/conf
    stdin_open: true
  spark-worker-1:
    build: .
    container_name: spark-worker-1
    ports:
      - "8081:8081"
    volumes:
      - ./..:/spark-connector
      - ./vertica-hdfs-config/hadoop:/etc/hadoop/conf
    stdin_open: true
  spark-worker-2:
    build: .
    container_name: spark-worker-2
    ports:
      - "8082:8081"
    volumes:
      - ./..:/spark-connector
      - ./vertica-hdfs-config/hadoop:/etc/hadoop/conf
    stdin_open: true
  vertica:
    image: vertica/vertica-k8s:${VERTICA_VERSION:-latest}
    container_name: docker_vertica_1
    ports:
      - "5433:5433"
    volumes:
      - ./vertica-hdfs-config/hadoop:/etc/hadoop/conf
  hdfs:
    image: mdouchement/hdfs
    container_name: docker_hdfs_1
    ports:
      - "22022:22"
      - "8020:8020"
      - "50010:50010"
      - "50020:50020"
      - "50070:50070"
      - "50075:50075"
    stdin_open: true
    volumes:
      - ./vertica-hdfs-config/hadoop:/hadoop/conf
  minio:
    image: minio/minio
    container_name: docker_minio_1
    entrypoint: sh
    command: -c 'mkdir -p /data/test && minio server /data --console-address ":9001"'
    ports:
      - "9000:9000"
      - "9001:9001"
    volumes:
      - minio-data:/data
volumes:
  minio-data:
