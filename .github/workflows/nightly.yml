name: Scheduled Test

on:
  push:
    branches: [ nightly_action ]
  schedule:
    # Every day at 4:18 am
    - cron: '18 4 * * *'
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout the project
        uses: actions/checkout@v2
      - name: Build the project
        run: cd connector && sbt package
      - name: Upload the build artifact
        uses: actions/upload-artifact@v1
        with:
          name: build-jar-file
          path: /home/runner/work/spark-connector/spark-connector/connector/target/scala-2.12/spark-vertica-connector_2.12-3.1.0.jar
  run-analysis:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout the project
        uses: actions/checkout@v2
      - name: Run scalastyle
        run: cd connector && sbt scalastyle
  run-unit-tests:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout the project
        uses: actions/checkout@v2
      - name: Run unit tests
        run: cd connector && sbt coverage test coverageReport
      - name: Upload coverage report to codecov
        uses: codecov/codecov-action@v2
        with:
          flags: unittests
          name: codecov-umbrella
          fail_ci_if_error: true
          verbose: true
  run-integration-tests-spark-3-0-2-Vertica-10-1-1-0:
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Checkout the project
        uses: actions/checkout@v2
      - name: Set Vertica version to 10.1.1-0
        run: export VERTICA_VERSION=10.1.1-0
      - name: Run docker compose
        run: cd docker && docker-compose up -d
      - name: Create db in Vertica
        run: docker exec docker_vertica_1 /bin/sh -c "opt/vertica/bin/admintools -t create_db --database=docker --password='' --hosts=localhost"
      - name: Replace HDFS core-site config with our own
        run: docker exec docker_hdfs_1 cp /hadoop/conf/core-site.xml /opt/hadoop/etc/hadoop/core-site.xml
      - name: Replace HDFS hdfs-site config with our own
        run: docker exec docker_hdfs_1 cp /hadoop/conf/hdfs-site.xml /opt/hadoop/etc/hadoop/hdfs-site.xml
      - name: Copy partitioned parquet data to HDFS container
        run: docker cp ./functional-tests/src/main/resources/3.1.1 docker_hdfs_1:/partitioned
      - name: Copy partitioned parquet data to hadoop from local
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 20
          max_attempts: 10
          retry_on: error
          command: docker exec docker_hdfs_1 hadoop fs -copyFromLocal /partitioned /3.1.1
      - name: Download the build artifact
        uses: actions/download-artifact@v2
        with:
          name: build-jar-file
          path: ./functional-tests/lib/
      - name: Increase active sessions in database
        uses: nick-invision/retry@v2
        with:
          timeout_seconds: 20
          max_attempts: 10
          retry_on: error
          command: docker exec docker_vertica_1 vsql -c "ALTER DATABASE docker SET MaxClientSessions=100;"
      - name: Copy functional tests to home directory of client container
        run: docker exec docker_client_1 cp -r /spark-connector/functional-tests /home
      - name: Copy version.properties file from client container
        run: docker exec docker_client_1 cp -r /spark-connector/version.properties /home
      - name: Run the integration tests on Spark 3.0
        run: docker exec -w /home/functional-tests docker_client_1 sbt run -DsparkVersion="3.0.2" -DhadoopVersion="2.4.0"
      - name: Remove docker containers
        run: cd docker && docker-compose down
  slack-workflow-status:
    if: always()
    name: Post Workflow Status To Slack
    needs:
      [  run-integration-tests-spark-3-0-2-Vertica-10-1-1-0,
#        run-integration-tests-spark-3-1-1,
#        run-integration-tests-spark-3-0-2
      ]
    runs-on: ubuntu-latest
    steps:
      - name: Slack Workflow Notification
        uses: Gamesight/slack-workflow-status@master
        with:
          # Required Input
          repo_token: ${{secrets.GITHUB_TOKEN}}
          slack_webhook_url: ${{secrets.SLACK_CHANNEL_WEBHOOK}}
          # Optional Input
          name: 'Alex Workflow Bot'
          icon_emoji: ':ezy:'
